0:00:00.250,0:00:04.350
딥러닝 레슨2에 돌아오신걸 환영합니다.

0:00:06.940,0:00:08.940
지난주에

0:00:09.360,0:00:12.800
꽤나 정확한 이미지 분류 모델을 
성공적으로

0:00:13.180,0:00:15.740
학습시키는 것까지 진행하였습니다.

0:00:16.000,0:00:18.719
어떻게 했었는지 
리마인드 해드리도록 하겠습니다.

0:00:19.280,0:01:01.220
(백그라운드 사운드)

0:01:02.440,0:01:08.240
리마인드 차원에서, 이미지 분류 모델을 만든 
방법은 단순히 

0:01:09.300,0:01:12.620
세 줄의 코드를 사용한 것이었습니다.

0:01:12.820,0:01:16.049
그리고 이 세 줄의 코드는 
특정 경로(PATH)를 가리켰는데, 

0:01:16.990,0:01:22.259
이 경로에는 이미 데이터가 들어 있었죠.
모델을 어떻게 학습스키는지를 알기위해서

0:01:23.049,0:01:30.479
개와 고양이 이미지 데이터를 가진 이 경로가
특별한 구조를 가진다는게 중요합니다.

0:01:31.270,0:01:33.570
이 경로에는 학습(train)과 검증(valid) 폴더가 있고

0:01:33.850,0:01:37.949
각 폴더에는 고양이(cats)와 개(dogs)폴더가
들어 있습니다.

0:01:37.949,0:01:42.400
그리고 각 고양이(cats)와 개(dogs)폴더에는
고양이와 개들의 사진이 들어 있습니다. 

0:01:42.400,0:01:44.400
꽤나 표준적인 방식의 구조로

0:01:45.560,0:01:48.120
주로 사용되는 두 가지 구조 중

0:01:48.480,0:01:50.120
하나로 

0:01:50.530,0:01:55.470
이미지 모델의 학습에 필요한 데이터가 이 폴더에 
있다는걸 알려줍니다. 지난 한 주 동안

0:01:55.780,0:01:59.549
다른 종류의 이미지를 가진 폴더에 저장된

0:02:00.340,0:02:03.899
자신만의 다른 데이터를 가지고
자신만의 이미지 모델을 만들어 봤을 겁니다. 

0:02:04.300,0:02:09.140
커뮤니티 포럼에 게시된 글을 보면
대부분 잘 동작하는것 같더군요.

0:02:09.760,0:02:12.080
스스로 해 보신것이

0:02:12.140,0:02:13.880
코스를 시작하는데 있어서

0:02:13.890,0:02:15.890
알아야할 전부입니다.

0:02:16.150,0:02:21.660
다른 종류의 이미지 수백장 또는 수천장이 포함된
폴더를 스스로 만들어 보셨다면, 

0:02:22.180,0:02:24.959
이 동일한 세 줄의 코드의 수행 결과가

0:02:25.569,0:02:31.679
이미지 분류 모델을 생성해 주고,
마지막 세 번째 행을 보고

0:02:31.680,0:02:35.760
모델이 얼마나 정확한지를 
알 수 있을 것입니다.

0:02:37.420,0:02:39.280
그리고

0:02:39.280,0:02:41.280
몇 간단한

0:02:42.010,0:02:44.640
시각화를 수행해서 

0:02:45.640,0:02:49.340
불확실한게 무엇이고, 잘못된 결과가 
무엇인지등을 살펴봤습니다.

0:02:49.340,0:02:51.340
이 시각화는 매우 좋은 접근 방법 입니다.

0:02:52.800,0:02:54.180


0:02:54.190,0:02:58.889
그리고나서, 선택해야 하는 한가지 중요한 숫자에 대해서 
배웠습니다. 

0:02:58.890,0:03:05.970
여기 이게 그 숫자로 값이 0.01 인데,
이 숫자는 학습률(learning rate)이라고 불립니다.

0:03:07.120,0:03:09.959
그리고 학습률이 의미하는게 무엇인지
코스의 나머지를 진행하는 동안

0:03:10.600,0:03:15.509
이론적으로 상세하게 많이 배우게 될겁니다.
단지, 지금은 방법에 대해서 설명드린 것입니다.

0:03:18.780,0:03:27.040
네. Yannet?

0:03:30.760,0:03:35.910
전에 다른 세가지 숫자가 나빠지는 것에 대해서
말씀하였죠??

0:03:36.640,0:03:38.230
여기 이 세가지 숫자요? 

0:03:38.230,0:03:43.170
세번째 것은 나중에 말씀 드리겠습니다.
일단 마지막에 있는 숫자가 주된 것으로

0:03:43.170,0:03:45.959
정확도를 의미합니다.

0:03:47.110,0:03:53.429
첫번째 숫자는 에포크 숫자고, 더 나은 분류 모델을 
학습하기 위해서 몇번이나 전체 데이터셋을

0:03:54.610,0:04:00.239
훑어봤는지를 말해주죠.
두번째, 세번째 숫자는 손실이라는 것인데

0:04:01.209,0:04:05.369
오늘 나중이나,  다음주에 배우게 될 겁니다.
그 중 첫번째는 학습 데이터셋에 대한 손실로

0:04:05.530,0:04:09.179
더 나은 분류 모델을 만들기 위해서
살펴봐야 하는 이미지들에 대한 것입니다.

0:04:09.180,0:04:14.459
두번째는 검증 데이터셋에 대한 손실로,
학습단계에서는 사용되지 않는 이미지로

0:04:14.459,0:04:19.679
아무 관여 없이, 얼마나 정확힌지 확인해 보는것입니다.
쨋든 나중에 좀 더 자세히 배우게 될거에요.

0:04:25.400,0:04:27.400


0:04:29.300,0:04:33.789
요약해 보면, 에포크의 수가 있고
학습 데이터셋에 대한 손실,

0:04:34.700,0:04:39.430
검증 데이터셋에 대한 손실, 그리고 
마지막에 정확도가 있습니다.

0:04:45.399,0:04:48.599
학습률의 기본적인 개념은

0:04:54.520,0:05:01.469
학습률의 기본적인 개념은 얼마나 빠르게
해결책으로 다가갈지를 결정하는 것입니다.

0:05:01.599,0:05:08.218
학습률이 뭔지를 생각해보기에 좋은 방법으로

0:05:08.219,0:05:10.219
어떤함수에 맞아 들어가길 

0:05:10.539,0:05:12.539
원하는 상황을 사용해 봅시다.

0:05:13.240,0:05:18.449
여기 보시는것 처럼 말이에요. 
이함수의 최소 지점이 어디쯤인지를 알고 싶은거에요.

0:05:19.029,0:05:24.509
딥러닝을 할때, 보통 우리가 원하는 것은
함수의 최소지점을 찾는 것입니다.

0:05:26.349,0:05:28.349
만약 우리의 함수가 수백만개의 

0:05:28.869,0:05:33.329
파라메터로 이루어져 있더라도, 동일한 방식으로 동작합니다. 
이 함수를 보면

0:05:33.330,0:05:35.319
즉시 최소 지점이 여기라는걸

0:05:35.319,0:05:37.319
아실 수 있을 거에요.

0:05:38.680,0:05:44.459
하지만, 사람이 아니라 컴퓨터 알고리즘이라면
어떻게 여길 알아낼 수 있을까요?

0:05:44.619,0:05:48.869
여기처럼 시작시점에는 무작위 지점을 선택합니다.
그리고 그 지점에 대해

0:05:48.870,0:05:51.569
손실 또는 에러값이 무엇인지 계산하게 되죠

0:05:51.999,0:05:56.009
그리고 나서, 어느방향이 위고 아래인지를 말해주는
경사도를 구하게 됩니다.

0:05:56.529,0:06:02.729
경사도가, 아래로 내려가기 위한 방향이 왼쪽이라는걸
알려주고, 얼마나 빠르게 내려갈 수 있을지도 알려줍니다.

0:06:03.339,0:06:05.759
이 지점에서는 꽤나 빠르게 내려가겠군요.

0:06:06.519,0:06:09.029
그러면 그 방향으로 한번의 보폭만큼

0:06:09.309,0:06:13.829
내려가고, 움직인 거리는

0:06:13.990,0:06:20.909
얼마나 가파른지를 나타내는 경사도에 비례하게 됩니다. 
더 가파르면, 더 멀리 움직이게 되는거죠.

0:06:21.219,0:06:25.889
설명드린 내용이 기본적인 개념입니다.
이 예제에서 보시면, 이 지점에서 

0:06:25.889,0:06:30.718
얼마나 가파른지에 대한 경사도를 구하고,
경사도에 학습률이라는 값을 곱해줍니다.

0:06:31.209,0:06:34.349
만약 이 학습률의 값을 아주 작게

0:06:35.289,0:06:36.550
설정하면

0:06:36.550,0:06:41.339
아주아주 조금씩 매번 최소지점으로 가까워
지는것을 보장할 수 있습니다.

0:06:41.680,0:06:48.419
하지만 그러면 너무 오랜 시간이 걸리게 되죠.
만약 아주아주 큰 값으로 설정하면

0:06:48.459,0:06:54.959
방향은 맞지만, 너무나 멀리 움직이게 되어 버리는데
이만큼 반대편으로 날아갈 수 있습니다.

0:06:56.169,0:07:00.929
마지막엔 결국 시작점보다도 훨씬 더 
멀리 떨어져 버릴 수 있고, 점점 더 

0:07:01.300,0:07:08.699
나빠지게 됩니다. 만약 뉴럴넷의 학습을 시작하는데,
정확도나 손실값이 

0:07:09.130,0:07:12.930
무한대로 빠져버린다면, 거의 확실하게
학습률이 너무 크다고 보시면 됩니다.

0:07:14.050,0:07:18.120
그러니까 아주 작은 학습률이 
아주 클때보다는

0:07:18.550,0:07:22.590
오랜 시간 기다리기만 하면 되서, 더 나은 문제입니다.
하지만, 만약 최고의 학습률을

0:07:22.590,0:07:24.590
생각해낼 방법이 있다면 좋겠지요?

0:07:24.640,0:07:30.640
아주 빠르게 최소지점으로 도달 가능하니까요.

0:07:32.220,0:07:36.080
그러기 위해서 우리는 
학습률 발견자(lr_find)라는 것을 사용합니다.

0:07:36.090,0:07:42.479
학습률 발견자가 하는일은 매번
미니배치에 대해서, 아 미니배치란

0:07:42.880,0:07:50.010
한번에 확인 대상이 되는 적응양의 이미지로,
GPU를 이용한 병렬 처리의 장점을 효과적으로

0:07:50.350,0:07:52.350
용하기 위한 것입니다. 일반적으로

0:07:52.420,0:07:57.900
각 미니배치에는 64 또는 128장의 이미지가 있습니다.
여기 iterations 으로 표시되어 있습니다.

0:07:58.840,0:08:01.500
학습률을 서서히 배수 단위로

0:08:01.540,0:08:02.850
증가시킵니다.

0:08:02.850,0:08:09.329
처음에는 아주 작은 학습률로 시작해서,
점진적으로 값을

0:08:09.640,0:08:12.180
증가시킵니다. 

0:08:12.670,0:08:18.870
마침내 학습률은 너무 커져서, 손실값이 
점점 나빠지게 됩니다. 

0:08:18.870,0:08:20.870
그러면 이때는 

0:08:21.970,0:08:26.249
학습률에 대한 손실값의 변화에 대한 그래프를
살펴봐야 합니다. 보시다시피 학습률이 아주 작으면

0:08:27.250,0:08:30.510
손실변화가 천천히 증가하고, 
손실변화가 더 빨이 증가하게 되고,

0:08:30.510,0:08:35.100
마지막으로 더이상 증가하지 않기 시작합니다.
사실상 좋아지는게 아니라 나빠지고 있는 시점이죠.

0:08:35.380,0:08:40.840
그리고 과학적 표기와 친숙해 져야

0:08:41.140,0:08:44.100
한다는걸 알아주세요. 
예를 들어서 10의 -1승은 0.1이고

0:08:45.370,0:08:51.359
10의 0승은 1이고, 10의 -2승은 0.01 같은것들 말이죠.

0:08:52.120,0:08:58.140
파이썬에서 이 표기들을 코딩할때는 
10-1이나 10-2처럼 적는게 아니라

0:08:58.240,0:09:00.240
1e-1, 1e-2  처럼

0:09:00.700,0:09:06.809
적으면 됩니다. 좌우가 동일한 값이에요.
이 표기를 자주 접하게 될겁니다.

0:09:07.780,0:09:12.299
첫번째가 0.1, 두번째가 0.01인 것도 알아두세요.

0:09:15.100,0:09:17.100


0:09:18.460,0:09:22.769
여기에 출력되는 텍스트로 인해서 혼동하지 마세요.
여기 있는 손실(loss)는

0:09:23.020,0:09:27.380
제일 마지막에 대한 최종 손실값입니다.
일단 지금은 무시하고 넘어가도  됩니다.

0:09:28.260,0:09:32.160
학습률 발견자를 사용하는게 아닌
기본적인 학습을 할때만, 의미 있는 값이에요.

0:09:32.160,0:09:38.999
학습률 발견자를 사용할때 관심을 가져야하는건
learn.sched.plot() 인데요,

0:09:39.670,0:09:45.959
이 그래프에서 가장 낮은 지점이 중요한게 아닙니다.
최저점은 더이상 향상되지 않는 부분이니까요.

0:09:45.960,0:09:47.380
학습률이 너무 높은거죠.

0:09:47.380,0:09:53.489
그러니까 중요한 지점은 최저점이 아니라
최저점의 한단계 직전 지점이 됩니다.

0:09:54.250,0:09:56.110
여기서는 1e-2 정도가 

0:09:56.110,0:09:58.110
좋은 선택이 되겠군요.

0:09:58.140,0:10:04.220
learn.fit() 함수를 수행할때, 
첫번째 인자값으로 0.01(=1e-2) 을

0:10:04.560,0:10:08.460
선택한 이유입니다.

0:10:10.180,0:10:15.450
이 숫자는 우리가 조절할 수 있는 
중요한 숫자라고 배웠다는

0:10:16.090,0:10:17.980
점이 중요합니다.

0:10:17.980,0:10:19.240
그리고

0:10:19.240,0:10:20.260
만약

0:10:20.260,0:10:24.660
다른 부분은 그대로 놔둔채, 이 숫자만 다르게 
조절 해보면 대부분 좋은 결과를 얻을 수 있는데

0:10:24.820,0:10:32.489
보통 교과서나 다른 강의들이 말하는 내용과는 
매우 다른 이야기가 됩니다.

0:10:33.100,0:10:34.660
왜냐하면

0:10:34.660,0:10:36.100
지금까지는

0:10:36.100,0:10:41.790
설정해야하는 하이퍼-파라메터가 수십개씩
존재해 왔고,

0:10:41.950,0:10:47.249
매우 민감하고, 설정하기가 매우 어렵다고 생각되었습니다. 
Fast AI 라이브러리에서는

0:10:47.340,0:10:50.360
가능한한 이 모든것을 자동으로 할 수 있도록

0:10:50.500,0:10:52.150
도와주고,

0:10:52.150,0:10:56.400
코스 동안에는 좀 더나은 결과를 얻기위한 
다른 무언가를 배우게 될 것입니다.

0:10:57.760,0:10:59.580
약간

0:10:59.580,0:11:02.140
재밌는 상황이긴 한데요

0:11:02.140,0:11:06.869
아직 아무것도 배우지 않은 학생들에게는
그 다른 무언가가 전부가 됩니다.

0:11:07.630,0:11:11.999
매우 쉽죠. 그리고 이 수업을 듣지 않은
다른 사람들과 이야기할때

0:11:12.000,0:11:17.100
딥러닝이 매우 어렵고, 진정한 예술적인 형태라고
말할지도 모릅니다.

0:11:17.320,0:11:22.229
진실은 이 학습률을 설정하는게 
엄청나게 중요하다는 것이죠.

0:11:22.300,0:11:27.409
학습률을 어떻게 설정 잘 할지를 알아내기 위해
고안된 이 논문에 소개된 방법은

0:11:28.170,0:11:30.170
약 18개월 정도 되었지만

0:11:30.449,0:11:33.919
거의 아무도 이 논문에 대해서 모른단 말이죠.
별로 유명하지 않은

0:11:33.920,0:11:39.769
연구실 소속의 학생이 적어서, 대부분의 사람들이
이를 무시했어요. 사실 소개된 기법은 전체 논문의

0:11:39.990,0:11:41.990
일부분으로 소개된 내용입니다.

0:11:42.829,0:11:46.099
그러니까 이 방법이 학습률을 어떻게
설정해야 하는 방법이에요.

0:11:47.189,0:11:53.689
이 수업을 듣지 않으면 모를 일이죠. 논문의 저자
Leslie Smith는 물론 알겠지만요 ㅎ

0:11:55.259,0:12:00.589
동료들에게 학습률을 설정하는 매우 좋은
방법이 있다는걸 알려주길 바랍니다.

0:12:01.709,0:12:06.438
또 다른 유명한 논문은 제목이
"no more pesky learning rates"로
(더이상 성가시지 않은 학습률)

0:12:06.899,0:12:10.008
제가 소개드린 것 보다 "덜" 효과적인 기법 입니다.

0:12:10.009,0:12:12.049
학습률을 설정하는 것이

0:12:12.209,0:12:17.899
매우 어렵고 환장할 일이라는게 대부분의 
딥러닝 역사를 통해서 사실로 여겨져 왔죠

0:12:19.019,0:12:21.409
여기 그래프를 보세요

0:12:22.050,0:12:27.079
최저지점 같아보이는 곳을 찾고, 거기서부터
약 1/10만큼 앞의 값을 학습률로 시도해보세요

0:12:27.080,0:12:31.160
이 값으로 잘 동작하지 않으면, 계속해서
1/10만큼 작은걸 시도해 보면 됩니다.

0:12:31.160,0:12:34.300
제 경우는 그럴필요가 항상 없었지만요.

0:12:40.160,0:12:41.279
>> 질문이요

0:12:41.279,0:12:46.578
>> 학습률 방법이 momentum 등 다른 방법과
비교해서 어떤가요?

0:12:46.579,0:12:52.428
>> 학습률 설정 기법의 장점과 단점 같은 것들 말예요

0:12:58.559,0:13:00.559
아주 좋은 질문이에요.

0:13:00.689,0:13:03.498
경사하강법의 향상을 위한 말씀하신 momentum이나

0:13:03.920,0:13:07.700
Adam 같은 많은 방법을 코스동안에 배우게 될 겁니다.

0:13:08.129,0:13:14.029
사실 Adam같은 기법들은 fastai 라이브러리가
하려는 일과 직교하는데요,

0:13:14.610,0:13:17.149
fastai가 올바른 경사하강을 알아내려고 할때,
내부적으로는 

0:13:17.149,0:13:22.849
Adam 이라는 것을 사용합니다. 이 학습률의
기법은 최고로 좋은 학습률을

0:13:24.749,0:13:28.399
Adam optimizer라는걸 사용해서 알려주는 것이죠.

0:13:28.529,0:13:34.489
그러니까 각 기법들이 상호 타협적인것이 
아니라는 겁니다.

0:13:34.490,0:13:37.669
다른 기법들을 사용하더라도
여전히 학습률을 설정 해야만 하는 것이죠.

0:13:37.679,0:13:39.600
어떤 문제에 대해서

0:13:39.600,0:13:43.129
최고의 optimizer를 발견했다고 해도,
여전히 학습률을 설정 해야 합니다.

0:13:43.129,0:13:47.629
여기 그래프가 그 방법을 보여주죠.
사실 이 학습률 기법을, 논문의 발표당시

0:13:48.209,0:13:50.899
없었던 더 진보된 

0:13:51.029,0:13:54.049
Adam 같은 optimizer와 함께 
사용할 수도 있습니다.

0:13:54.050,0:13:57.199
엄청난 임팩트가 있는건 아니지만,
아직 이 기법을 시도한 사람이 

0:13:57.990,0:14:00.589
많지 않으니까 좋은 결과를 보여줄 거에요.

0:14:05.800,0:14:07.010
>> 잘 안들림

0:14:07.010,0:14:14.229
(Adam Optimizer 저자가 그러길, 학습률이 
에포크 동안 변화해야 하는것이고 하지 않았냐?)

0:14:14.420,0:14:16.420
라고 들리는군요...)

0:14:19.040,0:14:20.990
음..

0:14:20.990,0:14:25.570
Adam이나 더 자세한 내용을
클래스 나중에 배우게 될것입니다.

0:14:25.570,0:14:29.640
일단 간단히 대답해 드리면, "아니오" 구요.
Adam 또한 학습률이 있는데

0:14:31.320,0:14:37.740
간단히 말해보자면... 학습률은 앞서 계산된
경사도의 평균으로 나눠(divide) 진 후

0:14:38.690,0:14:43.179
가장 최근의 경사도들의 
루트값들의 합입니다.

0:14:43.180,0:14:48.700
여전히 학습률이라고 불리는 숫자가 있어요.
동적인 학습률이라고 언급하더라도

0:14:49.250,0:14:51.080
여전히

0:14:51.080,0:14:53.080
학습률이 있습니다.

0:14:55.640,0:14:57.640


0:14:59.839,0:15:01.839
모델을 더 좋게

0:15:02.690,0:15:08.649
만들기 위해서 가장 중요한 것은 
더 많은 데이터를 던져 주는 겁니다.

0:15:09.290,0:15:14.589
이 모델에는 수백만개의 파라메터가 있는데,
한동안 이 모델을 학습 시키면

0:15:15.320,0:15:18.640
과적합(overfitting) 이라는 것이 

0:15:19.070,0:15:26.679
시작된다는 난제가 있습니다. 과적합이란 
모델이 모든 이미지의 일반적인 부분이 아니라, 
주어진 이미지의 아주 특정 부분만을

0:15:26.740,0:15:28.740
바라보기 시작한다는 것입니다.

0:15:29.320,0:15:32.820
일반적인 학습이 되어야,
검증 데이터셋에서도 잘 동작할 것입니다.

0:15:33.529,0:15:38.199
과적합을 피하기 위해서 할 수 있는 것은
더 많은 데이터를 구하는 것입니다.

0:15:38.329,0:15:43.329
어디서든지 데이터를 더 많이 구해서
레이블링하는것이 확실한 방법입니다. 

0:15:43.760,0:15:49.119
그러나 "data augmentation"이라고 불리는 
기법을 사용하는게 더 쉬운 방법이고,
항상 사용해야 하는 방법이에요.

0:15:50.540,0:15:55.599
많은 코스들은 이 방법에 대해서 언급조차
하지 않거나

0:15:55.600,0:15:59.560
심화 주제로 코스 마지막에 다루거나 합니다만

0:15:59.560,0:16:04.779
사실상 모델을 더 좋게 만들기 위해서
가장 중요한 방법중 하나입니다.

0:16:04.779,0:16:09.849
이 방법은 fastai 라이브러리에 내장되어 있고,
아주 사용법이 쉽습니다. 관련 코드를 상세히

0:16:09.849,0:16:13.260
잠시후 보게 될 텐데요,

0:16:14.080,0:16:17.320
일단 작성된 최초의 코드를 보면

0:16:18.340,0:16:22.620
ImageClassfierData.from_path 라는 
코드 한 줄이 있습니다.

0:16:22.630,0:16:27.279
여기에 데이터가 있는 경로(path)와 
아키텍처의 크기를 바꾸는

0:16:28.279,0:16:31.838
transform을 파라메터로 줬습니다.
상세한 내용은 잠시 후에 알려드릴게요.

0:16:32.180,0:16:37.839
그리고 나서, 어떤 종류의 "data augmentation"을
사용할지에 대한 파라메터를 추가 했습니다.

0:16:38.600,0:16:40.070


0:16:40.070,0:16:47.529
data augmentation을 이해하려면, 이 기법이
적용된 사진을 직접 보는게 가장 쉬울 겁니다.

0:16:47.529,0:16:51.819
여기에 제가 적용한 결과가 있습니다.

0:16:53.180,0:16:55.010
Image...Data 클래스를 

0:16:55.010,0:17:01.080
6번 생성 했습고, 각 생성때 마다
똑같은 고양이 사진을 출력했습니다.

0:17:01.080,0:17:04.780
어떤일이 일어났는지 보이시나요?

0:17:05.060,0:17:09.620
세번째 고양이는 좀더 왼쪽으로 움직였고
다섯번째는 오른쪽으로 움직였고, 

0:17:09.620,0:17:12.100
네번째는 좌우 반전 되었습니다.

0:17:12.100,0:17:16.300
다른 종류의 이미지를 원하면

0:17:16.520,0:17:24.300
다른 종류의 data augmentation이 필요 합니다.
예를들어서, 문자와 숫자를 인식하고 싶으면

0:17:25.520,0:17:30.400
좌우를 뒤집으면 안되겠죠. 뒤집으면
다른 의미를 가지게 되니까요.

0:17:31.040,0:17:33.699
반면에, 고양이나 강아지

0:17:34.429,0:17:40.329
사진에 대해서는, 상하를 뒤집지 말아야 겠죠.
왜냐하면 동물들이 보통 뒤집어지지 않으니까요.

0:17:40.550,0:17:44.469
또 다른 예로, 현재 진행중인 Kaggle에 보면

0:17:45.050,0:17:46.670
위성 사진에서 

0:17:46.670,0:17:50.859
빙산을 인식하는 경연이 있는데, 여기서는
사진의 위아래를 뒤집어야 할지도 모릅니다.

0:17:51.110,0:17:56.500
왜냐하면 빙산 주변에 뭐가 있는지는
별로 중요한게 아닐 수 있니까요.

0:17:58.250,0:18:01.119
transform을 설정 하는 한가지 예로

0:18:01.370,0:18:06.069
transforms_side_on가 있습니다.
측면으로 찍힌 사진이 있을때

0:18:06.590,0:18:09.939
이 사진은 좌우 뒤집기는 괜찮지만
상하 뒤집기는 안되는등

0:18:10.010,0:18:13.749
모든 변형 가능한 방법을 제공해 줍니다.
측면에 대한 뒤집기와

0:18:14.390,0:18:19.839
약간, 그러나 너무 많이는 아닌 각도의 회전시키
콘트라스트와 밝기를 약간 없애버리기

0:18:21.400,0:18:25.180
그리고 약간 확대나 축소하는 것
또, 약간 위치를 움직이는 것등

0:18:25.180,0:18:28.600
매번 다른 종류의 이미지가 생기게 됩니다.

0:18:30.200,0:18:32.420
>> 사람들이 이런 몇가지 질문을 하곤 해요.

0:18:34.110,0:18:39.410
>> 왜 손실 그래프의 최소 지점이 학습률이 더 높은데 
선택하면 안되는지 설명해 주실 수 있나요?

0:18:39.410,0:18:43.180
또, 학습률 기법이 

0:18:43.480,0:18:46.340
모든 종류의 CNN에 대해서

0:18:46.710,0:18:54.590
잘 동작하는지 궁금합니다.

0:18:58.050,0:19:03.919
(백그라운드 사운드)
옆에 남는 자리 있으면 손들어 주실래요?

0:19:10.650,0:19:15.469
왜 죄저점보다 더 낮은 학습률을 
사용해야 하는지에 대한 

0:19:15.469,0:19:21.700
학습률 발견자에 대한 질문이 있었습니다.
그리고, 학습률 발견자가 무슨 일을 하는지

0:19:22.860,0:19:26.900
이해하기 위해서,
이 그림으로 잠시 돌아가서 어떻게

0:19:28.530,0:19:35.060
어떤 학습률을 사용해야 하는지 알아보죠.
매번 특정 보폭만큼 움직이는데

0:19:35.250,0:19:38.660
각 움직임마다, 학습률을 두배 증가시킬 겁니다.

0:19:39.320,0:19:43.520
다시 말해 보자면

0:19:43.520,0:19:48.680
점점 더 약간씩 큰 보폭으로 움직이는 거죠.

0:19:49.260,0:19:51.260


0:19:51.480,0:19:53.220
좀더 크게

0:19:53.220,0:19:54.990
좀더 크게

0:19:54.990,0:19:56.700
그리고

0:19:56.700,0:20:00.470
이 과정의 목적은 최소지점을 찾느게 아닙니다.

0:20:00.840,0:20:06.949
이 과정의 목적은 빠르게 감소할 수 있게 해주는
학습률을 찾는 것입니다.

0:20:07.530,0:20:13.009
어느 지점에서 손실이 최소냐하면
여기 동그라미 친 부분이겠죠?

0:20:13.009,0:20:17.300
근데 그 지점의 학습률은 너무 커서,
막 앞뒤로 점프하게 

0:20:17.440,0:20:20.300
될 가능성이 있습니다.

0:20:20.460,0:20:29.660
그래서, 그 대신에 뭘 하고 싶냐하면 손실을 빠르게
증가시키는 학습률이 있는 지점으로 돌아가야 합니다.

0:20:30.720,0:20:37.340
지금 보시는 그래프가 매번 증가하는 학습률을 
보여줍니다. 매번이라 하면 각 미니배치 마다죠

0:20:37.420,0:20:40.840
미니배치 횟수에 대한 학습률의 변화입니다.

0:20:41.240,0:20:47.020
이 그래프는 학습률에 대한 손실의 변화입니다.
여기가 최저점이고, 이미 학습률이 너무 높은 곳이죠

0:20:47.780,0:20:52.300
그리고 이 지점이, 약간 앞으로 되돌아간 지점이고
이곳의 손실값은 빠르게 잘 증가합니다.

0:20:53.800,0:20:56.380
stochastic 경사하강법 이라는걸

0:20:56.759,0:20:58.968
잠시 후에 배우게 될 건데요, 

0:20:59.159,0:21:04.549
1e-3 지점이 사실상 더 가파르기 때문에
1e-2 대신 선택할지도 모릅니다.

0:21:04.820,0:21:07.540
이 지점에서 

0:21:07.740,0:21:09.800
더 빠르게

0:21:09.809,0:21:13.189
학습할 수도 있고, 시도해봐도 좋습니다.
하지만 왜

0:21:13.190,0:21:17.869
더 큰 수를 선택하는게, 더 나은 일반화를
가져다 주는지 잠시 후에 아시게 될거에요.

0:21:18.389,0:21:20.389
일단 이 부분은 잠시 미뤄두죠.

0:21:20.399,0:21:22.608
>> "높다"라고 말할때

0:21:23.279,0:21:26.209
>> 높은 학습률을 말한건가요?

0:21:27.059,0:21:29.059
>> 많은 반복이나 다른것 인가요?

0:21:29.849,0:21:35.809
높은 학습률을 말한겁니다. 학습률 발견자에서
반복수를 증가 시키면, 학습률이 높아지죠.

0:21:35.849,0:21:39.588
이 그래프틑 반복수에 대한 학습률의 변화에요.
이 변화에 대해서,

0:21:40.259,0:21:43.639
학습률이 증가하게 되면

0:21:44.039,0:21:48.829
손실은 감소하게 되죠. 그리고 학습률이
너무나 커지는 지점까지 도달하게 되구요.

0:21:49.080,0:21:51.199
그 지점에서는 손실값이 나빠지기 시작하죠.

0:21:51.450,0:21:57.289
>> 최저점이 1e-1 이긴 하지만, 1e-2를 선택해야
한다고 제안하셨 잖아요?

0:21:58.020,0:22:01.760
>>근데 지금 말씀하시는건

0:22:01.760,0:22:05.520
>> 왼쪽의 "높은" 방향으로 
되돌아가야 한다고 한것 같아요.

0:22:05.549,0:22:11.358
그걸 의미한건 아니에요. 죄송합니다.
더 낮은 학습률로

0:22:11.999,0:22:16.249
되돌아가야 한다고 말한 겁니다. 

0:22:17.129,0:22:21.228
>> 그러니까 낮은거라는 거죠?
네 맞습니다.

0:22:23.159,0:22:28.549
>> 지난 클래스에서, 모든 지역적 최저점들이 
동일하다고 했고

0:22:29.180,0:22:35.720
>> 이 그래프 역시 그 사실을 보여주는데요
그 사실이 관찰된 건가요? 아니면 
어떤 이론적 바탕에 기반한 건가요?

0:22:36.340,0:22:39.020
그건 이 그래프가 보여주려는게 아닙니다.

0:22:39.270,0:22:43.759
이 그래프는 단순히 학습률이 더 증가할때
더 나아지지 않는 지점이 

0:22:44.100,0:22:48.500
있다는걸 보여주고, 심지어 
더 나빠지기 시작한다는걸 보여주죠.

0:22:49.500,0:22:52.640
지역적 최저점들이 동일하다는건

0:22:53.520,0:22:55.320
완전히 다른 문제에요

0:22:55.740,0:23:00.100
완전히 다른거요. 나중에 이걸 설명하는
그림을 다시 보여드릴게요.

0:23:02.900,0:23:09.740
>> 매 에포크 마다, 기본이 되는 학습률을
찾아야만 하나요?

0:23:10.740,0:23:12.419
매 어떤거요?

0:23:12.420,0:23:14.640
>> 에포크요.
아 에포크 말이군요.

0:23:14.640,0:23:21.920
>> 학습을 진행하는 동안얼마나 많이 
학습률 발견자를 수행해야 하나요?

0:23:24.020,0:23:26.700
매우 좋은 질문입니다.

0:23:27.580,0:23:31.540
시작할때 일단 한번 수행하는건 확실합니다.

0:23:32.420,0:23:36.200
클래스 나중 부분에가면, 계층을 "unfreeze"하는 것에
대해서 배우게 될겁니다.

0:23:36.380,0:23:37.460
그리고

0:23:37.460,0:23:43.180
계층을 "unfreeze"한 후에, 학습률 발견자를 
한번 더 수행합니다. 제가 만약 학습에 관련해서

0:23:43.340,0:23:48.480
뭔가 변화를 준다면, 학습률 발견자를 
기본적으로 다시 수행해야 할 지도 모릅니다.

0:23:48.740,0:23:52.960
만약 계층을 "unfreeze" 하는 것 처럼 
학습하는 방법에 대한 뭔가를 바꾸게 되면

0:23:53.640,0:23:58.160
다음(다른) 학습이 불안정 하거나 너무 느리다는걸

0:23:58.920,0:24:03.920
알 수 있을텐데요, 그러면 이때 학습률 발견자를 다시
수행해 볼 수 있을겁니다. 이를 수행함에 있어서

0:24:04.180,0:24:07.580
해로운건 없어요. 오래 걸리지도 않고요.

0:24:08.160,0:24:10.110
좋은 질문이었습니다.

0:24:10.110,0:24:17.300
data augmentation으로 돌아가서, 
tfms_from_model을 수행할때

0:24:18.060,0:24:22.960
aug_tfms 인자의 값으로 주로 전달하는 것으로

0:24:23.820,0:24:30.320
transforms_side_on, transforms_top_down 또는
나중에 배우게 될 자신만의 transform 목록이 

0:24:31.170,0:24:36.920
될 수 있습니다. 일단 고양이와 개 사진은 측면에서
촬영된 것이어서 transform_side_on을 사용 했습니다.

0:24:37.280,0:24:42.520
각 이미지를 보게 되면, 약간의 확대/축소가 되거나
약간 위치가 이동하거나

0:24:43.000,0:24:45.880
약간 회전되거나

0:24:46.890,0:24:53.780
뒤집어져 있을 수 있습니다. data augmentaion은
완전히 새로운 데이터를 만드는 것은 아니지만

0:24:54.420,0:25:00.000
동일한 사진을 바라보는 다른 방식들을 의미합니다.
CNN이 관심있어하는 방식으로, 사실상

0:25:00.500,0:25:04.460
고양이와 개를 인식하는법의 학습을 가능하게 해주죠

0:25:05.130,0:25:11.690
누군가가 data augmentation이라고 하면, 
문제의 특정 분야 지식에 기반해서

0:25:13.350,0:25:20.000
같은 이미지를 조작할 수 있는 다른 방법들을 의미합니다. 
사람이 볼땐, 동일한 이미지 이지요.

0:25:20.000,0:25:24.260
그리고 조작된 이미지는 현실 세계에서도
존재할 것이라고 기대될 수 있어야 합니다.

0:25:25.830,0:25:30.710
그러면, 지금부터 우리가 할 수 있는건
from_path 메소드에서

0:25:30.710,0:25:37.279
tfms 인자로 transforms의 목록들을 전달하는 것입니다
이 목록이 곧 data augmentation의 방법들이구요

0:25:37.950,0:25:39.950


0:25:41.400,0:25:46.020
그리고나서, 우리가 수행하는건 fit 이 됩니다.

0:25:47.160,0:25:49.360
초기에는

0:25:49.840,0:25:57.060
data augmentation은 초기엔 아무것도 하지 않습니다.
왜냐하면, pretrained 메소드의 precompute의 값을

0:25:57.400,0:26:02.240
True로 설정했기 때문입니다. 마찬가지로
앞으로 여러번 이것에 대해서 이야기 하게 될겁니다.

0:26:03.160,0:26:09.500
이 값이 의미하는걸 설명하기 위해서,
전에 각 계층이 학습하는것을 시각화한 사진을 보셨죠?

0:26:10.520,0:26:14.900
왼쪽에 있는 활성화된 파라메터가 오른쪽의
꽃에서 부터

0:26:16.380,0:26:19.420
조류의 눈이라던지

0:26:19.430,0:26:24.339
찾는데요, 무슨일이 일어났던 걸까요?

0:26:25.550,0:26:32.889
CNN의 나중 계층들은 "activation(활성화)"라고 
불리는 것들이 있는데, 활성화의 의미는

0:26:32.890,0:26:37.689
어떤 숫자입니다. 이 숫자는 조류의 눈과 같은

0:26:38.840,0:26:44.680
특징이 이 위치에 존재할 확률에 대한
신뢰도를 보여줍니다.

0:26:44.960,0:26:48.610
나중에 이 내용을 많이 보게 되겠지만

0:26:49.520,0:26:52.869
미리 학습된 네트워크를 가지고 있을때

0:26:53.330,0:26:58.689
미리 학습되었다는건, 이미 뭔가를 인식하기 위해서
학습되었다는 것이죠. 

0:26:58.880,0:27:04.630
이 예제에서는 ImageNet 데이터셋에 있는
150만개의 이미지를 인식하기 위해 학습되었고요

0:27:04.630,0:27:09.360
그러면 이때 우리가 할 수 있는건
사물이 뭔지를 알아내기에 모든 충분한

0:27:10.020,0:27:14.020
정보를 가지고 있는
마지막에서 두번째인 계층에 대한

0:27:14.020,0:27:20.770
activation을 저장하는 것입니다.
여기서 저장한다는건

0:27:20.770,0:27:25.810
모든 이미지에 대하여 
조류의 눈, 강아지 얼굴, 또는 푹신한 귀등과 같은
것에 대한 

0:27:26.240,0:27:31.479
단계의 activation들을 저장한다는 의미 입니다.

0:27:32.270,0:27:35.739
우리는 이것들을 흔히 미리 계산된 
activations 이라고도 부르죠

0:27:35.740,0:27:41.020
우리가 새로운 분류 모델을 생성하려고 할 때

0:27:41.510,0:27:45.489
기본적으로 이 미리 계산된 activation의 
이점을 활용할 수 있는데

0:27:46.040,0:27:52.689
많은 내용이 이미 저장되어 있어서, 아주 빠르게
학습할 수 있게 됩니다. 이것에 기반하면

0:27:53.240,0:27:57.199
간단한 선형적 모델을 아주 빠르게 학습 시킬 수 있습니다.
설명드린게 precompute을 True로 

0:27:57.200,0:28:04.549
설정 했을때 발생하는 일입니다. 눈치 채셨겠지만
이번주에 처음으로, 새로운 모델을 돌렸어도

0:28:04.889,0:28:07.008
1~2분만 소요된 이유죠.

0:28:07.590,0:28:10.519
제가 돌렸을때는 5~10초정도 걸렸었구요.

0:28:10.620,0:28:13.939
여러분은 activation들의 precompute를 
수행해야 해서 1~2분 걸렸던 겁니다.

0:28:14.789,0:28:20.209
본인 컴퓨터나 AWS를 사용하면, 
precompute 는 한번만 수행되면 됩니다.

0:28:20.249,0:28:22.249
한번만 말입니다.

0:28:22.470,0:28:26.869
만약 Crestle을 사용하고 계신다면,
매번 Crestle을 다시 실행할때 마다 

0:28:27.330,0:28:31.610
매번 precompute를 수행해줘야 합니다.

0:28:32.399,0:28:34.309
미리 계산된 activation에 대해서

0:28:34.309,0:28:39.739
crestle은 어떤 특별한 공간을 사용하는데,
crestle이 재실행 될때마다 사라지는 특징이 있습니다

0:28:40.200,0:28:44.869
crestle과 같은 특별한 경우가 아니라면,
일반적으로 특정 데이터셋에 대해서 한번만

0:28:45.389,0:28:47.449
수행되면 됩니다.

0:28:49.110,0:28:54.019
이 부분에 대한 문제점은
각 이미지에 대해서 precompute를 사용하기 때문에

0:28:54.720,0:28:58.960
여기의 얼마나 많은 부분이 귀이며
저기의 얼마나 많은 부분이 도룡뇽의 눈이 

0:28:59.280,0:29:05.090
있는지등에 대해서 data augmentation이 
잘 동작하지 않을 것이라는 겁니다. 다시 말해보면

0:29:05.090,0:29:11.809
매번 다른 버전의 고양이 이미지를 보여줄텐데, 어떤 특정 버전의 고양이만의 activation이 미리 계산됩니다.

0:29:12.749,0:29:17.868
data augmentation을 사용하기 위해서는
단순히 learn.precompute의 값을 False로 설정하면 됩니다.

0:29:18.419,0:29:20.929
그리고나서몇번의 추가 에포크를 

0:29:21.720,0:29:23.129
수행하면 되죠.

0:29:23.129,0:29:27.469
보다시피, 더 많은 에포크를 수행함에 따라서

0:29:28.049,0:29:33.799
정확도가 딱히 더 좋아지지 않는걸 알 수 있습니다.
별로 좋은 소식은 아니지만, 다른 좋은 소식은

0:29:34.679,0:29:37.189
모델의 에러를 측정하는 방법인

0:29:37.710,0:29:41.720
학습 손실이 줄어들어서 좋아진다고 
볼 수 있다는 것입니다.

0:29:41.720,0:29:46.249
하지만, 검증 에러는 줄어들이 않아서

0:29:46.649,0:29:51.649
과적합이 발생하지도 않는 상황입니다.
과적합은 학습 손실이 검증 손실보다 훨씬 

0:29:52.110,0:29:58.039
낮다는 것이고, 코스 진행동안에 이에 대해서
엄청나게 많이 이야기 하게 될 것입니다.

0:29:58.039,0:29:59.009
어쨌든

0:29:59.009,0:30:02.059
학습 데이터셋에 대해서

0:30:02.220,0:30:07.069
검증 데이터셋 보다 훨씬 잘 동작한다면, 
모델이 일반화되지 않았다는 의미라는 거죠.

0:30:07.780,0:30:12.389
이 예제에서는 그런 상황이 발생하지 않았고, 좋은 상태
입니다. 하지만 많은 향상이 이루어지지도 않았어요.

0:30:13.300,0:30:16.289
그래서 이 문제를 다룰 방법을 생각해 내야만 하고요.

0:30:16.860,0:30:21.680
그러기 전에 먼저, 한가지 멋진 요령을
알려드리겠습니다.

0:30:21.920,0:30:24.240
cycle_len을 1로 설정하는 건데요

0:30:24.400,0:30:26.800
이건 이것대로 또 매우 흥미로운 내용입니다.

0:30:27.900,0:30:30.460
그게 뭐냐하면

0:30:30.460,0:30:32.579
cycle_len을 1로 설정하게 되면

0:30:33.250,0:30:40.800
딥러닝에 사용된 가장 최근에 발견된 
stochastic 경사하강을 재시작하게 됩니다.

0:30:41.440,0:30:42.760
최저점에

0:30:42.760,0:30:47.849
점점 더 점점 더

0:30:48.520,0:30:50.520
가까워 질수록

0:30:51.850,0:30:58.020
학습률을 줄여나가고 싶을거에요.
왜냐하면, 최저점에 가까워지기 시작하면

0:30:58.020,0:31:05.129
보폭을 줄여서 정확히 그 지점에
도달하길 원할 테니까요.

0:31:05.460,0:31:09.660
그래서, 학습을 진행하면 할수록

0:31:12.020,0:31:14.020
학습률은

0:31:14.320,0:31:16.740
아마도 점점 감소하게 될겁니다.

0:31:16.880,0:31:21.680
왜냐하면 정확히 원하는 최저점이라는
지점에 점점 더 가까이

0:31:21.820,0:31:24.260
도달하려고 하기 때문이죠.

0:31:24.260,0:31:29.940
학습이 진행되는 동안 학습률을 줄여나가는
이 발상은 annealing(냉각)

0:31:29.940,0:31:32.080
이라고 불리는데

0:31:32.080,0:31:35.820
아주아주 일반적이고, 아주아주 인기있는 방식입니다.

0:31:36.590,0:31:39.160
모든사람이 항상 사용한다고 볼 수 있을 거에요.

0:31:39.920,0:31:42.519
가장 일반적인 종류의 학습률 annealing은

0:31:43.400,0:31:50.050
소름끼치게 진부합니다. 기본적으로 
한동안 잘 동작할 것 같은 학습률을 선택합니다.

0:31:50.050,0:31:54.009
그리고나서, 학습이 더이상 잘 안되면
학습률을 10배 줄입니다.

0:31:54.010,0:31:58.809
이런식으로 학습률을 10배씩 더 줄여나가는데,
더이상 아무런 향상도 없을때 까지 반복 합니다.

0:31:59.200,0:32:05.360
대부분의 대학 연구 논문이나, 산업에 종사자들이
사용하는 방법이에요. 단계적인 annealing을 수작업으로

0:32:05.520,0:32:09.340
수행하는건데, 좀 짜증나는 방식이죠.

0:32:09.520,0:32:15.280
더 나은 접근방법은 단순히 직선과 같은 어떤 
함수적인 형태를 선택하는 것입니다.

0:32:16.010,0:32:20.650
정말 좋은 함수의 형태는 
코사인 함수 절반의 형태라는게 드러났죠.

0:32:22.710,0:32:27.319
최저점에 전혀 가깝지 않을때는

0:32:27.320,0:32:30.650
큰 학습률의 값이 설정되어 있을테고
그리고, 최저점에 아주 가까워질때

0:32:30.650,0:32:36.220
재빨리 학습률을 아주 낮은 학습률로 줄여서,
최저점까지 적은 수의 반복으로 내려가게 됩니다.

0:32:36.540,0:32:38.540
이 방법이 코사인 annealing 이라고 합니다.

0:32:38.900,0:32:45.460
삼각법을 공부한지 좀 지난 분들이 계시다면
코사인이란 기본적으로 이렇게 생긴 그래픕니다.

0:32:46.000,0:32:49.040
그리고 여기서, 반쪽의 영역이 되는거죠

0:32:49.440,0:32:53.280
우리는 코사인 annealing을 사용하게 될 겁니다.

0:32:54.570,0:32:56.570
근데 우리의 문제가

0:32:56.730,0:32:58.730
매우 고차원적인 공간의 것이라면

0:32:59.480,0:33:04.260
이 그림은 단지 3차원 형태만 보여드리긴 하지만

0:33:04.380,0:33:08.120
현실적으로 수백만 차원의 공간이 존재한다는걸
알고 계시길 바랍니다.

0:33:08.120,0:33:09.660
이 예제에서 보면

0:33:09.660,0:33:11.420
많은 수의

0:33:11.430,0:33:18.400
평평한 지점이 있습니다. 지역적 최소점은 아니지만,
꽤나 평평해서 좋아 보이는 지점이 있습니다.

0:33:18.540,0:33:23.200
그런데 이 평평한 지점들이 흥미로운것은
약간 다른데 있는데요

0:33:23.200,0:33:32.800
잠시만요, 보여드릴게요

0:33:32.860,0:33:39.960
제가 그리는 그래프처럼 생긴 표면이 있다고
일단 상상해 봅시다.

0:33:39.960,0:33:46.160
그리고 무작위로 시작지점을 오른쪽 위로
정했다고 상상해 봅시다.

0:33:46.940,0:33:51.380
그러면, annealing 스케줄에 의해서, 초기 학습률이
여기 아래로 내려가게 됩니다.

0:33:51.460,0:33:53.300
그리고 이때

0:33:53.300,0:33:59.230
꽤 좋아보이는 낮은 에러 지점입니다.
근데 문제는 일반화가 잘 안된다는 점입니다.

0:33:59.230,0:34:05.529
왼쪽/오른쪽 방향에 대해서 약간만 다를 수 있는
만약 다른 종류의 데이터셋을 사용한다면

0:34:06.340,0:34:10.380
갑자기 최악의 해답이 나오게 됩니다.

0:34:10.700,0:34:12.940
반면에 왼쪽 하단 지점은 기본적으로

0:34:13.020,0:34:15.159
손실에 대해서 동등하게 좋습니다.

0:34:15.159,0:34:20.829
그리고 여기서는 약간 다른 데이터셋이 대상이 되어도
여전히 좋은 해답이 나오게 되죠.

0:34:20.860,0:34:27.560
다시 말하면, 우리가 원하는건 왼쪽 하단의 해답입니다.
이 해답이 다른쪽의 녀석보다

0:34:27.560,0:34:31.400
일반화가 더 잘되었다고 볼 수 있는거죠.

0:34:31.400,0:34:38.020
그러면 이제 우리가 해야할 일을 말씀드리죠.
여기 보시면 여러개의 죄저 지즘이 있습니다.

0:34:39.200,0:34:45.099
그리고 표준적인 annealing 접근법은 점점 언덕의 
아래로 아래로, 최종적으로 한 지점으로 빠집니다.

0:34:45.700,0:34:50.400
근데, 대신에 우리는 학습률 스케줄이라는 것을
사용할 수 있습니다.

0:34:50.440,0:34:53.640
여기 보시는 그래프 같은 거에요.

0:34:53.690,0:34:59.200
코사인 annealing을 한 후 갑자기 다시 위로 점프, 
또 다시 코사인 annealing, 그리고 점프를 보여줍니다.

0:34:59.530,0:35:03.969
매번 위로 점프한다는건
만약 뾰족뾰족한 지점이 있다면

0:35:03.970,0:35:08.800
갑자기 학습률을 증가시켜서
완전히 다른 지점으로 점프시킨다는걸 말합니다.

0:35:09.470,0:35:12.459
그리고나서 다시 annealing되어 이동하게 되죠.
이때 또 다시 높은 학습률로

0:35:12.460,0:35:15.099
점프하게 되는데 이때는

0:35:15.859,0:35:19.299
여기에 머물게 됩니다.
매번 위쪽의 학습률로 점프하는건

0:35:19.300,0:35:24.729
만약 표면에 뾰족뾰족한 부분이 있다면

0:35:24.740,0:35:28.420
그 뾰족한 부분을 뛰어 넘어넘는단 말이죠
이 것을 충분히 많이 반복하면 희망적으로

0:35:28.600,0:35:31.380
좋고 부드러운 그릇의 안쪽(최저점)을

0:35:31.580,0:35:35.640
최종적으로 발견하게 될 것입니다.

0:35:40.560,0:35:45.380
>> 서로다른 시작지점에 대해서, 여러번
반복하면 동일한 효과를 기대할 수 있나요?

0:35:45.600,0:35:50.340
>> 최종적으로 모든 가능성이 있는 최저점들을 
탐색할 수 있으니까요?

0:35:50.620,0:35:53.400
매우 좋은 질문이에요

0:35:53.880,0:35:55.660
설명드린 방식인

0:35:56.200,0:35:58.760
재시작하는 stochastic 경사하강
(stochastic gradient descent with restarts)

0:35:59.020,0:36:00.860
이전에

0:36:01.440,0:36:05.060
만들어진건데요.

0:36:05.740,0:36:10.560
그게 정확히 말씀하신 방법이었죠. 
완전히 새로운 모델을 여러번 다시학습하는 방식의

0:36:12.300,0:36:18.980
앙상블(ensemble)이라는 것들을 만들었습니다.
그 모델 중 하나가 더 나아지길 기대하면서요

0:36:21.760,0:36:27.880
재시작하는 stochastic 경사하강의 멋진점은
일단 모델이 좋은 지점에 위치하게 되면

0:36:27.880,0:36:30.820
학습률값을 매번 점프해도

0:36:30.820,0:36:34.680
재시작하는게 아니라, 사실상 그 좋은 지점에 
머물게 된다는 겁니다. 

0:36:34.900,0:36:37.260
그리고 나서는 계속해서 좋아지게 됩니다.

0:36:37.420,0:36:40.740
여러번의 분리된 코사인 annealing을 수행하는
방법을 통해서

0:36:41.220,0:36:46.120
무작위로 몇 다른 시작 지점에 대해서
시도하는것 보다

0:36:46.760,0:36:51.780
결국에는 더 좋은 결과를 얻게 됩니다

0:36:52.360,0:36:56.520
아주 깔끔한 비법이죠. 그리고 상당히

0:36:56.700,0:36:59.100
최근에 개발된 것이지만

0:36:59.110,0:37:02.080
역시나 대부분 사람들이 잘 모릅니다.

0:37:02.800,0:37:04.800
근데 제 생각엔

0:37:05.100,0:37:10.960
이것과 학습률 발견자를 같이 사용하면
제가 일종의 수퍼파워를 얻은거 같다는 거에요.

0:37:11.280,0:37:16.740
일반적인 경연에 있어서, 제가 거의 항상
다른 누구보다도 좋은 결과를 얻습니다.

0:37:21.580,0:37:26.780
다시 돌아가서 설명 드리면
이게 왜 제가 

0:37:27.460,0:37:33.340
가장 가파른 지점을 선택하지 않은 이유입니다.
실제로는 좀더 높은 공격적인 부분을 선택하는거죠

0:37:33.340,0:37:34.860
여전히 내려가지만

0:37:34.860,0:37:37.679
아주 높은지점에 근접한 지점을 향해서 
내려가는 곳이죠.

0:37:37.960,0:37:40.919
재시작하는 stochastic 경사하강법을

0:37:42.130,0:37:48.119
수행할때, 이 지점 1e-2는 

0:37:48.820,0:37:54.299
이 그래프에서 가장 높은 값과 같습니다.
1e-2까지 올라갔다가, 그리곤 내려가죠.

0:37:54.580,0:37:59.460
다시 1e-2까지 올라갔다가 내려가고요.
만약 너무 작은 학습률을 사용하면,

0:37:59.460,0:38:03.509
함수의 다른 지점으로 점프가 되지 않습니다.

0:38:05.950,0:38:11.819
>> 몇가지 질문이 있습니다. 첫 번째는 
얼마나 많이 학습률을 바꿔야 하나요?

0:38:12.610,0:38:15.180
(잘못 말함)

0:38:15.180,0:38:18.659
여기 아래로 내려가는 부분에 대해서

0:38:18.660,0:38:26.339
매 미니배치때 마다, 학습률을 변경합니다.
그리고 학습률을 다시 초기화하는 횟수는 

0:38:27.190,0:38:31.559
cycle_len 파라메터에 의해서 설정됩니다.
값이 1이면, 매 에포크마다 초기화 한다는 의미입니다.

0:38:32.110,0:38:36.450
만약 값이 2라면, 매 두번의 에포크 마다
학습률을 초기화 하게 되는 것이죠

0:38:36.520,0:38:42.180
매 미니배치마다 사실상 학습률을 변경하는데

0:38:42.430,0:38:44.380
이게 동작할 수 있게하는데

0:38:44.380,0:38:51.599
아주 중요합니다. 다시 말씀드리지만,  이 방법은 
연구실이나 산업 종사자들이 해오던 것과 매우 다르죠

0:38:53.460,0:38:59.760
>> recompute이 True인 것을 
다시 설명해 주실 수 있나요?

0:39:00.140,0:39:02.820
네, 근데 그 부분은

0:39:03.220,0:39:07.680
코스 진행동안 수차례 계속 보게 될 겁니다.
이 코스가 운영되는 방식은, 일단 높은 수준에서

0:39:08.080,0:39:13.259
내용을 바라보게 됩니다. 그리고 나서 두세번의
 레슨 후에 다시 공부하는 것입니다.

0:39:13.260,0:39:18.239
그리고 코스 마지막에 그 내용을 재방문 하고,
매번 재방문 할때마다, 더 많은 수학과 코드와 함께

0:39:18.240,0:39:21.570
더 깊이 있게 바라보게 되죠.
또 관련해서 커뮤니티 포럼에서도 이야기 하고요.

0:39:27.040,0:39:32.320
>> 우리의 목표는 일반화이고, 음..
좁은 최저점에 도달하길 원하는건 아니죠?

0:39:32.460,0:39:37.020
요약 잘하셨습니다.
>> 이 방식에서, 최저점과 평균 지점들을 

0:39:37.020,0:39:40.680
>> 계속 추적하는 건가요?

0:39:41.260,0:39:43.260
말씀하신건 

0:39:43.300,0:39:48.060
또 다른 수준의 상세한 내용인데요,
오른쪽 그림을 보시면, snapshot ensemble

0:39:48.320,0:39:51.580
이라고 적힌 곳이 있습니다.
지금 당장 이것관련 코딩을 하진 않을거지만

0:39:51.720,0:39:54.560
말씀하신게 맞아요. 만약 일반화를 
더 잘하고 싶으면

0:39:54.880,0:40:01.369
아래 부분의 가중치(weights) 값들을 저장하고
이들의 평균을 구할 수 있겠죠.

0:40:01.820,0:40:06.620
하지만, 일단 지금의 우리는 
마지막 것만을 취할 겁니다.

0:40:07.920,0:40:12.560


0:40:14.100,0:40:18.360
약간 건너뛰어서 공부하실거면
cycle_save_name 이라는 파라메터가 있을겁니다.

0:40:19.470,0:40:24.290
이걸 사용하면, 매 학습률 사이클의 마지막 마다

0:40:25.040,0:40:29.600
그 부분의 가중치를 저장하게 됩니다. 
그러면 그 값들을 가지고 ensemble 할 수 있겠죠.

0:40:31.820,0:40:33.820


0:40:34.200,0:40:36.200
우리가 만든 모델은

0:40:36.359,0:40:40.129
꽤나 괜찮은 것으로, 99.93%의 정확도를 보여줍니다.

0:40:40.740,0:40:45.220
그리고 아시다시피 
약 1~2분 정도 걸리는 작업을 했습니다.

0:40:45.460,0:40:47.140
그리고 가끔씩

0:40:47.150,0:40:51.290
가중치를 저장하는 경향이 있습니다.
learn.save() 메소드에 파일이름을 넣어주시면

0:40:51.900,0:40:56.210
가중치를 저장해 줍니다. 그리고 나중에
learn.load() 메소드를 이용해서 이 가중치가

0:40:56.640,0:41:01.680
저장된 시점으로 돌아갈 수 있습니다.
가끔씩 이 작업을 수행하는건 좋은 생각인데요

0:41:02.000,0:41:05.060
이 작업을 수행할때
무슨일이 일어나는지

0:41:05.360,0:41:07.760
말씀드리기에 좋은 때인것 같군요.

0:41:08.100,0:41:15.700
learn.save()나, 미리 계산된 activations을 생성하거나,
크기가 변경된 이미지를 생성하는등의 작업들은

0:41:15.900,0:41:19.310
다양한 임시성 파일들을 생성해 냅니다.

0:41:20.080,0:41:23.880
그래서, 어떤일이 일어나느냐 하면

0:41:24.420,0:41:27.160
data 폴더로 

0:41:27.560,0:41:29.560
들어가서

0:41:30.210,0:41:32.210
dogscats 폴더로 이동하면

0:41:32.520,0:41:36.880
여기가 데이터가 저장된 폴더인데요, 
이 폴더 안에 보시면 "tmp"라고 된 폴더가 

0:41:37.260,0:41:39.800
있습니다.

0:41:40.200,0:41:45.480
이 폴더는 자동으로 생성되고,  모든 미리계산된 
activations들이 여기에 보관됩니다.

0:41:45.740,0:41:48.240
이걸 말씀드리는 이유는

0:41:48.540,0:41:56.380
뭔가 이상한 에러를 만나게 되면, 이는
미리계산된 activations이 절반 정도만 완료된

0:41:56.609,0:41:57.869
경우라던지

0:41:57.869,0:42:03.679
뭔가 충돌이 발생했기 때문입니다.
그때는 이 tmp 폴더 자체를  

0:42:04.100,0:42:08.660
삭제하고, 그 에러들이 사라지는지 한번
시도해 보세요.

0:42:08.960,0:42:12.840
fastai를 껏다가 키는것과 동일하다고 
보시면 됩니다.

0:42:13.200,0:42:19.160
그리고 models이라는 폴더가 있는것도
보실 수 있을 텐데요,

0:42:13.200,0:42:19.159
그리고 models이라는 폴더가 있는것도
보실 수 있을 텐데요,  모델에 대해서 .save()를 

0:42:19.160,0:42:21.820
수행하면 저장되는 곳입니다.

0:42:22.020,0:42:26.080
재시작하는 stochastic 경사하강법
논문이 발표 됐을때를 상기켜 주는군요

0:42:26.080,0:42:32.300
누군가가 트윗하기를, 딥러닝이 더 잘 동작하게
하려면 껐다가 다시 켜라 라고 한걸 봤어요 ㅎ

0:42:33.180,0:42:35.180
질문이군요

0:42:36.360,0:42:43.640
>> (잘 안들림)

0:42:48.600,0:42:52.140
맨 처음부터 모델을 학습시키길 원한다면

0:42:52.520,0:42:58.980
일반적으로 미리 계산된 activations을 지워야 할
이유는 없습니다. 왜냐하면 이 activations는

0:42:59.540,0:43:03.160
어떤 학습도 없는 것이니까요. 그게 바로
미리 계산된 모델이 

0:43:03.480,0:43:08.200
인터넷에서 다운로드한 가중치(weights)를
가지고, 생성되었다는 것을 의미합니다.

0:43:08.460,0:43:11.180


0:43:11.310,0:43:17.390
미리계산된 activations을 삭제할 단 한가지 이유는
불완전한 생성에 의한 에러가 발생해서

0:43:17.910,0:43:21.049
모델 생성이 실패하거나

0:43:21.360,0:43:26.540
입력의 크기를 바꾸거나, 아키텍쳐의 형태를
바꾸거나 하면, 이런 행위는 모두 다른 종류의

0:43:26.760,0:43:29.080
activations을 다른 파일에 생성합니다.

0:43:29.300,0:43:31.300
근데 일반적으로 별로 걱정 안해도 됩니다.

0:43:31.770,0:43:36.199
완전히 처음부터 모델을 다시 학습시키고 싶을때,
해야할 단 한가지는

0:43:37.980,0:43:43.219
learn 객체를 만드는 겁니다. 예를 들어서
ConvLearner.pretrained 가 새로운 learn 객체를 

0:43:43.500,0:43:46.669
새로운 종류의 가중치를 가지고 
생성하게 됩니다.

0:43:49.140,0:43:50.460


0:43:50.460,0:43:54.400
잠시 쉬어가기 전에, 미세 조정과 
차등 학습률에 대해 이야기에 대한 것을

0:43:54.540,0:43:58.220
마무리 지을 겁니다.

0:43:59.040,0:44:01.040
지금까지

0:44:02.420,0:44:04.940
우리가 한 모든 것은

0:44:04.950,0:44:12.559
여기 보이는 이미 학습된 필터의 내용을 전혀
바꾸지 않았습니다. 이미 학습된 모델을 사용해서

0:44:14.850,0:44:16.850
초기 계층에서는

0:44:17.010,0:44:18.900
모서리나 그라데이션

0:44:18.900,0:44:21.600
그리고 다음 계층에서는, 모퉁이나 커브

0:44:21.900,0:44:24.660
그리고 다음 계층에서는, 반복적인 문양과

0:44:24.960,0:44:27.940
몇몇 글자들, 
그리고 마지막 계층에 도달해서는

0:44:28.380,0:44:31.740
눈알에 대한 필터를 그대로 가져가는 것입니다.

0:44:32.260,0:44:35.060
이 필터의 어느 activations/특징도

0:44:35.369,0:44:37.369
재학습의 대상이 아닙니다.

0:44:37.650,0:44:43.789
정확히는 CNN 커널에 있는 가중치(weights) 입니다.
우리가 한 모든 것은, 이 존재하는 것들 위에

0:44:44.400,0:44:49.420
추가된 새로운 계층들을 학습했다는 것이죠.
미리 학습된 특징들과 어떻게 섞고 

0:44:49.580,0:44:52.280
끼워맞추는지에 대한
방법을 배웠습니다.

0:44:52.560,0:44:56.040
여러분 자신만의 데이터(이미지)에는

0:44:56.460,0:45:01.220
다른 종류의 논알이나 얼굴이 있을 것이
당연합니다.

0:45:01.220,0:45:04.909
또는 완전히 다른 위성 이미지 같은 것을
사용하게 되면

0:45:05.220,0:45:10.309
완전히 다른 종류의 특징들이 함께 있게 됩니다.
예를 들어서, 빙산을 인식하기 위해서 

0:45:10.920,0:45:14.720
학습을 시킨고자 한다면, 처음으로 돌아가서

0:45:14.960,0:45:19.560
여기 보이는 간단한 그라데이션이나 모서리
같은 것들의 다른 조합을 학습해야 할 것입니다.

0:45:20.140,0:45:23.020
고양이와 개라는, 
우리가 다루는 예제 에서는

0:45:23.600,0:45:28.900
크게 중요하지 않은 차이점을 가지겠지만, 여전히 
그런 것들이 발견 될 겁니다. 그래서, 후반부의

0:45:29.020,0:45:31.840
계층들을 약간 조정(튜닝)하면,
꽤나 도움이 될 수 있겠죠.

0:45:32.180,0:45:39.280
learner에게 CNN의 필터를 바꾸고 싶다는걸
알려주기 위해서 해야할 일은

0:45:40.280,0:45:45.340
단순히 "unfreeze" 하는 것입니다. 
frozen(얼어붙은) 계층이라는건 학습되지 않아서 

0:45:45.440,0:45:47.440
업데이트가 되지 않는 계층이라는 말입니다.

0:45:47.540,0:45:50.000
그래서, 모든 계층을 "unfreeze() 해동"
해야 하는 것이죠.

0:45:50.880,0:45:55.040
한번 생각해 보시면,

0:45:55.040,0:45:57.420
대각선이나 그라데이션 같은 것에 대한

0:45:57.420,0:46:00.139
첫번째 계층이

0:46:01.170,0:46:07.549
많이 바뀔 필요는 없을 것입니다. ImageNet의
150만장의 이미지를 통해서

0:46:07.549,0:46:10.849
꽤나 충분히 대각선이나 그라데이션을
찾아내는 방법을 터득 했을 테니까요.

0:46:10.920,0:46:17.629
마찬가지로, 어떤 종류의 모서리나 곡선을
찾아낼 수 있는지 이미 알고 있겠죠.

0:46:17.680,0:46:22.220
다시 말해서, 이런 초기의 계층들은
필요한 경우에 한해서, 아주 약간의 학습들만이

0:46:22.360,0:46:24.539
필요한 것입니다.

0:46:24.540,0:46:29.680
반면에 후반부의 계층은 좀 더 학습이 많이
필요 할 것입니다. 이런 사실은 그 대상이

0:46:30.300,0:46:35.380
위성사진에서 열대숲이나 빙산을 찾는 문제든
사진에서 고양이나 개를 찾는 문제든지간에

0:46:35.660,0:46:38.260
보편적으로 맞는 내용 입니다.

0:46:38.900,0:46:42.820
그러면, 우리가 해야할 일은
학습률들이 담긴 배열을 생성하는 것인데요

0:46:43.680,0:46:50.640
마지막의 학습률은 미리 학습된 계층들 위에 
우리가 추가한 계층에 대한 것이고

0:46:51.060,0:46:55.159
중간의 학습률은, 중간에 존재하는
계층들에서 사용될 것이고

0:46:55.160,0:46:59.380
처음의 학습률은 초반 몇개의 레이어에서
사용됩니다.

0:46:59.380,0:47:03.600
다시 말하자면, 첫번째 학습률은 매우 간단한
기하학적인 특징(선/곡선)을 표현하는

0:47:03.780,0:47:08.720
계층에 대한 것이고, 두번째 학습률은 
정교한, 좀 더 복잡한 나선형태의 특징의

0:47:09.179,0:47:16.249
계층에서 사용됩니다. 그리고 마지막 학습률은
우리가 추가한 계층이 학습할 특징들에 대한 것입니다.

0:47:16.380,0:47:20.160
그러니까 학습률들을 담은 배열을 
생성할 수 있고,

0:47:20.400,0:47:26.400
fit() 메소드를 호출할때, 그 학습률의 배열을 
전달하면 됩니다. 그러면 모델의 다른 부분에 대해서

0:47:26.400,0:47:29.660
서로 다른 학습률을 사용하게 되는 거죠.

0:47:29.660,0:47:32.460
보여드린 것은 저희가 

0:47:32.460,0:47:34.820
발명한건 아니지만

0:47:34.820,0:47:40.200
역시나 보편적인 방법은 아니라서,
아직까지 어떤 이름도 붙여지지 않았습니다.

0:47:40.480,0:47:43.520
우리는 이 방법을 
차등 학습률 이라고

0:47:43.520,0:47:45.840
부르게 될 것 입니다.

0:47:46.020,0:47:51.200
만약 이 방법에 이름이 있거나, 누군가가 이것에
특화된 내용을 다루는 논문을 쓴적이 있는지

0:47:51.200,0:47:52.860
잘 모르겠습니다.

0:47:52.860,0:47:54.360
위대한 연구자인

0:47:53.669,0:47:58.860
Jason Yosinski라는 사람이 있는데, 
이 생각과 비슷한 내용의 논문을 적은적이 있습니다.

0:47:59.140,0:48:02.660
다른 학습률들을 설정하길 원하는 상황에 대한 내용이었죠.

0:48:02.980,0:48:07.340
근데 제 생각엔, 다른 어떤 라이브러리도
아직까지 이 내용을 지원하지 않습니다.

0:48:08.820,0:48:13.360
unfreeze한 다음,  차등의 학습률들을 사용하는
방법에 대해서

0:48:13.360,0:48:20.520
꽤나 좋은 모델을 만들어내기 위한 비법이라는 사실을
발견했다고 저는 생각합니다.

0:48:24.960,0:48:27.700
>> 이해를 명확하게 하기 위해서 말인데요

0:48:28.160,0:48:33.940
>> 여기 세개의 하이퍼파라메터 숫자들이 있는데,
그 중 첫번째가

0:48:34.860,0:48:38.680
>> 이전 계층에 대한 거라는 건가요?

0:48:40.040,0:48:41.699


0:48:41.700,0:48:46.820
대답을 해드리면, 여러개의 계층입니다. 이 계층들이
그룹으로 묶여 있다고 생각하시면 되요.

0:48:46.920,0:48:49.880
나중에 ResNet 이라고 불리는 아키텍쳐에 대해서
배우게 될 텐데요, 

0:48:49.880,0:48:51.960
이 계층 그룹이 일종의 ResNet에 사용되는
블록 입니다.

0:48:51.960,0:48:56.300
그러니까 블록들(계층들)을 세 개의 그룹으로
모으는 것을 한 것이고

0:48:56.520,0:49:01.440
이 첫번째 숫자는 가장 앞단에 위치한
계층들을 위한 것입니다.

0:49:03.640,0:49:09.269
모서리나, 선, 그라데이션 같은 것을 표현하는
픽셀(데이터)에 가장 가까운 계층들이에요.

0:49:09.940,0:49:17.339
>> 그런데, 최초에 그 계층들은 "frozen" 되어있지 않나요?
맞아요, 그래서 unfreeze 했었죠.

0:49:17.339,0:49:20.758
>> unfreeze 하고나서,  부분적으로 학습을 시키잖아요?

0:49:21.910,0:49:28.319
우리가 추가한 계층들을 학습 시켰었죠.
>> 그리고 지금은, 전체 계층을 다시 학습 시키는 거죠?

0:49:29.049,0:49:33.538
>> 여기서 초반의 계층들에 대한 학습률은
특히나 작은거 같아 보여요.

0:49:33.539,0:49:39.359
맞습니다. 이 계층들에 대해서는 심지어 
아무런 변화(학습)도 원하지 않을지도 모릅니다.

0:49:40.089,0:49:43.169
근데, 만약 해야한다면, 할 수 있다는 거죠.

0:49:43.960,0:49:45.960
>> 고맙습니다.
별말씀을요!

0:49:48.759,0:49:53.009
>> 차등의 학습률을 사용하는게 
그리드 탐색(grid search)와 어떻게 다른거죠?

0:49:55.119,0:50:01.048
그리드 탐색과 비슷한 점은 없습니다. 그리드 탐색은
최고의 하이퍼 파라메터를 찾기 위한 것이에요.

0:50:01.869,0:50:06.568
예를 들어서, 학습률 발견자를
정밀한 한 종류의 그리드 탐색이라고

0:50:07.720,0:50:13.860
생각해 보실 수 있습니다. 왜냐하면 학습률 발견자는 
많은 학습률들 시도하고 그 중 최고를 찾으니까요.

0:50:14.520,0:50:17.780
근데 차등 학습률은 그리드 탐색과는
완전히 무관합니다.

0:50:17.820,0:50:24.180
차등 학습률은 학습 전체에 대한것이고, 
각각의 계층에 대해서 다른 학습률을 사용한다는 겁니다.

0:50:28.980,0:50:36.440
>> 이미 학습된 모델을 사용할때, 
이 모델의 입력으로는 

0:50:37.060,0:50:41.539
>> 동일한 차원의 데이터를 사용해야 할텐데요.
막강한 기계를 사용해서 모델을

0:50:41.539,0:50:45.799
>> 미리 학습시켜놨고, 우리는 이것을 활용하고 싶잖아요?

0:50:45.839,0:50:49.758
>> 만약에 이 모델에서 사용된 이미지 보다
더 큰 이미지를 가지고 있으면 어떻게 해야 하나요?

0:50:50.100,0:50:55.500
크기에 대해서는 나중에 이야기 할 겁니다. 근데 간단히
말씀드리면, fastai 라이브러리와 현대의 아키텍쳐를

0:50:56.040,0:50:59.500
사용하면, 어떤 크기든지 사용할 수 있게 됩니다.

0:51:02.849,0:51:07.159
>> 그러면, 어떤 특정 계층만을 
unfreeze 할 수 있다는 건가요?

0:51:07.619,0:51:14.629
네 맞아요. 아직 그러진 않을 거지만, 그러길 원한다면 
learn.unfreeze_to() 메소드에 계층의 번호를 넘겨주면 됩니다

0:51:19.440,0:51:26.210
제 스스로 놀라웠던 점은, 거의 대부분의 경우에
그럴 필요가 없었다는 것입니다.

0:51:26.560,0:51:30.540
거의 항상 도움이 안되었죠.
차등 학습률을 사용하면

0:51:30.980,0:51:35.800
optimizer가 딱 필요한 만큼만을 
학습할 수 있게 되기 때문입니다.

0:51:36.960,0:51:38.960


0:51:43.470,0:51:47.779
>> 데이터가 적은 경우에도 그런가요?

0:51:48.539,0:51:52.008
네, 그 경우도 마찬가지인것 같습니다.
한가지 도움이 되는 경우가 있는데

0:51:52.760,0:51:59.520
아주 큰 메모리 집약적인 모델을 사용중이어서,
GPU의 자원을 미친듯이 사용해야 한다면

0:52:00.620,0:52:05.280
적은 수의 계층을 unfreeze할때, 더 적은 메모리의 사용, 
더 적은 학습 시간이 걸리게 됩니다.

0:52:05.280,0:52:07.280
실용적인 측면의 이야기 이빈다.

0:52:07.340,0:52:10.360
>> 제 질문은

0:52:10.580,0:52:13.740
>> 특정 하나의 계층만을 
unfreeze 가능하냐는 것이었어요.

0:52:14.180,0:52:20.080
아니요, 그러지 못합니다. 대신에, n번째 부터 
그 이후까지의 계층을 unfreeze는 가능합니다.

0:52:21.000,0:52:27.080
라이브러리를 좀더 들여다 보면, 가능할지도 모르지만
왜 그래야 하는지 저는 잘 모르겠군요.

0:52:28.580,0:52:31.900
이 내용들을 보여드려서 흥분 되는데요,
저희가 일년내내

0:52:31.900,0:52:35.180
연구한 내용에 관한 것이기 때문입니다.
그 내용은 어떻게 최신예 모델들을

0:52:35.220,0:52:37.100
학습시키는지에 대한 것입니다.

0:52:37.100,0:52:44.500
그리고, 이에 대해서 몇가지 비법을 발견했습니다.
learn.fit 의 수행결과를 보시면

0:52:44.900,0:52:47.480
99.5% 까지의 정확도를 얻을 수 있음을

0:52:47.760,0:52:49.600
보실 수 있을 겁니다.

0:52:49.680,0:52:51.680
이 정도의 정확도는 엄청난 것이죠

0:52:51.780,0:52:59.239
또 다른 비법으로는, 순환 길이가 1인
"재시작하는 확률적 경사하강법" 입니다.

0:52:59.700,0:53:05.599
앞에서 잘못 알려드린 부분이 있는데,
세 번의 에포크를 수행한다는 부분입니다.

0:53:06.000,0:53:11.420
이 숫자는 사실, 순환의 갯수를 의미합니다.
만약 cycle_len을 2로 설정하게 되면

0:53:11.900,0:53:17.520
매 두번의 에포크에 대한 순환을 세번 수행하게 됩니다.
총 6번의 에포크가 되죠.

0:53:17.520,0:53:20.740
근데 여기서는 값을 3으로 설정 했지만,
결과는 7번의 에포크군요

0:53:20.740,0:53:24.980
왜 그런지는 cycle_mult=2라는 부분이 가진
마지막 비법이 그 이유 입니다.

0:53:25.380,0:53:29.300
이 부분이 하는 일을 설명해 드리기 위해서,
아주 간단한 그림을 보여드리겠습니다.

0:53:29.910,0:53:33.319
learn.sched.plot_lr()을 수행하면

0:53:34.500,0:53:37.609
cycle_mults=2가 뭘 하는지 확인이 가능합니다.

0:53:37.609,0:53:39.609
각 순환 이후의

0:53:39.630,0:53:46.579
순환 길이를 두배 증가합니다. 
"재시작하는 확률적 경사하강법"을 소개한 논문의

0:53:47.069,0:53:51.949
저자가 이 부분에 대해서
가끔식 매우 잘 동작하는것 같다고 했었습니다.

0:53:51.949,0:53:56.400
저는 이 방법이 아주 자주 잘 동작한다는 걸
확실히 발견했다고 생각합니다.

0:53:57.800,0:54:01.860
직관적으로 말씀드리면,
순환의 길이가 매우 짧은 경우에 대해서

0:54:02.790,0:54:06.109
일단 시작은 좋은 지점을 찾기 위해서 내려갑니다

0:54:06.109,0:54:10.800
그리곤 위로 튀어 오르죠. 다시, 좋은 지점을 
찾으려고 내려가고 위로 튀어 오릅니다.

0:54:10.960,0:54:16.040
이 과정은 좋은 지점을 결코 찾지 못하지만,
초반에 수행하기엔 좋습니다. 약간 부드러운

0:54:16.040,0:54:21.700
지점을 발견하려고 하기 때문입니다. 하지만 

0:54:21.700,0:54:24.460
나중에는 좀더 탐색하고,  
그리고 좀더 많이 탐색할 필요가 있습니다.

0:54:24.460,0:54:29.860
cycle_mults=2이 매우 좋은 접근인 경우가
자주 있습니다.

0:54:30.480,0:54:35.179
많은 하이퍼파라메터가 필요 없다고 해놓고,
갑자기 많은 것을 소개해 드리는데요

0:54:35.400,0:54:39.049
좋은 학습률을 설정하는 것으로

0:54:39.869,0:54:44.478
다른 것들은 신경쓰지 않아도 되지만,
소개드린 방법들을 추가하면

0:54:45.390,0:54:52.729
다른 큰 노력없이 추가적인 향상을 이끌어내는데
도움이 됩니다. 실제로 저의 경우에

0:54:53.759,0:54:58.039
순환 갯수를 3, cycle_len을 1, 
그리고 cycle_mult=2로 설정한 경우

0:54:59.190,0:55:03.019
아주 자주, 매우 잘 동작하는 
아주 좋은 모델을 얻곤 합니다.

0:55:04.769,0:55:09.409
그렇게 해서 잘 안된다면, 
cycle_len을 2로 하고, cycle_mult는

0:55:09.920,0:55:15.100
설정안하고 시도해 봅니다. 이 두가지 방법이
아주 많은 경우에 잘 동작하는것 같더군요.

0:55:15.100,0:55:17.560
다른 추가적인 조작이 필요하지 않았어요

0:55:17.560,0:55:21.120
이 한줄의 코드를, 언제나 항상 사용 하신다면

0:55:21.300,0:55:25.000
꽤나 좋은 결과를 얻지 못했을때,
저는 그 상황에 놀랄지도 모릅니다.

0:55:25.200,0:55:28.440
질문이 들어 왔군요

0:55:28.680,0:55:34.660
>> 왜 부드러운 표면이 더 일반화된 
네트워크와 관련성이 있는건가요?

0:55:39.660,0:55:41.660
약간 직관적인

0:55:42.120,0:55:47.800
설명을 해보도록 하죠.
일단 이 그림을 다 지우고...

0:55:48.560,0:55:51.420
만약에

0:55:51.860,0:55:56.820
약간 뾰족뾰족한 그래프가 있을때

0:55:57.200,0:56:02.360
X축은 그 값이 바뀜에 따라서

0:56:02.940,0:56:08.500
얼마나 고양이와 개를 잘 인식하는지를
보여줍니다.

0:56:08.740,0:56:11.520
뭔가가 일반화 가능하다는 것은

0:56:11.780,0:56:16.060
약간 다른 데이터셋이 주어졌을때도
잘 동작하길 원한다는 의미입니다.

0:56:16.160,0:56:19.080
약간 다른 데이터셋이란

0:56:19.460,0:56:26.660
기존의 X값에 따라서 개/고양이가 
얼마나 잘 인식 되는지에 대한

0:56:26.660,0:56:30.300
약간은 다른 관계를 보일 것입니다.
(빨간색 그래프)

0:56:30.560,0:56:34.740
다시 말하자면, 최종적으로 파란색 그래프
오른쪽 하단에 안착하는 경우

0:56:35.360,0:56:40.809
약간 달라진 데이터셋에 대해서는 잘 동작하지
않게 됩니다. 반면에, 왼쪽 하단에 안착하면

0:56:40.809,0:56:44.740
약간 달라진 데이터셋에 대해서도 
잘 동작하게 되죠.

0:56:47.160,0:56:51.580
다시 이전으로 돌아가서,
cycle_mult=2가 하는 일에 대해서 배웠는데요

0:56:51.680,0:56:55.300
잠깐 휴식하기 전에, 현재 99.5%의 
정확도를 보여주는 이 모델을 

0:56:55.360,0:57:02.840
여전히 좀더 향상 시키기 위한 
마지막 방법을 소개해 드릴까 합니다.

0:57:03.380,0:57:09.580
우리가 할 일은 모델을 바꾸는게 아니라
일단 몇가지 시각화 자료를

0:57:10.800,0:57:18.180
다시 확인해 보는 것입니다. 잘못 분류된 몇 사진들에 
대해서 시각화 했던 것 말입니다.

0:57:20.720,0:57:27.900
제가 했던건 가장 잘못 분류된 사진들을
출력한 것인데요. 

0:57:29.720,0:57:35.649
한가지 짚고 넘어가야 할 점은
모델 검증 단계에서, 모델에 대한 모든

0:57:36.560,0:57:41.709
인력 데이터(이미지)는 "정사각형"이 
되어야 했다는 것입니다. 그 이유는

0:57:42.740,0:57:44.590
약간 덜 중요한 기술적 상세내용 이긴 한데

0:57:44.590,0:57:49.660
만약 다른 이미지들이 서로다른 차원의 배열의
형태로 이루어져 있다면, GPU는 기본적으로 

0:57:49.660,0:57:52.180
빠르게 동작하기 어렵습니다.

0:57:52.200,0:57:56.640
 GPU의 모든 부분(코어)은 똑같은 일을 하기 때문에
일관성 있게 유지되어야 하는 경향이 있습니다.

0:57:56.640,0:57:58.600
물론 이 부분을 개선할 수 있겠지만

0:57:58.640,0:58:03.020
그게 이 기술의 현 주소입니다. 그래서
검증 데이터셋에 대해서, 이 사진이 개라고

0:58:03.020,0:58:04.020
판별하게 되면

0:58:04.020,0:58:06.740
실제로 일어나는 일은
이 사진의 중간지점에 대해서

0:58:06.740,0:58:11.220
정사각형 만큼의 부분을 드러냅니다.
양쪽 모서리 부분을 없애는 거죠

0:58:11.230,0:58:13.150
일단 사진의 높이를 측정하고

0:58:13.150,0:58:17.060
그에 따른 폭으로, 정사각형을 만드는 겁니다.

0:58:17.060,0:58:20.720
이 사진의 경우엔, 사실상 이 강아지의
머리 부분이 안보이게 될 겁니다.

0:58:20.720,0:58:27.860
이 사진이 올바르게 분류되지 않은 이유는
몸통 부분만을 바라보게 되기 때문이라고 생각되는군요.

0:58:28.780,0:58:32.780
몸통만 보면, 딱히 개인지 고양인지 
알아보기 힘드니까요. 

0:58:32.840,0:58:36.100
이 부분에 대해서 우리가 할 수 
있는 작업이 있습니다.

0:58:36.380,0:58:41.220
검증 데이터셋에 대한 예측을 계산할때,
test time augmentation (테스트 할때의 강화)

0:58:41.220,0:58:43.200
라는걸 사용할 겁니다.

0:58:43.200,0:58:47.500
이게 의미하는것은 모델을 학습시킨 후에
학습 데이터셋에 없는 사진에 대해서

0:58:47.500,0:58:51.220
고양이인지 개인지를 매번 결정한다는 것입니다.
그리고,

0:58:52.200,0:58:54.260
네 가지의 

0:58:54.420,0:58:58.380
무작위 data augmentation을 수행합니다
기억하시죠? data augmentation은 사진 

0:58:58.380,0:59:00.300
위치를 막 바꾸게 하거나

0:59:00.300,0:59:02.540
확대/축소나, 뒤집거나 하죠.

0:59:02.720,0:59:07.660
그 결과 중에서 네개를 무작위로 선택하고
augment 되지 않은 원본 이미지를

0:59:08.570,0:59:14.110
선택합니다. 다음으로는 이 선택된 이미지에 대해서
예측 과정을 수행합니다. 그리곤 이들의

0:59:14.750,0:59:20.680
평균을 구할 겁니다. 예를 들면, 이것도 고양이인지?
저것도 고양이인지? 모두 측정하는데

0:59:20.750,0:59:26.500
희망적으로, 무작위로 선택된 이미지들 중에서
다른 강이지 얼굴만큼 크게 보이는 정도로

0:59:26.810,0:59:29.590
이미지를 확대하거나, 다른 강아지들 사진과
비슷한 정도로 기울어져 있는등의 사진으로부터

0:59:29.590,0:59:33.780
강아지 얼굴을 발견하길 원하는 것입니다.

0:59:34.200,0:59:36.760
이를 위해서, 우리가 해야할

0:59:36.760,0:59:40.500
모든것은 TTA()를 호출하는 것입니다.
TTA는 Test Time Augmentation의 약자에요.

0:59:40.700,0:59:46.150
테스트(Test) 라는 용어는 
학습된 모델이 예측을 수행하는 것에 대한 것인데

0:59:46.150,0:59:48.729
추론(inference) 또는 

0:59:48.730,0:59:53.620
테스트(test)라고 불리기도 하죠.
그래서 TTA 라고 네이밍 했습니다.

0:59:53.620,1:00:00.910
TTA()를 수행하고, 정확도를 다시 확인해 보면
99.6%인 것을 확인 가능합니다.

1:00:01.460,1:00:03.460
질문이 들어 왔습니다.

1:00:05.080,1:00:08.340
>> 매 에포크마다

1:00:08.780,1:00:13.260
>> 특정 이미지에 대해서 한가지 종류의 augmentation을
하는게 맞나요?

1:00:13.400,1:00:15.720
학습을 수행할때,

1:00:15.820,1:00:19.300
TTA를 전혀 하지 않습니다.

1:00:19.670,1:00:26.319
물론 그럴 수는 있죠. 예를 들어서, 매 에포크마다 
TTA를 수행해서, 경과를 확인한다 던지요

1:00:26.320,1:00:28.720
근데 여기서 보여드린건 그런게 아닙니다.
일단 전체적인 학습을 

1:00:28.840,1:00:30.520
학습때(training time)의 

1:00:30.530,1:00:32.170
augmentation과 함께 수행했습니다.

1:00:32.170,1:00:35.380
training time augmentation은 TTA처럼 특별한
이름은 없습니다. 일반적으로 그냥 

1:00:35.380,1:00:39.640
data augmentation이라고 하면 그게 똑같은 거니까요
여기 보시면, 매 에포크마다 무작위로

1:00:39.880,1:00:44.820
약간씩 augment된 사진을 보여주게 되는거죠.
7번의 각 에포크다마, 각기 다른 버전의 사진을

1:00:44.860,1:00:46.860
보게 되는 겁니다.

1:00:47.020,1:00:51.340
그러고나면, 완전히 학습된 모델이 생성되고,

1:00:51.350,1:00:56.229
검증 데이터셋을 한번 확인해 보게 되죠.
디폴트로 TTA는 검증 데이터셋을 사용합니다.

1:00:56.230,1:00:58.630
검증 데이터셋의 각 사진에 대해서, 어떤게 고양이고 
개인지에 대한 예측이 무엇인지 구하게 되죠.

1:00:58.630,1:01:00.630
그리고 총 네번의 예측을

1:01:00.700,1:01:05.000
서로다른 무작위의 사진, 즉 원본 사진과
세 장의 augment된 사진에 대해 수행하고

1:01:05.000,1:01:06.540
이것들의 평균을 구합니다.

1:01:06.540,1:01:09.900
그리고 이 출력이 그 결과 입니다.

1:01:10.200,1:01:12.840
>> TTA()를 할때 augment된 샘플들 중

1:01:13.000,1:01:16.200
>> 동일한게 나타날 확률이 높은가요?

1:01:17.580,1:01:22.500
네. 사실 모든 이미지의 augment된 데이터는
유일무이 합니다. 왜냐하면 회전이

1:01:22.500,1:01:25.660
0.34 각도만큼 되거나

1:01:25.660,1:01:31.300
확대가 1.0  또는 1.65만큼 되거나 하니까요.
그러니까 매번 약간씩 다르다는 것이죠.

1:01:31.300,1:01:32.580
>> 감사해요

1:01:32.600,1:01:34.600
천만에요

1:01:36.840,1:01:38.460


1:01:38.470,1:01:40.830
>> white padding 같은걸 사용안하는 이유가 뭐죠?

1:01:41.440,1:01:46.160
white padding 이요?
>> 사진 가장자리에 빈 공간을 추가하는 것이요

1:01:46.600,1:01:53.160
많은 종류의 data augmentaion을 할 수 있어요.
그 종류중 하나로 사진 가장자리에

1:01:53.160,1:01:56.280
테두리를 넣을 수 있습니다.

1:01:56.280,1:02:00.940
기본적으로 경계선을 추가하는 거죠
제 실험적 경험에 의하면, 별로 도움이 안됩니다.

1:02:01.480,1:02:06.240
CNN이 경계선 추가된 사진을 별로
흥미롭게 바라보지 않는거 같아요

1:02:06.780,1:02:10.900
나중에 보게될 건데, 제가 주로 하는건
reflection padding 이라는 건데요

1:02:10.900,1:02:12.700
반사된 경계선을

1:02:12.700,1:02:19.220
추가하는 방식입니다. 좀 더 큰 이미지를 생성하는
방법으로, 특히 위성 사진 같은 데이터에 사용됩니다.

1:02:19.860,1:02:25.700
일반적으로는, padding을 많이 하지는 않아요.
대신에 확대를 하죠.

1:02:27.540,1:02:30.680
>> 마지막 질문에 이어지는 건데요

1:02:30.900,1:02:35.360
>> 이미지를 잘라내는것 보단 흰색 테두리를
추가하는게 나은거 아닌가요?

1:02:35.360,1:02:37.360
>> 잘라내면 강아지 얼굴이 날라가니까요

1:02:37.400,1:02:41.300
>> 하지만 흰색 테두리를 추가하면, 그렇지 않죠
맞아요.

1:02:41.560,1:02:46.020
그래서 refelction padding이나 확대등과 같은 방법이
도움이 되는 겁니다.

1:02:46.020,1:02:50.340
그리고 fastai 라이브러리에 사용자 정의 형태로, 
사진을 변형시키기 위한 방법이 있습니다.

1:02:50.620,1:02:57.560
(생각중..)

1:02:58.120,1:03:01.220
이미지 크기에 의존적인거에요

1:03:01.440,1:03:05.560
일반적으로 말하자면, TTA와 data augmentation을
같이 사용할때

1:03:05.920,1:03:09.750
최상의 방법은 가능한한 더 큰
이미지를 사용하는 것입니다.

1:03:09.750,1:03:13.860
만약에 이미지를 잘라내고, 흰색 경계선을
위 아래에 추가하면

1:03:14.320,1:03:17.249
꽤나 크기가 줄어들게 되죠.
그리고나서, 입력 크기만큼 크기를 다시 맞추려면

1:03:17.350,1:03:22.049
GPU의 사용량이 더 많아지고, 
그러면 더 큰 이미지를 확대 하는게

1:03:22.050,1:03:23.350
더 나은것이 되겠죠.

1:03:23.350,1:03:27.149
제가 지금까지 가지고 놀아본 결과,
별로 성공적이지 않았구요

1:03:35.400,1:03:41.000
>> data augmentation 이라는 개념이
이미지가 아닌 다른 분야에서

1:03:41.380,1:03:44.380
>> 얼마나 사용되나요?

1:03:44.680,1:03:45.880


1:03:45.880,1:03:47.440


1:03:47.440,1:03:52.160
누구도 잘 모르는거 같아요. 제가 사실
자연어처리 커뮤니티에 있는

1:03:52.620,1:03:58.560
몇 지인들에게 물어 봤거든요?
자연어 처리는 나중에 배우게 될거에요!

1:03:59.110,1:04:01.739
꽤나 도움이 되는거 같아요. 
제가 보여드릴 몇가지

1:04:02.590,1:04:08.489
예제가 있는데, 그 예제관련의 논문들에서
예를들어, 동의어를  대체하려는 노력이 있었죠

1:04:08.489,1:04:14.060
근데 전체적으로 보면, 이미지가 아닌 분야에 대한
적절한 data augmentation 관련 주제는

1:04:14.860,1:04:18.940
아직 연구가 많이 되지 않은 상태입니다.

1:04:23.500,1:04:28.920
>> 제 질문은 슬아이딩 윈도우를 사용해서
이미지를 생성해내는건 어떤가요?

1:04:28.920,1:04:32.420
>> 예를 들어서, 그 강아지 그림을

1:04:32.500,1:04:36.220
>> 삼등분 하면 더 나을까요?
TTA() 할때 말하는거죠?

1:04:36.520,1:04:38.940
>> 아뇨, 일반적으로 이야기 하는거에요.

1:04:39.480,1:04:43.400
학습할때엔, "아니요" 라고 답해드리고 싶어요
왜냐하면, 그 방법으론

1:04:43.400,1:04:44.860
많은 다양한 이미지가
생성 안되거든요

1:04:44.860,1:04:46.860
보셨다 시피

1:04:47.100,1:04:52.040
많은 각도를 회전하거나 픽셀을 움직이거나
픽셀을 움직이는등, 아주 많은 조금씩 다른 버전을

1:04:52.140,1:04:58.200
만듭니다. 만약에 단 세개 방법으로만 이를 수행하면, 
데이터를 바라보는 많은 방법을

1:04:58.200,1:05:00.080
제공해주지 않는 것이죠.

1:05:00.280,1:05:02.080
TTA()의 경우엔

1:05:02.200,1:05:05.760
고정된 위치를 기준으로 잘려진다면

1:05:06.020,1:05:07.960
학습때보다는 더 나을 것 같습니다.

1:05:07.960,1:05:14.960
아직 그 부분을 구현하진 않았습니다.
제 생각에, 고정된 위치를 기준으로 자르는것

1:05:14.960,1:05:17.040
과 함께

1:05:17.049,1:05:18.700
무작위의

1:05:18.700,1:05:22.720
대비, 밝기, 회전등의 변화를 주면
더 좋을것 같습니다.

1:05:23.620,1:05:28.979
아직 구현을 하지 않은 이유는, 제가 test하는
실제 상황에서 크게 도움이 안되게 보였거든요

1:05:28.980,1:05:34.140
그리고, 코드가 훨씬 더 복잡해지죠.
흥미로운 질문을 해주셨지만

1:05:34.480,1:05:41.500
>> 저희 모두가 사용하는 fastai 라이브러리의
모든 부분이 오픈소스인가요?

1:05:43.440,1:05:48.340
아주 좋은 질문입니다. fastai 라이브러리는
오픈소스가 맞습니다. 이 부분에 대해서 좀더

1:05:48.340,1:05:51.540
일반적인 이야기를 해 봅시다.

1:05:51.660,1:05:53.880
왜냐하면 사실

1:05:54.080,1:05:57.720
이 라이브러리를 사용하는건
흥미롭지만 일반적이지 않아요

1:05:57.980,1:06:01.680
그리고 PyTorch라는 라이브러리에 기반하고 있죠

1:06:02.480,1:06:06.600
PyTorch 라이브러리는

1:06:07.080,1:06:08.880
꽤나 최근에 개발된 것인데

1:06:08.880,1:06:11.440
제가 존경하는 대부분의

1:06:11.540,1:06:15.180
연구자들이 요즘 이것을 사용한다는걸 알게 됐어요

1:06:15.960,1:06:19.879
지난해의 전체 강의의 두번째 부분에서,
제가 가르치고자 했던 많은 최신예 기법들이

1:06:19.880,1:06:25.309
제가 주로 사용하던, Keras나 TensorFlow로
로 가르치는게 쉽지 않더군요

1:06:26.040,1:06:32.620
그래서 두번째 부분의 코스 내용을 PyTorch로 
바꿔야 했습니다. 한가지 문제는

1:06:32.720,1:06:38.380
자신만의 학습 과정을 처음부터 코딩해야하는등
PyTorch는 사용하기가 아주 쉽지는 않다는거에요.

1:06:38.390,1:06:42.319
기본적으로 맨땅에 코딩해야 하죠.
fastai 라이브러리의를 사용하면, 이 모든걸

1:06:42.319,1:06:43.980
직접 코딩 안해도 됩니다.

1:06:43.980,1:06:47.000
기본적으로 딥러닝을 공부하는건

1:06:47.280,1:06:52.399
매우 힘든 일입니다. 특히나 수백죽의 코딩을
직접 해야 한다면 더욱 말이죠.

1:06:53.910,1:06:59.119
그래서, 저희가 PyTorch를 기반으로 하는 라이브러리를
만들게 되었습니다. 왜냐하면 저희의 목표는

1:06:59.910,1:07:02.839
세계적-수준의 딥러닝을 가르치는 것인데요

1:07:02.839,1:07:05.929
세계 최고의 것을 어떻게 만드는지
보여드리고 싶었죠

1:07:06.869,1:07:10.939
그리고, 보여드리고 했던 수 많은 
세계적 수준의 것들은 PyTorch가

1:07:06.860,1:07:11.360
그리고, 수 많은 세계적 수준의 것들을
보여드리기 위해선 PyTorch가 필요했거나

1:07:11.520,1:07:18.340
적어도 PyTorch로 이를 실현하기가 훨씨 쉬웠습니다
하지만 PyTorch는 딥러닝을 처음 배우는

1:07:18.340,1:07:23.080
학생들에게 첫번째로 가르치기에는

1:07:23.080,1:07:27.740
적합하지 않았습니다. 그래서 저희가
PyTorch 기반의 라이브러리를 만든것이죠

1:07:29.339,1:07:31.220
최초에는 작년에 저희가 가르친 Keras로부터

1:07:31.220,1:07:36.859
많은 영향을 받았습니다. 하지만, 나중에는
Keras보다도 훨씬 쉽게 만들어야 한다는걸 깨달았죠

1:07:36.930,1:07:40.069
작년의 Keras로 적힌 코스 노트를 보시면

1:07:40.260,1:07:43.960
모든 코드가 2-3줄 이상 더 길다는걸
아실 수 있을 겁니다.

1:07:44.080,1:07:47.480
그래서 위험 요소가 좀 더 있었죠

1:07:47.600,1:07:50.300
왜냐하면 좀 더 많은 것을 올바르게 
작성(코딩) 해야 했으니까요.

1:07:51.539,1:07:59.059
그래서 결국 딥러닝을 배우는것을 더 쉽게 
할 뿐만 아니라, 최신예적인 결과를 더 쉽게

1:07:59.059,1:08:01.969
얻어낼 수 있게 하기 위해서 
fastai 라이브러리를 만들게 되었습니다.

1:08:02.729,1:08:08.959
그래서 작년 한해동안 라이브러리를 개발했었고
최신예적인 결과를 얻거나, 새로운 방법을

1:08:10.349,1:08:16.818
스스로 개발하는데 있어서, 이 라이브러리를 사용하면 
훨씬 더생산적일 수 있다는걸 발견했습니다.

1:08:16.819,1:08:22.548
그리곤 깨닫기 시작했죠. 그동안 무시했던 수 많은
논문들의 내용을 사용하면, 학습률 발견자와 비슷한

1:08:22.700,1:08:30.100
자동화나 반자동화를가능하게 해 준다는 것을요.
다른 라이브러리엔 없는 기능들입니다.

1:08:30.100,1:08:35.220
fastai는 다른 어떤것 보다 더 쉬운 방법을

1:08:35.480,1:08:41.480
제공해 줄 뿐만 아니라 
동시에, 사실상 내부적으로 더 세심한 것들을

1:08:42.180,1:08:47.060
제공해 줍니다.

1:08:47.340,1:08:50.880
흥미로운 조합이죠

1:08:51.300,1:08:54.980
아주 초기버전의 fastai 라이브러리를
배포하게 되었고

1:08:54.980,1:09:00.230
이 코스를 마지막까지 진행하는 동안
많은 사람들이

1:09:00.230,1:09:04.660
라이브러리를 발전시키는데 도움을 주길
희망해 보겠습니다. 이미 많은 사람들이

1:09:04.960,1:09:08.760
꽤나 안정적인 것들의 개발에 도움을 주었구요

1:09:09.120,1:09:12.680
그리고 누구든지 이 라이브러리를 사용해서

1:09:13.650,1:09:19.040
오픈소스 라이센스 정책하에 자신들만의 모델을
만들 수 있기를 희망합니다.

1:09:23.060,1:09:30.140
내부적으로는 PyTorch형 모델을 생성하고,
PyTorch형 모델은 다른 여러 형태로

1:09:30.300,1:09:33.480
변환이 가능합니다.

1:09:33.680,1:09:37.980
말이 나왔으니 말인데, 예를 들어서
모바일 장치에서 뭔가를 해보고 싶은 경우에

1:09:37.980,1:09:40.980
아마도 TensorFlow를 사용해야 할 겁니다.

1:09:41.040,1:09:43.040
그리고,

1:09:43.199,1:09:44.509
코스 후반에 가면

1:09:44.509,1:09:48.439
fastai 라이브러리에서 우리가 하는 몇가지 것들을
어떻게 똑같이 Keras와 TensorFlow에서 할 수 있는지

1:09:48.500,1:09:53.320
보여줌으로써, 다른 라이브러리가 어떻게 
생겼는지에 대한 감각을 얻게 될 겁니다.

1:09:53.600,1:09:57.660
일반적으로 말해서, 간단한 것들은

1:09:58.020,1:10:00.259
Keras나 Tensorflow로 구현 하는 법을
배우는게 fastai나 PyTorch에 비해서

1:10:00.860,1:10:06.679
얼마 시간이 안걸릴 겁니다. 하지만, 
더 복잡한 문제들에 대해서는 종종

1:10:07.590,1:10:14.659
그렇게 되기 힘들거에요. (잘 안들림)

1:10:18.060,1:10:20.719
제 생각에 더 중요한 점은

1:10:22.110,1:10:29.600
매년 라이브러리의 많은 부분이 변화하기 때문에

1:10:29.600,1:10:34.879
이 코스를 진행하는 동안에, 
어떻게 학습률을 찾는지, 왜 차등 학습률이 중요한지

1:10:34.880,1:10:38.270
어떻게 학습률 annealing을 수행하는지,

1:10:38.820,1:10:43.009
재시작하는 확률적 경사하강법이 무슨일을 하는지
등과 같은 컨셉을 이해해야 한다는 것입니다.

1:10:44.550,1:10:47.360
내년에 이 코스를 다시 가르칠때가 되면

1:10:48.449,1:10:50.658
라이브러리 관련

1:10:51.540,1:10:53.540
상황들이 바뀔 확률이 큽니다.

1:10:54.389,1:10:56.389
질문이 있나보군요

1:11:03.510,1:11:10.310
>> Pyro에 어떤 의견이 있으신기 궁금합니다.
그게 뭔지 아직 본 적이 없어요.

1:11:10.310,1:11:14.060
확률적 프로그래밍에 큰 관심이 있고, 그게 정말 멋진 
일인줄 알지만 아직 들여다 보진 않았습니다.

1:11:14.060,1:11:18.859
Pyro는 Pytorch를 기반으로 작성된 것입니다.
이 코스는 단순히 딥러닝 라이브러리 자체 보다는

1:11:18.860,1:11:22.790
PyTorch에 대한것을 더 많이 배우게 될 건데,
PyTorch는 GPU로 가속화된

1:11:24.690,1:11:26.219
임의의

1:11:26.219,1:11:27.600
알고리즘의 코딩을 할 수 있게 해줍니다.

1:11:27.600,1:11:32.689
이 코스에서 실제로 어떻게 하는지 배우게 될거에요.
Pyro는 딥러닝 이외의 분야에 PyTorch가 사용된

1:11:32.760,1:11:34.760
한가지 좋은 예라고 볼 수 있습니다.

1:11:35.969,1:11:37.969


1:11:38.699,1:11:41.719
그러면, 일단 8분간의 휴식 후에 
이어서 진행하도록 하죠.

1:11:46.590,1:11:48.590
(휴식 끝나고)
그러니까

1:11:51.060,1:11:53.509
99.65%의 정확도가

1:11:54.270,1:11:56.929
의미하는건 무엇일까요?

1:11:57.570,1:12:01.130
머신러닝에서 분류하는 문제를 다룰 때,

1:12:01.590,1:12:06.409
결과를 바라보는 아주 간단한 방법은
오차행렬(confusion matrix) 라는 겁니다.

1:12:06.719,1:12:14.149
딥러닝에 대한것 만은 아집니다. 머신러닝을 사용한
어떤 종류의 분류 모델이든지 적용되는 이야기로

1:12:14.690,1:12:19.190
각 1,000장의 고양이와 강아지 사진이 있는데
1,000장의 고양이 이미지 중에서

1:12:19.469,1:12:23.929
모델이 고양이라고 예측한 것이 몇개나 되는지를 나타냅니다
명백하게 이것은 검증 단계에 대한 것이죠.

1:12:23.930,1:12:26.329
학습 단계에서 사용되지 않은 이미지 말입니다.

1:12:26.820,1:12:33.259
결과적으로 998장을 고양이라고 예측했고,
2장에 대해서는 잘못 예측했습니다.

1:12:33.260,1:12:39.980
개 이미지에 대해서는 995장을 개라고 예측했고,
나머지 5장에 대해서는 잘못 예측했습니다.

1:12:40.710,1:12:46.430
오차행결은 4-5종류의 분류 카테고리를 예측할때,
어떤 그룹에 대해서 가장 문제를 겪는지 알아보고 싶은 경우에

1:12:46.739,1:12:50.599
특히 유용합니다. 그리고 보시다시피
색깔이 칠해져 있는데

1:12:50.940,1:12:56.600
큰 부분을 강조하는 용도로 사용되었습니다.
대각선 부분이 강조된 부분이 되기를

1:12:57.480,1:12:59.480
희망해야만 합니다.
(좋은 결과)

1:13:00.150,1:13:03.109
그러면, 우리에게는 재학습된 모델이 준비 되었었습니다.
지금부터는, 다시 돌아가서

1:13:03.110,1:13:10.130
어떤 특정 이미지들이 올바르게 예측되지 못했는지
확인해 보는게 꽤나 도움이 됩니다.

1:13:10.680,1:13:13.309
보시면, 단 2장만이 고양이로 잘못 분류 되었죠.

1:13:13.770,1:13:18.770
4장을 디폴트로 출력하는데, 오른쪽의 두장은
0.5보다 낮은 수치를 보여줍니다.

1:13:18.770,1:13:25.910
그 말은 이 두장은 잘못 분류된 것이 아니라는 거죠.
왼쪽의 두장만이 잘못된 것이며, 제일 왼쪽의 사진은

1:13:26.580,1:13:32.600
두번째 사진은 눈알이 전혀 없는걸 보면,
이상한 공예품으로 보이는군요.

1:13:33.120,1:13:35.070
그다음은

1:13:35.070,1:13:40.850
얼마나 많은 개 사진들이 잘못 분류되었는지로, 
총 5장이 존재하고 여기엔 4장이 출력되어 있습니다.

1:13:41.850,1:13:49.069
첫번째와 세번째는 모델이 실수한것으로 보여지고,
마지막은 충분한 정보가 없는 것에서 발생한 실수같군요

1:13:50.190,1:13:56.449
일단 리뷰를 해보면, 꽤나 좋은 분류 모델을
만들어 냈습니다.

1:13:57.300,1:14:01.640
많은 Kaggle 경연에 참가하고, 다양한 연구 논문과
결과를 비교해 볼때

1:14:01.640,1:14:06.499
제 생각엔 이 모델이 최신예 분류 모델이라고
말할 수 있을것 같습니다.

1:14:06.989,1:14:08.930
잠시후엔 지금보다 좀 더 개선할 것입니다.

1:14:08.930,1:14:13.489
일단 여기 보시는 순서가 기본적인 단계 입니다.
세계적 수준의 이미지 분류 모델을 만들려면,

1:14:13.770,1:14:19.100
지금까지 우리가 해온 단계들인데, 
data augmentation 기능을

1:14:19.320,1:14:24.020
aug_tfms 인자값에 side_on 또는 top_down등
상황에 맞게 설정해 줘서 활성화 하고

1:14:24.660,1:14:26.660
precompute=True 로 일단 시작을 합니다.

1:14:27.179,1:14:31.579
괜찮은 학습률을 lr_find()로 찾고, 1-2번의
에포크 만큼 발견된 학습률로 학습을 수행합니다.

1:14:31.580,1:14:35.059
이미 precompute=True 되어 있다면, 
수 초정도 걸리는 작업이죠.

1:14:35.460,1:14:40.100
그리고 나서 precompute=False를 설정합니다. 그래야 
data augmentation을 사용하고, 

1:14:40.100,1:14:42.100
일반적으로 cycle_len=1이 설정해서

1:14:42.720,1:14:44.720
2-3 에포크 만큼 학습을 수행할 수 있게 됩니다.

1:14:45.090,1:14:49.639
다음으로 모든 계층들을 unfreeze 합니다. 그리고
이전 단계 계층들에 대한 학습률을

1:14:49.860,1:14:56.060
다음 단계의 계층들의 학습률에 비해서 3-10배 정도
낮게 설정합니다. 

1:14:59.020,1:15:01.640
여기서는 10배로 했었죠.

1:15:01.640,1:15:07.000
오른쪽에서 왼쪽으로 매번 10배씩 감소 했었죠.

1:15:07.100,1:15:09.100
경험상의 법칙이 있다면

1:15:09.270,1:15:12.439
ImageNet 데이터셋에 대해서 미리 학습된
모델을 가지고 시작한다고 가정할때

1:15:12.750,1:15:18.739
분류하고자 하는 대상이 ImageNet 데이터셋에 있는
물체나 환경등에 대한 사진과

1:15:18.810,1:15:21.410
상당히 비슷하다는걸 알고 있다면

1:15:22.110,1:15:29.179
10배 정도의 차등을 설정해야 할 겁니다. 왜냐하면
이전 계층들은 아마도 이미 꽤나 좋은 것들이거든요

1:15:29.760,1:15:33.170
하지만 만약 위성사진이나 의학사진같은게 대상이라면

1:15:33.180,1:15:37.800
ImageNet과는 완전히 달라 보이기 때문에,
이전 계층들이 더 많이 학습 되어야 합니다. 

1:15:37.800,1:15:42.180
이에 대해서, 3배 정도 차등을 줘야 할겁니다.

1:15:43.440,1:15:48.109
10배냐 3배냐의 차이가
제가 주는 변화 중 한가지 입니다.

1:15:51.440,1:15:54.420
그래서, 모든 계층을 unfreeze한 후에

1:15:54.680,1:15:59.540
lr_find()를 다시 수행할 수 있습니다.

1:15:59.580,1:16:08.020
그런데 이때는 모든 계층을 unfreeze 했기 때문에
차등 학습률의 기능도 켜져 있습니다.

1:16:09.020,1:16:14.160
그리고, 이전 결과와의 차이가 있는지
확인해 봐야 할 것입니다.

1:16:14.480,1:16:18.120
차등 학습률을 설정한 상태에서

1:16:18.320,1:16:20.620
lr_find()를 호출할때 알아둬야 할게 있는데

1:16:21.000,1:16:25.080
실제로 출력되는 내용은 각 차등 학습률이 적용되는

1:16:25.080,1:16:28.900
계층 그룹의 마지막 계층에 대한 학습률입니다.

1:16:29.190,1:16:30.140
그리고 나서는

1:16:30.140,1:16:35.450
cycle_mult=2로 설정한 상태로 전체 네트워크를
과적합이 될때까지 혹인 허락된 시간이 다 소진될때 까지

1:16:35.600,1:16:40.100
다시 학습 시킵니다. 
상기 내용들을 완전히 다른 데이터셋에 대해서

1:16:40.100,1:16:42.840
다시한번 수행해 보도록 하겠습니다.

1:16:42.840,1:16:44.220
오늘 아침에,

1:16:44.220,1:16:48.380
커뮤니티 포럼에 계신 몇 분들이, 이 레슨의 내용과

1:16:48.380,1:16:50.880
매우 유사한 "개 품종의 분류"라는 

1:16:50.880,1:16:53.400
Kaggle 경연대회를 시도하시더군요.

1:16:53.680,1:16:56.880
"개 품종 분류"라는 Kaggle 경연은

1:16:57.060,1:17:02.420
사진이 고양이냐 개냐를 결정할 필요는 없고,
일단 모든 데이터가 개 사진입니다.

1:17:02.430,1:17:08.849
하지만, 어떤 종의 개인지를 결정해야 하죠.
여기에는 120가지의 종이 포함 됩니다.

1:17:09.370,1:17:11.370


1:17:11.770,1:17:13.800
병리학적인 사진의 세포 종류나

1:17:14.530,1:17:16.530
CT 사진에 있는 암 종류나

1:17:17.290,1:17:22.560
위성사진에서 다른 종류의 빙산을 구분해내는등

1:17:24.100,1:17:29.789
레이블링된 이미지가 있는 것이라면 모두
비슷한 문제라고 보시면 됩니다.

1:17:30.820,1:17:34.559
그래서 오늘 아침에 제가 뭘 했는지를
보여드리고 싶군요. 약 1시간정도 걸렸는데

1:17:35.140,1:17:40.499
제가 아직 시도해보지 못한 문제에 대해서
처음부터 끝까지 해본 것입니다.

1:17:41.650,1:17:45.540
일단 Kaggle에서 데이터를 다운로드 했습니다.
어떻게 했는지는 잠시후에 보여드리도록 하겠지만

1:17:45.540,1:17:47.790
Kaggle CLI라는 깃헙 프로젝트를 사용해서

1:17:48.130,1:17:53.459
여기에 Kaggle 경연대회의 이름을 주게 되면,
이 경연대회에 대한 모든 데이터를

1:17:53.560,1:17:58.920
Crestle이나 AWS나 사용하는 어디든지
다운로드 할 수 있습니다.

1:17:59.140,1:18:02.380
전 그 데이터를 data 폴더에 저장했습니다.

1:18:02.620,1:18:04.240
그리고

1:18:04.240,1:18:10.349
ls 쉘 명령을 수행해서 폴더 내용을 확인했구요
확인해 보니까

1:18:11.560,1:18:16.110
전에 사용하던 데이터셋과는 약간 다르더군요
일단 train 폴더가 있는데

1:18:16.110,1:18:19.220
이 폴더 안에는 서로 다른 개 품종 마다
또 다른 폴더들이 있습니다.

1:18:19.380,1:18:25.400
그리고 csv 파일이 있습니다. pandas를 
사용해서 csv 파일을 읽어 들였는데

1:18:25.410,1:18:30.479
pandas는 csv 파일같이 구조화된 데이터의
분석을 파이썬으로 할때 사용하는 것입니다.

1:18:31.030,1:18:34.469
여기 보이시는 pd가 pandas입니다.

1:18:35.170,1:18:39.120
pd.read_csv() 를 이용해서 csv파일을
읽어들일 수 있고, 내부를 살펴볼 수 있습니다.

1:18:39.120,1:18:42.059
보시면 아시겠지만, 식별자(ID) 같은게 있구요

1:18:42.580,1:18:46.260
그리고 개 품종이 있습니다.

1:18:46.260,1:18:50.480
이 방식이 이미지에 대한 레이블을 제공하기위해 
두번째로 주로 사용되는 방식입니다.

1:18:50.480,1:18:53.360
첫번째 방식은 서로다른 이미지 종류를
서로다른 폴더에 넣는것 말입니다.

1:18:53.360,1:18:59.800
두번째 방식은 csv파일 같은것을 던져주고
그 파일 내용으로 어떤 이미지가 있는지 알려주죠

1:19:00.070,1:19:02.489
여기서는 breed가 레이블이에요

1:19:04.359,1:19:06.359
그리고 나서 제가 한 일은

1:19:06.820,1:19:10.019
pandas를 다시 사용해서 데이터를 그룹화하기 위해
피벗 테이블을 만들었습니다.

1:19:10.120,1:19:15.780
각 품종마나 얼마나 많은 사진이 있는지
정렬해서 확인했고, 

1:19:15.780,1:19:20.220
많은 사진이 있는 품종은 약 100장부터

1:19:20.800,1:19:24.689
적은 사진이 있는 품종은 60장 정도 되었습니다.

1:19:25.269,1:19:30.239
총 120열이 있는데, 120가지 품종이
있다는걸 의미합니다.

1:19:30.760,1:19:34.079
이 이후엔, 보여드린 단계를 하나씩 수행할 겁니다.

1:19:35.260,1:19:42.780
첫번째로는 data augmentation의 활성화로
tfms_from_model()을 변형방식을 파라메터로

1:19:43.020,1:19:48.580
주면서 호출하면 됩니다. 저는 side_on을 전과 동일하게
선택 했습니다. 전과 비슷한 개에 대한 사진이니까요

1:19:49.560,1:19:52.340
max_zoom 에 대해서는 나중에
더 자세히 다루겠습니다.

1:19:52.539,1:20:00.148
간단하게 max_zoom은 augmentation을 수행할 때
확대하고자하는 최대치를 의미합니다.

1:20:00.789,1:20:07.349
여기서는 그 최대치로 1.1을 설정했습니다.
원본 이미지가 1이고, 1.1까지 허용하는 것이죠

1:20:07.389,1:20:13.618
많이 확대하는게 아니어서, 사진의 모서리 같은
작은 부분들만 잘려나갈 거에요.

1:20:14.409,1:20:18.239
여기까지 한 이후의 단계는 from_csv를 
사용하는 것입니다.

1:20:19.269,1:20:25.799
전에는 from_path를 사용했었죠. 폴더들의
이름 자체가 레이블의 이름으로 사용 됐었죠

1:20:25.800,1:20:28.100
여기서는 from_csv를 사용하고

1:20:28.200,1:20:31.480
레이블 내용이 들어있는
csv 파일을 파라메터로 줍니다.

1:20:31.480,1:20:35.540
다시 정리해보면, 첫번째는
모든 데이터가 포함된 경로이고

1:20:35.820,1:20:41.060
두번째는 학습 데이터가 포함된 폴더 이름,
세번째는 레이블 내용이 들어 있는 csv 파일 이름

1:20:41.900,1:20:46.260
그리고 테스트 데이터셋이 위치한 폴더도 알려줘야 합니다. 

1:20:46.260,1:20:49.300
다음주에 Kaggle에 결과를 제출하는 방법에
대해서도 이야기 하게 될거구요.

1:20:49.540,1:20:51.140
일단 오늘은

1:20:52.510,1:20:57.959
ㅁㅁㅁ

1:20:58.300,1:21:03.449


1:21:04.030,1:21:05.499


1:21:05.499,1:21:08.909


1:21:09.130,1:21:13.089


1:21:13.670,1:21:15.879


1:21:16.430,1:21:20.440


1:21:22.460,1:21:26.679


1:21:27.050,1:21:31.779


1:21:32.030,1:21:39.190


1:21:39.710,1:21:47.679


1:21:48.590,1:21:56.259


1:21:56.510,1:22:00.790


1:22:01.880,1:22:05.889


1:22:06.140,1:22:09.430


1:22:11.090,1:22:15.040


1:22:15.830,1:22:17.480


1:22:17.480,1:22:18.680


1:22:18.680,1:22:20.480


1:22:20.480,1:22:24.580


1:22:26.640,1:22:34.279


1:22:35.310,1:22:37.310


1:22:41.940,1:22:43.500


1:22:43.500,1:22:50.629


1:22:52.350,1:22:55.309


1:22:57.600,1:22:59.600


1:23:00.330,1:23:02.330


1:23:02.429,1:23:08.479


1:23:08.790,1:23:13.159


1:23:13.350,1:23:18.709


1:23:19.710,1:23:21.710


1:23:22.320,1:23:25.219


1:23:25.890,1:23:28.939


1:23:29.580,1:23:36.739


1:23:37.290,1:23:41.269


1:23:41.520,1:23:42.020


1:23:42.020,1:23:48.649


1:23:48.800,1:23:50.840


1:23:52.260,1:23:55.699


1:23:56.040,1:24:02.359


1:24:02.360,1:24:04.940


1:24:04.940,1:24:10.609


1:24:10.890,1:24:16.519


1:24:17.219,1:24:20.149


1:24:20.670,1:24:24.859


1:24:25.290,1:24:29.779


1:24:30.090,1:24:35.659


1:24:35.659,1:24:38.999


1:24:39.880,1:24:47.130


1:24:47.679,1:24:51.509


1:24:52.060,1:24:53.580


1:24:53.580,1:24:58.830


1:25:00.010,1:25:02.040


1:25:04.389,1:25:08.909


1:25:08.909,1:25:14.459


1:25:15.760,1:25:17.760


1:25:18.639,1:25:23.789


1:25:25.060,1:25:27.449


1:25:27.969,1:25:33.928


1:25:34.239,1:25:41.098


1:25:41.920,1:25:45.899


1:25:45.900,1:25:48.480


1:25:48.480,1:25:52.589


1:25:53.139,1:25:56.909


1:25:58.060,1:26:03.029


1:26:03.909,1:26:07.319


1:26:07.960,1:26:10.889


1:26:10.889,1:26:16.379


1:26:16.960,1:26:23.520


1:26:23.520,1:26:25.520


1:26:27.940,1:26:34.799


1:26:39.179,1:26:41.689


1:26:44.909,1:26:52.129


1:26:54.030,1:26:55.679


1:26:55.679,1:26:57.449


1:26:57.449,1:27:00.949


1:27:00.949,1:27:07.699


1:27:08.909,1:27:12.919


1:27:12.920,1:27:17.599


1:27:18.630,1:27:24.799


1:27:24.800,1:27:26.800


1:27:27.449,1:27:33.049


1:27:34.530,1:27:41.300


1:27:41.519,1:27:43.519


1:27:44.010,1:27:46.489


1:27:47.369,1:27:50.328


1:27:51.119,1:27:53.119


1:27:53.940,1:27:55.940


1:27:56.489,1:28:01.458


1:28:03.059,1:28:06.228


1:28:07.709,1:28:09.739


1:28:11.639,1:28:15.018


1:28:15.019,1:28:19.639


1:28:19.639,1:28:21.209


1:28:21.209,1:28:22.349


1:28:22.349,1:28:24.469


1:28:27.389,1:28:29.179


1:28:29.179,1:28:32.149


1:28:32.280,1:28:37.489


1:28:38.130,1:28:39.440


1:28:39.440,1:28:44.929


1:28:44.929,1:28:48.408


1:28:48.850,1:28:54.720


1:28:55.420,1:29:01.500


1:29:02.320,1:29:04.710


1:29:04.990,1:29:11.969


1:29:11.970,1:29:13.090


1:29:13.090,1:29:16.410


1:29:17.050,1:29:20.490


1:29:21.700,1:29:23.200


1:29:23.200,1:29:29.189


1:29:30.280,1:29:34.319


1:29:35.020,1:29:40.080


1:29:40.270,1:29:43.379


1:29:44.170,1:29:47.670


1:29:48.040,1:29:52.950


1:29:53.770,1:29:58.560


1:29:58.810,1:30:03.780


1:30:04.570,1:30:10.680


1:30:11.350,1:30:17.939


1:30:17.940,1:30:19.940


1:30:21.190,1:30:22.440


1:30:22.440,1:30:29.250


1:30:30.040,1:30:34.410


1:30:34.410,1:30:38.939


1:30:38.940,1:30:43.020


1:30:44.500,1:30:49.740


1:30:49.810,1:30:52.709


1:30:53.320,1:30:54.610


1:30:54.610,1:30:56.440


1:30:56.440,1:31:00.450


1:31:00.850,1:31:03.579


1:31:04.580,1:31:06.580


1:31:06.830,1:31:10.000


1:31:10.000,1:31:12.939


1:31:12.940,1:31:18.190


1:31:18.770,1:31:25.479


1:31:25.670,1:31:30.069


1:31:30.350,1:31:36.340


1:31:37.190,1:31:44.829


1:31:44.830,1:31:52.030


1:31:53.120,1:31:58.750


1:32:00.530,1:32:02.530


1:32:02.630,1:32:04.630


1:32:05.150,1:32:08.199


1:32:09.170,1:32:11.170


1:32:11.480,1:32:16.719


1:32:17.660,1:32:19.660


1:32:20.000,1:32:22.929


1:32:22.930,1:32:27.159


1:32:27.740,1:32:35.650


1:32:36.170,1:32:37.220


1:32:37.220,1:32:41.949


1:32:41.950,1:32:49.780


1:32:52.160,1:32:58.720


1:32:59.720,1:33:07.449


1:33:08.120,1:33:13.270


1:33:13.270,1:33:17.589


1:33:18.289,1:33:19.939


1:33:19.939,1:33:21.939


1:33:22.610,1:33:28.269


1:33:28.579,1:33:31.629


1:33:32.840,1:33:36.249


1:33:36.249,1:33:39.909


1:33:39.909,1:33:45.398


1:33:45.399,1:33:50.589


1:33:50.899,1:33:52.929


1:33:52.929,1:33:59.379


1:33:59.840,1:34:02.229


1:34:03.260,1:34:08.949


1:34:08.949,1:34:10.789


1:34:10.789,1:34:12.499


1:34:12.499,1:34:19.089


1:34:19.090,1:34:26.229


1:34:26.630,1:34:28.630


1:34:29.209,1:34:32.349


1:34:32.349,1:34:37.478


1:34:37.479,1:34:39.479


1:34:43.610,1:34:47.349


1:34:48.199,1:34:50.199


1:34:50.869,1:34:55.629


1:34:56.510,1:35:01.329


1:35:01.329,1:35:05.708


1:35:06.709,1:35:10.629


1:35:12.199,1:35:15.339


1:35:17.209,1:35:22.839


1:35:22.840,1:35:25.929


1:35:26.599,1:35:28.599


1:35:29.869,1:35:34.089


1:35:34.090,1:35:37.090


1:35:37.809,1:35:39.809


1:35:42.219,1:35:44.669


1:35:44.670,1:35:50.850


1:35:50.850,1:35:57.120


1:35:57.310,1:36:00.330


1:36:00.429,1:36:02.380


1:36:02.380,1:36:07.980


1:36:07.980,1:36:13.589


1:36:13.870,1:36:20.519


1:36:20.770,1:36:25.199


1:36:25.199,1:36:29.279


1:36:29.800,1:36:36.480


1:36:37.060,1:36:41.789


1:36:42.699,1:36:46.499


1:36:47.050,1:36:51.029


1:36:51.030,1:36:54.659


1:36:55.179,1:36:58.859


1:37:00.179,1:37:01.330


1:37:01.330,1:37:03.040


1:37:03.040,1:37:05.129


1:37:05.130,1:37:10.199


1:37:10.270,1:37:15.270


1:37:15.270,1:37:21.749


1:37:22.690,1:37:27.899


1:37:28.480,1:37:33.779


1:37:34.570,1:37:36.570


1:37:36.610,1:37:41.190


1:37:41.949,1:37:43.949


1:37:45.280,1:37:47.610


1:37:48.610,1:37:55.880


1:37:57.030,1:38:04.280


1:38:06.929,1:38:11.539


1:38:11.540,1:38:14.959


1:38:16.170,1:38:21.500


1:38:22.800,1:38:25.670


1:38:25.670,1:38:30.230


1:38:30.230,1:38:36.109


1:38:36.110,1:38:38.110


1:38:39.660,1:38:41.660


1:38:46.350,1:38:51.949


1:38:53.780,1:38:58.820


1:38:59.640,1:39:06.559


1:39:12.600,1:39:19.249


1:39:19.250,1:39:21.290


1:39:21.290,1:39:27.649


1:39:28.170,1:39:30.170


1:39:33.510,1:39:40.880


1:39:42.870,1:39:45.559


1:39:46.560,1:39:50.600


1:39:51.150,1:39:57.080


1:39:59.910,1:40:02.719


1:40:04.080,1:40:06.709


1:40:08.559,1:40:13.319


1:40:13.420,1:40:18.479


1:40:19.300,1:40:24.449


1:40:25.989,1:40:29.518


1:40:30.429,1:40:35.219


1:40:35.559,1:40:43.109


1:40:43.780,1:40:45.510


1:40:45.510,1:40:46.840


1:40:46.840,1:40:52.409


1:40:52.989,1:40:57.328


1:40:58.119,1:41:03.509


1:41:03.820,1:41:08.729


1:41:08.729,1:41:15.479


1:41:16.630,1:41:22.679


1:41:23.590,1:41:26.519


1:41:29.499,1:41:34.289


1:41:34.289,1:41:39.958


1:41:40.539,1:41:43.859


1:41:45.010,1:41:47.010


1:41:48.429,1:41:54.388


1:41:55.090,1:41:59.699


1:42:01.949,1:42:04.158


1:42:05.130,1:42:10.069


1:42:11.579,1:42:13.289


1:42:13.289,1:42:15.589


1:42:16.409,1:42:20.538


1:42:23.099,1:42:27.558


1:42:27.559,1:42:31.819


1:42:39.659,1:42:44.538


1:42:44.729,1:42:50.239


1:42:50.729,1:42:53.689


1:42:55.530,1:43:01.639


1:43:02.550,1:43:03.809


1:43:03.809,1:43:10.819


1:43:12.780,1:43:15.739


1:43:16.289,1:43:21.049


1:43:21.719,1:43:24.408


1:43:25.349,1:43:27.529


1:43:28.199,1:43:30.059


1:43:30.059,1:43:32.268


1:43:33.719,1:43:39.138


1:43:39.139,1:43:41.839


1:43:41.840,1:43:46.969


1:43:46.969,1:43:51.498


1:43:52.559,1:43:58.248


1:43:58.249,1:44:03.469


1:44:03.900,1:44:09.769


1:44:10.709,1:44:12.709


1:44:14.439,1:44:16.559


1:44:18.639,1:44:22.679


1:44:22.679,1:44:28.199


1:44:28.659,1:44:31.498


1:44:31.659,1:44:37.409


1:44:37.409,1:44:38.429


1:44:38.429,1:44:39.159


1:44:39.159,1:44:45.149


1:44:48.090,1:44:49.929


1:44:49.929,1:44:55.289


1:44:55.290,1:45:02.219


1:45:06.010,1:45:10.170


1:45:10.840,1:45:13.980


1:45:14.800,1:45:20.639


1:45:22.090,1:45:24.210


1:45:24.210,1:45:30.179


1:45:30.179,1:45:33.839


1:45:33.969,1:45:40.019


1:45:40.210,1:45:45.419


1:45:45.820,1:45:50.340


1:45:50.949,1:45:55.499


1:45:55.570,1:45:59.520


1:45:59.590,1:46:02.849


1:46:03.489,1:46:11.039


1:46:11.920,1:46:18.989


1:46:19.869,1:46:22.859


1:46:33.820,1:46:35.820


1:46:38.920,1:46:43.109


1:46:44.619,1:46:51.299


1:46:51.940,1:46:56.639


1:46:57.880,1:47:02.190


1:47:03.310,1:47:05.310


1:47:05.560,1:47:08.160


1:47:10.880,1:47:13.040


1:47:17.130,1:47:20.839


1:47:20.840,1:47:25.429


1:47:26.310,1:47:31.850


1:47:33.510,1:47:36.679


1:47:37.260,1:47:40.610


1:47:41.010,1:47:45.920


1:47:46.020,1:47:50.779


1:47:50.780,1:47:56.480


1:47:57.449,1:47:59.449


1:48:00.179,1:48:02.658


1:48:05.969,1:48:07.940


1:48:07.940,1:48:11.839


1:48:13.670,1:48:15.670


1:48:16.760,1:48:22.900


1:48:24.860,1:48:28.420


1:48:29.840,1:48:31.960


1:48:31.960,1:48:37.870


1:48:38.000,1:48:41.830


1:48:42.170,1:48:46.330


1:48:46.880,1:48:52.390


1:48:53.300,1:48:55.300


1:48:57.110,1:49:03.699


1:49:04.520,1:49:06.230


1:49:06.230,1:49:13.060


1:49:14.750,1:49:18.879


1:49:19.550,1:49:26.350


1:49:26.350,1:49:30.309


1:49:31.610,1:49:36.489


1:49:36.890,1:49:41.289


1:49:41.930,1:49:43.930


1:49:44.090,1:49:49.299


1:49:49.670,1:49:54.699


1:49:54.699,1:49:58.779


1:49:59.420,1:50:05.710


1:50:06.590,1:50:11.080


1:50:11.840,1:50:14.710


1:50:14.710,1:50:19.120


1:50:19.120,1:50:24.219


1:50:24.219,1:50:28.239


1:50:28.790,1:50:31.149


1:50:31.429,1:50:36.399


1:50:36.400,1:50:38.400


1:50:38.570,1:50:42.009


1:50:42.770,1:50:49.029


1:50:49.030,1:50:54.219


1:50:54.219,1:50:58.479


1:50:58.480,1:51:00.320


1:51:00.320,1:51:07.690


1:51:08.119,1:51:09.440


1:51:09.440,1:51:11.329


1:51:11.329,1:51:13.779


1:51:13.780,1:51:20.559


1:51:20.659,1:51:22.309


1:51:22.309,1:51:28.779


1:51:28.780,1:51:32.050


1:51:34.099,1:51:38.049


1:51:39.440,1:51:42.129


1:51:42.829,1:51:45.729


1:51:46.520,1:51:47.869


1:51:47.869,1:51:55.719


1:51:58.280,1:52:04.690


1:52:05.750,1:52:08.949


1:52:09.980,1:52:11.179


1:52:11.179,1:52:13.209


1:52:13.969,1:52:19.328


1:52:21.020,1:52:22.909


1:52:22.909,1:52:27.429


1:52:27.429,1:52:31.359


1:52:31.880,1:52:37.719


1:52:39.860,1:52:44.770


1:52:46.040,1:52:52.390


1:52:54.470,1:52:56.470


1:52:58.640,1:53:00.640


1:53:01.100,1:53:03.100


1:53:03.140,1:53:05.140


1:53:05.450,1:53:10.599


1:53:10.600,1:53:14.140


1:53:16.190,1:53:21.760


1:53:24.980,1:53:26.980


1:53:27.440,1:53:31.690


1:53:31.730,1:53:36.160


1:53:36.500,1:53:39.850


1:53:40.850,1:53:45.399


1:53:46.010,1:53:52.780


1:53:53.840,1:53:59.559


1:53:59.690,1:54:01.690


1:54:02.390,1:54:04.629


1:54:04.630,1:54:09.460


1:54:10.490,1:54:12.999


1:54:13.760,1:54:16.419


1:54:16.420,1:54:23.710


1:54:23.710,1:54:29.530


1:54:30.140,1:54:31.700


1:54:31.700,1:54:32.720


1:54:32.720,1:54:34.300


1:54:34.300,1:54:37.300


1:54:37.340,1:54:39.909


1:54:40.400,1:54:41.960


1:54:41.960,1:54:44.859


1:54:44.950,1:54:49.090


1:54:50.660,1:54:57.609


1:54:59.000,1:55:01.000


1:55:01.670,1:55:08.770


1:55:09.800,1:55:17.350


1:55:18.020,1:55:23.919


1:55:24.140,1:55:29.409


1:55:30.020,1:55:35.859


1:55:35.860,1:55:42.100


1:55:42.800,1:55:44.800


1:55:45.830,1:55:47.300


1:55:47.300,1:55:52.029


1:55:52.100,1:55:59.379


1:55:59.380,1:56:03.219


1:56:03.860,1:56:09.250


1:56:09.250,1:56:13.750


1:56:14.510,1:56:17.199


1:56:17.199,1:56:22.928


1:56:25.460,1:56:26.810


1:56:26.810,1:56:33.370


1:56:34.159,1:56:36.159


1:56:36.469,1:56:43.719


1:56:43.719,1:56:49.448


1:56:49.449,1:56:56.979


1:56:56.980,1:56:58.489


1:56:58.489,1:57:00.489


1:57:00.679,1:57:02.679


1:57:02.840,1:57:08.620


1:57:08.989,1:57:11.859


1:57:12.560,1:57:14.560


1:57:14.720,1:57:19.059


1:57:19.970,1:57:22.659


1:57:23.450,1:57:28.539


1:57:29.660,1:57:31.839


1:57:32.870,1:57:38.260


1:57:38.450,1:57:42.789


1:57:44.870,1:57:49.300


1:57:49.940,1:57:51.940


1:57:52.100,1:57:57.249


1:57:57.830,1:58:03.010


1:58:03.740,1:58:10.269


1:58:11.090,1:58:13.090


1:58:13.550,1:58:16.059


1:58:16.820,1:58:18.820


1:58:19.160,1:58:21.160


1:58:21.200,1:58:27.729


1:58:29.450,1:58:31.420


1:58:31.420,1:58:36.220


1:58:36.290,1:58:40.330


1:58:41.000,1:58:43.000


1:58:43.340,1:58:50.440


1:58:50.990,1:58:53.109


1:58:53.180,1:58:59.349


1:58:59.350,1:59:02.289


1:59:02.290,1:59:05.620


1:59:06.170,1:59:08.530


1:59:09.140,1:59:11.800


1:59:13.190,1:59:16.000


1:59:16.640,1:59:22.660


1:59:23.190,1:59:25.460


1:59:26.010,1:59:31.250


1:59:32.099,1:59:38.119


1:59:38.429,1:59:42.379


1:59:43.080,1:59:48.679


1:59:48.840,1:59:54.500


1:59:55.139,2:00:00.919


2:00:01.440,2:00:03.679


2:00:04.590,2:00:11.630


2:00:12.690,2:00:17.149


2:00:18.030,2:00:22.580


2:00:23.520,2:00:24.570


2:00:24.570,2:00:26.900


2:00:27.510,2:00:33.260


2:00:33.530,2:00:36.349


2:00:37.170,2:00:39.170


2:00:40.199,2:00:42.199


2:00:43.530,2:00:50.239


2:00:50.310,2:00:52.310


2:00:52.710,2:00:57.409


2:00:59.040,2:01:00.869


2:01:00.869,2:01:02.869


2:01:03.780,2:01:07.070


2:01:08.730,2:01:10.730


2:01:11.010,2:01:16.010


2:01:16.010,2:01:18.010


2:01:18.540,2:01:24.560


2:01:24.599,2:01:29.839


2:01:30.610,2:01:34.239


2:01:34.940,2:01:36.940


2:01:37.010,2:01:38.750


2:01:38.750,2:01:43.659


2:01:45.500,2:01:47.500


2:01:48.650,2:01:56.409


2:01:57.800,2:02:02.560


2:02:05.480,2:02:07.689


2:02:08.960,2:02:13.659


2:02:13.660,2:02:19.180


2:02:19.340,2:02:22.060


2:02:23.780,2:02:27.639


2:02:31.010,2:02:34.119


2:02:36.020,2:02:37.430


2:02:37.430,2:02:39.230


2:02:39.230,2:02:41.230


2:02:41.510,2:02:44.739


2:02:45.410,2:02:47.410


2:02:49.490,2:02:53.920


2:02:54.890,2:02:58.900


2:03:00.020,2:03:01.610


2:03:01.610,2:03:04.389


2:03:05.180,2:03:07.180


2:03:08.520,2:03:10.520


2:03:10.990,2:03:14.879


2:03:16.000,2:03:18.299


2:03:18.970,2:03:21.119


2:03:21.190,2:03:26.609


2:03:26.710,2:03:29.640


2:03:30.460,2:03:32.460


2:03:33.190,2:03:38.790


2:03:38.790,2:03:45.990


2:03:46.180,2:03:48.180


2:03:48.430,2:03:52.439


2:03:52.750,2:03:55.109


2:03:55.720,2:04:02.970


2:04:02.970,2:04:04.970


2:04:05.680,2:04:10.019


2:04:11.410,2:04:16.260


2:04:18.190,2:04:20.879


2:04:22.510,2:04:24.510


2:04:25.270,2:04:28.950


2:04:28.950,2:04:33.839


2:04:33.840,2:04:34.600


2:04:34.600,2:04:39.419


2:04:39.820,2:04:45.600


2:04:47.080,2:04:50.039


2:04:50.040,2:04:55.379


2:04:56.680,2:04:58.680


2:04:58.990,2:05:03.059


2:05:04.060,2:05:05.610


2:05:05.610,2:05:11.190


2:05:11.440,2:05:17.069


2:05:17.260,2:05:22.990


2:05:25.970,2:05:30.820


2:05:31.460,2:05:37.390


2:05:37.540,2:05:39.540


2:05:39.950,2:05:45.249


2:05:45.440,2:05:49.150


2:05:49.150,2:05:54.400


2:05:55.100,2:05:58.990


2:05:59.180,2:06:01.930


2:06:02.570,2:06:04.570


2:06:05.600,2:06:07.600


2:06:11.330,2:06:18.400


2:06:19.100,2:06:25.059


2:06:25.870,2:06:31.570


2:06:32.630,2:06:38.199


2:06:38.900,2:06:40.100


2:06:40.100,2:06:42.100


2:06:42.530,2:06:44.530


2:06:44.960,2:06:46.460


2:06:46.460,2:06:47.870


2:06:47.870,2:06:49.870


2:06:51.110,2:06:53.650


2:06:53.810,2:06:59.110


2:07:00.560,2:07:01.670


2:07:01.670,2:07:08.170


2:07:08.170,2:07:10.170


2:07:11.749,2:07:14.858


2:07:16.159,2:07:18.159


2:07:18.800,2:07:22.869


2:07:23.629,2:07:27.309

