0:00:00.000,0:00:02.360
돌아오신걸 환영합니다

0:00:04.160,0:00:07.220
눈치채셨을지 모르지만
그동안 커뮤니티 포럼에서

0:00:07.220,0:00:10.500
학생들의 멋진 활동들이 있었는데요

0:00:10.500,0:00:11.380
한가지 소개해 드리자면

0:00:12.285,0:00:15.000
이 코스의 다른 학우를 위해서

0:00:15.005,0:00:18.215
도움이 되는 많은 자료들을

0:00:18.215,0:00:21.415
만들어서 이해를 도와 줬더군요

0:00:21.415,0:00:24.325
누군가를 가르치면서

0:00:24.325,0:00:27.115
스스로도 더 잘 이해하는 기회도

0:00:27.115,0:00:28.475
얻은것 같습니다

0:00:28.785,0:00:30.975
제가 Wiki 에 그 중 몇가지를

0:00:31.320,0:00:34.400
리스트업 해서 포스팅 해뒀습니다

0:00:34.860,0:00:35.860


0:00:36.300,0:00:39.100
reshamas라는 분이
입문자들을 위한

0:00:39.100,0:00:42.105
많은 튜토리얼을 작성하셨는데요

0:00:42.105,0:00:44.965
그 내용중 하나는
AWS 접속에 문제를 겪는 분들을 위해서

0:00:44.965,0:00:48.045
전체적으로 단계별로

0:00:48.045,0:00:50.540
어떻게 로그인하고

0:00:50.540,0:00:53.900
모든걸 정상동작 하게 만드는지 보여줍니다

0:00:53.940,0:00:56.240


0:00:57.340,0:01:00.260
스스로 상기하는 차원에서,
노트를 남기시길 원하시면

0:01:00.340,0:01:03.135
블로그 포스트를 작성하시거나

0:01:03.135,0:01:06.195
이분처럼 마크다운에 작성하셔도 좋습니다

0:01:06.195,0:01:09.285
전에 깃헙을 사용해보신 적이 없으면

0:01:09.285,0:01:12.185
좋은 훈련이 되기도 할 겁니다
깃헙에 올려두시면

0:01:12.185,0:01:15.080
다른 사람들도 볼 수 있습니다.
물론, 커뮤니티 포럼에 올려주셔도 됩니다

0:01:15.200,0:01:20.975
reshamas가 작성한

0:01:20.975,0:01:23.885
좀 더 심화적인 내용으로는
tmux 라는게 있습니다.

0:01:23.885,0:01:26.995
편리한 도구인데요

0:01:27.000,0:01:31.520
보여드릴게요

0:01:32.160,0:01:35.240
AWS 컴퓨터에 로그인 한 직후에

0:01:35.300,0:01:38.195
tmux a 명령을 실행하면

0:01:38.195,0:01:41.245
모든 윈도우 창이 모두 나타납니다

0:01:41.245,0:01:44.145
백그라운드에서 작업중인것을
포함해서

0:01:44.145,0:01:47.355
VIM 으로 편집중인 내용등을
보여주는데

0:01:47.360,0:01:52.460
원하는 창으로 들어갔다가
다른 창으로 이동도 가능합니다

0:01:53.200,0:01:55.720
이 내용에 관심이 있으시면

0:01:55.940,0:01:58.940
이 깃헙에 사용법에 대한 
튜토리얼이 있습니다

0:01:58.945,0:02:02.145
그리고 여기 깃헙에는
다른 많은 내용들도 있습니다.

0:02:02.145,0:02:05.305
멋지게 정리해 줬습니다

0:02:05.305,0:02:08.275
Apil Tamang이라는 분은

0:02:08.275,0:02:11.195
지난주에 대한 아주 멋진 요약을

0:02:11.195,0:02:12.365
적어주셨습니다

0:02:12.705,0:02:15.895
이 요약이 다루는건

0:02:16.560,0:02:20.720
우리가 한 중요한 일들과
왜 그것들을 해야 하는지에 대한 것입니다

0:02:21.200,0:02:24.340
지난주에 배운 내용들이 어떻게
서로 들어맞는지 궁금하시면

0:02:24.340,0:02:26.920
이 내용은 꽤나 도움이 많이 될 것 같습니다

0:02:27.200,0:02:30.145
2시간정도 우리가 한 내용을

0:02:30.145,0:02:32.625
1-2 페이지에 정리 해뒀거든요

0:02:32.980,0:02:37.560
또, Pavel Surmenok의 글도 정말 좋은데요

0:02:38.800,0:02:42.920
학습률 발견자에 대해서
깊이 있게 다룹니다

0:02:44.020,0:02:46.960
많은 분들이 더 많은 것을 알고 싶어하신
주제 인데요

0:02:46.960,0:02:48.460
특히나

0:02:48.720,0:02:51.725
딥러닝을 전에 공부해보신 분이라면

0:02:51.725,0:02:54.735
오랫동안 고통받던 문제에 대한
해결책이 될 수 있는데

0:02:54.740,0:02:58.540
아직까지 본 적이 없던 방법이기 때문입니다

0:02:59.240,0:03:03.695
이 글은 그 내용에 대해서 적은 것인데,
제가 이 글의 링크를

0:03:03.695,0:03:06.695
트위터에 올렸을때

0:03:06.695,0:03:09.815
엄청 많은 사람들이
공유를 했었습니다.

0:03:09.815,0:03:12.745
아주 인기 있었고, 수천번 정도
공유 됐던거 같습니다

0:03:12.745,0:03:13.705
Redek은

0:03:13.705,0:03:16.715
많은 멋진 내용을 포스팅 했는데요

0:03:16.715,0:03:19.615
그 중 PyTorch에 대한 현업 종사자의 가이드라는
글이 마음에 들더군요

0:03:19.615,0:03:22.345
이 글의 내용은 약간
심화 학생들을 위한건데

0:03:22.345,0:03:25.325
PyTorch를 전에 사용해보지
못했지만

0:03:25.325,0:03:28.780
기본적으로 숫자를 다루는
프로그래밍을 해보신 분들에게

0:03:29.040,0:03:31.600
파고들어 가보는데
도움을 주기도 합니다

0:03:31.600,0:03:34.980
어떻게 PyTorch가 다른지
빠르게 훑어볼 수도 있습니다

0:03:35.440,0:03:38.140
약간 흥미로운 연구 내용도 있는데요

0:03:38.145,0:03:41.195
학습률과 배치 크기사이의 관계에 
대한 것입니다

0:03:41.195,0:03:43.995
한 학생이 지난주에 물어본 내용이기도 하죠

0:03:44.000,0:03:48.580
정확히 그 내용에 대해서,
다른 학생이 분석한 글을 작성 했습니다

0:03:49.320,0:03:51.915
이 학생이 한 것은

0:03:51.915,0:03:54.595
서로다른 학습률과 배치크기를 시도해보고

0:03:54.595,0:03:57.195
각 결과를 비교해 본 것입니다

0:03:57.405,0:04:00.195
멋진 실험으로, 다른분들도
직접 해보시길 바랍니다

0:04:00.655,0:04:03.525
Redek이 또 다른 글을 적었는데요

0:04:03.605,0:04:06.595
일종의 연구적인 내용으로

0:04:06.595,0:04:09.655
어떻게 "재시작하는 확률적 경사하강법"이

0:04:09.735,0:04:12.535
함수에서 좀 더 일반화 가능한 지점을

0:04:12.535,0:04:15.565
발견할 수 있는지에  대한 것입니다

0:04:15.565,0:04:18.145
Redek은 그 지점을

0:04:18.145,0:04:21.175
좀더 직접적으로 발견하기 위한
측정법을 알아보고자 시도해봤습니다

0:04:21.175,0:04:23.935
그렇게 성공적이진 않지만, 꽤나
흥미로웠습니다

0:04:23.935,0:04:26.965
여기 다른 블로그 글은

0:04:26.965,0:04:30.375
초보자를 위한 CNN에 대한 내용도
있었습니다.

0:04:31.035,0:04:32.035


0:04:32.935,0:04:36.095
이 코스의 마지막 즈음 배우게 될 내용인데

0:04:36.095,0:04:39.365
아시다시피 우리가 ResNet을
사용 했었습니다.

0:04:39.375,0:04:42.165
Anand Saha라는 분이
아주 인상적으로

0:04:42.215,0:04:44.945
ResNet이 무엇이고

0:04:44.945,0:04:47.855
어떤 내용이 흥미로운지에 대하여

0:04:47.860,0:04:51.720
분석하는 글을 작성했습니다
이미 인터넷에서 많이 공유되는 글입니다

0:04:52.140,0:04:55.460
먼저 좀더 심화 내용을 확인해 보고 싶으신 분은

0:04:55.675,0:04:58.325
읽어보시기 바랍니다.
Apil Tamang도 비슷한

0:04:58.325,0:05:01.315
내용의 글을 작성했습니다

0:05:01.645,0:05:03.295
많은 자료들이

0:05:03.685,0:05:06.725
커뮤니티 포럼에 있는걸 보셨고

0:05:06.725,0:05:09.665
초보자 포럼(beginner forum)도 있습니다

0:05:09.665,0:05:12.600
그리고

0:05:13.340,0:05:20.620
멍청한 질문이라는건 없지만,
많은 주변사람들이 심화적인 내용을

0:05:20.860,0:05:23.565
이야기하는데 본인은 그렇지 않다면

0:05:23.565,0:05:26.565
초보자 포럼이 이를 도와줄 겁니다

0:05:26.565,0:05:29.445
그리고 본인 스스로가

0:05:29.475,0:05:32.535
심화 학생이라고 생각하고,
질문에 대한 대답을

0:05:32.535,0:05:35.445
도와줄 수 있다면 그렇게 해 주세요
단지 질문에 대답할때

0:05:35.445,0:05:38.215
사람들에게 친근한 방식으로

0:05:38.215,0:05:41.185
대답해주려고 노력해 주세요

0:05:41.185,0:05:45.420
1년 미만의 프로그래밍 경험과,
머신러닝을 해본적이 없다는 가정을 하고 말이죠

0:05:46.280,0:05:49.700
저는 이 클래스의

0:05:50.100,0:05:51.580
다른 학생들이

0:05:51.995,0:05:54.825
뭔가 기여할 수 있다고 느끼길 희망합니다.

0:05:54.825,0:05:57.080
단지 많은 사람들이

0:05:57.660,0:06:00.495
제 생각엔 전에 인터넷에 뭔가를
포스팅 해본적이 없는것 같은데

0:06:00.495,0:06:03.345
뭔가를 블로그 포스팅하기 위해서

0:06:03.345,0:06:06.205
특별한 사람일 필요는 없다는걸
기억해 주세요

0:06:06.205,0:06:09.055
생각나는걸 적고

0:06:09.275,0:06:12.275
인터넷에 올리세요

0:06:12.275,0:06:15.145
한가지 손쉬운 것은
포럼에 글을 올렸는데

0:06:15.145,0:06:18.125
상세한 부분까지 확신이 없다면

0:06:18.125,0:06:21.025
피드백을 받을 수 있는 기회가 있습니다.

0:06:21.025,0:06:23.795
"그건 그렇게 동작하는게 아니야,
대신 이렇게 동작하는거에요" 라던지

0:06:23.800,0:06:26.520
"이렇게 까지 생각한 부분이

0:06:26.520,0:06:29.060
아주 흥미로운 통찰력 이군요" 같은것 말이죠

0:06:29.620,0:06:32.635
지금까지 우리가 한 내용은

0:06:32.640,0:06:36.160
실무 종사자로서 받은 일종의
입문자용의 내용으로

0:06:36.400,0:06:41.040
이미지에 대한 컨볼루션 뉴럴넷을 다뤘습니다

0:06:41.060,0:06:43.860
이론적인 내용이나
왜 그렇게 동작하는지나

0:06:43.960,0:06:46.895
수학적인 내용에 대해선 아직
이야기 되지 않았습니다

0:06:46.895,0:06:49.935
하지만, 반면에

0:06:49.935,0:06:52.975
아주 잘 동작하는

0:06:52.975,0:06:56.165
모델을 만드는 방법을 배웠습니다

0:06:56.165,0:06:59.255
세계적 수준의 모델이죠

0:06:59.260,0:07:04.300
오늘 그 부분을 약간 리뷰하도록 하겠습니다

0:07:05.160,0:07:07.635
그리고 오늘은

0:07:07.635,0:07:10.565
CNN이 뭐고, 컨볼루션이 무엇이며

0:07:10.565,0:07:13.925
어떻게 동작하는지에 대한 이론적인 내용을
깊이있게 공부할 것입니다

0:07:14.080,0:07:17.100
그리고 나선, 여기 보이시는 원형의
각 단계에 대해서

0:07:17.160,0:07:20.075
딥러닝이 적용 가능한
어플리케이션 분야의 예를

0:07:20.075,0:07:23.175
소개할 것입니다

0:07:23.175,0:07:26.195
뉴럴넷 구조화된 데이터에
사용해서

0:07:26.195,0:07:29.175
로지스틱 이나, 금융 데이터와 같은 것에 대해서

0:07:29.175,0:07:32.305
뭔가를 예측하는 예를 소개할 것입니다.

0:07:32.305,0:07:35.365
그다음으로는 언어에 응용 되는,

0:07:35.365,0:07:38.685
보통 NLP라고 부르는 것으로
순환 구조의 뉴럴넷 을 사용하게 됩니다

0:07:39.055,0:07:41.945
네번째는 협업 필터링에 대한 것으로

0:07:42.545,0:07:45.575
추천 시스템 같은 것을 위한 것입니다

0:07:45.575,0:07:48.395
전에 우리가 한 이미지에 대한

0:07:48.395,0:07:51.405
CNN과 비슷한 것입니다.

0:07:51.405,0:07:54.365
이론적 디테일에 대한 설명 없이

0:07:54.365,0:07:57.395
우선 최신예 모델을 소개해 드리고

0:07:57.395,0:08:00.305
어떻게 모델을 만들어서, 동작시킬지를
알게 해드리는 것이죠

0:08:00.305,0:08:03.195
그리고 나서, 다시 역순으로 공부하게 됩니다

0:08:03.195,0:08:06.125
협업 필터링에 대해서

0:08:06.125,0:08:09.105
꽤 자세하게 파고들고,
내부적인 코드를 어떻게 작성하고

0:08:09.105,0:08:12.085
내부적으로 수학이 어떻게 적용되는지
공부하게 될 것입니다

0:08:12.085,0:08:15.095
그리고 동일한 과정을
구조화된 데이터 분석에도 진행합니다

0:08:15.095,0:08:17.985
그 다음으로는 CNN 이미지에 대해서
그렇게 하고

0:08:17.985,0:08:21.095
마지막으로는 순환 뉴럴넷(RNN)에 대해서
자세히 들여다 볼 것입니다

0:08:21.095,0:08:22.165


0:08:23.540,0:08:26.160
일단, 약간의 리뷰를 하면서

0:08:26.280,0:08:28.260
시작해 봅시다

0:08:28.580,0:08:30.000


0:08:30.695,0:08:33.655
그리고, 전에 건너뛰었던 부분에 대해서

0:08:33.655,0:08:36.655
약간 더 상세하게 이야기 해 보겠습니다

0:08:36.660,0:08:39.420
저는 모든 학생분들이

0:08:39.560,0:08:42.780
지난주의 개 품종에 관련된
숙제를 완료했다는걸

0:08:43.280,0:08:46.140
확인해 두고 싶습니다

0:08:46.140,0:08:49.840
기본적으로 배운 내용을
다른 종류의 데이터셋에 적용하는 것으로

0:08:49.840,0:08:52.120
가장 쉬운 예가
개 품종에 관련된 문제 입니다

0:08:52.140,0:08:55.240
모든 분들이 갖춰야할 모든 내용은
이 문제를 해결해 보는것으로 커버 됩니다

0:08:55.485,0:08:58.515
우선 첫번째로
어떻게 데이터셋을

0:08:58.515,0:09:01.305
다운로드 할지를 아셔야 합니다

0:09:01.305,0:09:03.955
데이터를 다운로드 할 수 있는
두 가지 장소가 있는데,

0:09:03.955,0:09:07.045
첫번째는 Kaggle이고

0:09:07.045,0:09:09.995
나머지 하나는 그 외의 장소입니다

0:09:09.995,0:09:12.985
그래서 우선

0:09:12.985,0:09:16.095
Kaggle에서 다운받아 보겠습니다

0:09:16.095,0:09:19.245
다운받기 위해서
Kaggle CLI 라는 것을

0:09:19.245,0:09:21.160
사용했는데요

0:09:22.360,0:09:25.235


0:09:25.240,0:09:27.900
일단 설치하기 전에

0:09:27.900,0:09:30.420
제 생각에는 이미 설치되어 있을 것 같습니다

0:09:31.700,0:09:32.700


0:09:33.595,0:09:36.455
네 맞아요, 사용중인 환경에 이미

0:09:36.525,0:09:39.215
설치가 되어 있습니다

0:09:39.215,0:09:42.215
이 명령어가 동작하는 방식은

0:09:42.215,0:09:45.175
Kaggle 웹 사이트에서 스크랩해서
다운로드를 진행하는데

0:09:45.175,0:09:48.315
Kaggle이 웹 사이트 구조를 바꾸면
정상 동작하지 않게 됩니다

0:09:48.315,0:09:51.335
Kaggle CLI를 사용하실때

0:09:51.335,0:09:54.135
Kaggle 웹사이트가 바뀐적이 있으면

0:09:54.140,0:09:57.185
Kaggle CLI의 가장 최신 버전을
사용 중 이신지

0:09:57.400,0:10:03.440
pip install kaggle-cli --upgrade
명령으로

0:10:03.700,0:10:06.480
체크 해 보시길 바랍니다.

0:10:06.485,0:10:09.885
이 명령을 수행하면

0:10:09.885,0:10:13.660
Kaggle CLI 포함 관련 라이브러리들이
모두 가장 최신 버전인지 확인합니다

0:10:13.660,0:10:15.880
여기까지 하셨다면

0:10:15.885,0:10:17.535
설명을 따라해 보시면 되는데

0:10:17.535,0:10:20.345
Rashma가 작성한 마크다운에

0:10:20.345,0:10:25.180
보시면, Kaggle CLI 관련 알아둬야 할
모든 내용이 들어 있습니다

0:10:25.940,0:10:29.220
간단하게 설명드리면

0:10:29.395,0:10:32.745
다음으로 하셔야 할 것은

0:10:32.975,0:10:34.965
kg download 명령 뒤에

0:10:35.965,0:10:38.305
사용자명과

0:10:38.715,0:10:41.515
패스워드를 적어주시고,
경연 제목을 적어 주셔야 합니다

0:10:41.515,0:10:44.605
kg download -u 사용자명 -p 패스워드 -c 경연이름

0:10:44.605,0:10:47.865
많은 학생분들이 경연이름으로 뭘 넣어야 할지

0:10:47.905,0:10:50.545
헷갈려 하시는데

0:10:50.545,0:10:53.735
브라우져의 주소창에 보시면
/c/ 뒤에서 부터 /data 전까지의

0:10:53.735,0:10:56.755
부분이 이 경연의 이름 입니다

0:10:56.760,0:10:59.920
여기선 planet-understanding-the-amazon-from-space
가 되는군요

0:11:00.320,0:11:03.265
Kaggle CLI로 다운로드 하기 전에

0:11:03.265,0:11:05.920
웹 사이트에서 한번은

0:11:05.920,0:11:08.780
Download를 클릭해주시기 바랍니다

0:11:08.780,0:11:12.080
최초에 한번은 경연에 대한
규칙에 동의를 해줘야 하기 때문입니다

0:11:12.085,0:11:13.945
만약 이 과정을 깜박 하시면

0:11:14.405,0:11:17.445
kg download 명령어가
규칙 동의하는걸 깜박하지 않았냐는

0:11:17.445,0:11:20.335
힌트를 줄 겁니다

0:11:20.335,0:11:23.445
만약 Kaggle을 사용자이름이 아니라

0:11:23.445,0:11:26.575
구글 계정 같은 것으로 로그인 하는경우엔

0:11:26.575,0:11:29.625
동작하지 않을 겁니다. 
이때는 비밀번호 찾기를 수행하면

0:11:29.625,0:11:32.635
Kaggle에서 일반 비밀번호를
보내줄 겁니다

0:11:32.635,0:11:35.775
여기까지가 Kaggle에서
다운로드를 하는 과정입니다

0:11:35.775,0:11:38.925
Kaggle에서 데이터셋을 다운로드 하면
그 경연에 관련된 데이터가

0:11:38.925,0:11:41.000
들어있는 폴더를 통째로 받게 됩니다.

0:11:41.420,0:11:44.520
뭔가의 이유로 이 방법을
사용하지 않을도 모르는데요

0:11:44.525,0:11:47.275
첫번째 이유는 데이터셋이 Kaggle에
없는 경우 입니다.

0:11:47.275,0:11:50.385
두번째 이유는 Kaggle에 있는 데이터셋 전부를

0:11:50.385,0:11:53.365
다운로드 하고 싶지 않은 경우입니다

0:11:53.365,0:11:56.345
예를 들어서, 오늘 보게될 이 화면에 있는

0:11:56.345,0:11:59.355
경연은 두가지 포맷으로

0:11:59.355,0:12:02.585
데이터셋을 제공합니다.
TIF와 JPG죠

0:12:02.585,0:12:05.700
TIF 데이터셋은 19GB 크기이고
JPG는 600MB 정도인데

0:12:05.760,0:12:09.040
두가지 모두를 다운받는 경우는
많이 없을 겁니다

0:12:09.385,0:12:12.335
이 경우에 사용 가능한
커뮤니티 포럼에서 누군가 말해준

0:12:12.340,0:12:15.280
멋진 툴을 소개해 드리고자 합니다.

0:12:17.680,0:12:22.780
크롬 브라우져의 확장 어플이 있는데요
CurlWget 이라는 이름입니다

0:12:23.420,0:12:26.360
CurlWget을 검색하셔서

0:12:26.360,0:12:28.200
설치하시면 됩니다

0:12:28.200,0:12:30.140
이미 설치가 완료 되었다면

0:12:30.140,0:12:33.175
ADDED TO CHROME 이라고 표시되게 됩니다

0:12:33.180,0:12:34.600
지금부터는

0:12:34.600,0:12:37.460
뭐든지 다운로드 받고 싶은게 있으면

0:12:37.560,0:12:40.900
일단 다운로드 버튼을 눌러서
그 파일의 다운로드가 시작되게 한 후

0:12:41.080,0:12:44.020
다운로드 중인걸 취소 합니다

0:12:44.020,0:12:46.560
그리고, 우측 상단에 보시면 
노란색 버튼이 추가된것이 보이실 겁니다

0:12:46.880,0:12:49.820
눌러보시면,
다운로드 하기 위한 명령이 나와 있습니다

0:12:50.140,0:12:52.240
이 명령을 복사해서

0:12:52.740,0:12:55.480
터미널(콘솔) 윈도우 창에다가

0:12:56.040,0:12:58.500
붙여 넣고

0:12:58.840,0:13:00.460
Enter를 누르시면

0:13:00.785,0:13:03.975
다운로드가 시작됩니다.
이 확장 어플이 하는 일은

0:13:04.080,0:13:06.740
쿠키라던지, 헤더등 그 파일을 다운로드하는데 
필요한 모든 내용을

0:13:07.060,0:13:10.020
긁어오는 것입니다

0:13:10.025,0:13:12.805
Kaggle 뿐만 아니라

0:13:12.805,0:13:15.805
TV 프로그램이나 다른 데에서도

0:13:15.805,0:13:18.755
유용하게 사용될 수 있는 프로그램입니다

0:13:18.760,0:13:21.080
로그인이나 다른 이유에 의해 가려진 모든 종류의

0:13:21.500,0:13:24.620
컨텐츠를 가져올 수 있는 것이죠

0:13:24.635,0:13:27.565
데이터 과학에도 꽤나 유용하게
사용 될 수 있는데

0:13:27.565,0:13:32.240
왜냐하면 비디오 같은걸 종종
콘솔창에서 분석해야 하기 때문입니다

0:13:32.900,0:13:34.780
지금까지
데이터를 구하기 위한

0:13:34.780,0:13:36.420
두 가지 방법을
소개 드렸습니다

0:13:36.835,0:13:38.205


0:13:39.445,0:13:42.455
그러면, 데이터를 구한 다음에는

0:13:42.455,0:13:45.225
모델을 만들어야 합니다

0:13:45.675,0:13:48.635
아시겠지만, 그 전에

0:13:48.635,0:13:51.635
데이터가 data라는 폴더에
들어 있다고 가정하고 있습니다

0:13:51.675,0:13:53.755
Notebook이 있는 폴더의

0:13:53.755,0:13:56.885
하위 폴더입니다

0:13:56.885,0:13:58.795
반드시 데이터를

0:13:59.315,0:14:02.005
data 폴더에 넣어야 하는건 아니라서

0:14:02.005,0:14:05.005
/home 이나 
다른 하드 드라이브나

0:14:05.005,0:14:06.740
어디든지 넣어도 됩니다.

0:14:07.140,0:14:10.175
courses/dl1 폴더 안을 확인해 보시면

0:14:10.175,0:14:13.015
data 폴더라는건 사실

0:14:13.015,0:14:15.415
다른 장소를 가리키는

0:14:15.715,0:14:18.785
심볼릭 링크라는걸 알 수 있습니다

0:14:18.785,0:14:21.635
어디든지 원하는 곳에
데이터를 넣어두고

0:14:21.635,0:14:24.775
단순히 심볼릭 링크를 걸어주시면 됩니다

0:14:24.775,0:14:28.045
심볼릭 링크를 사용해보신적이 없다면

0:14:28.045,0:14:31.135
리눅스의 얼라이어스나, 맥이나 윈도우즈의 바로가기와
비슷한 것이라고 보시면 됩니다.

0:14:31.315,0:14:34.385
꽤나 유용하고, 포럼에 가보시면

0:14:34.385,0:14:35.965
사용법에 대한 글이 있습니다.

0:14:36.315,0:14:38.825
심볼링 링크에 대한 다른 한가지 예로

0:14:38.825,0:14:41.495
Notebook이 있는 폴더에 있는

0:14:41.495,0:14:44.325
fastai 모듈도 심볼링 링크가 걸린것이고

0:14:44.325,0:14:46.620
실제로는 다른 장소에 있습니다.

0:14:48.280,0:14:53.335
리눅스에서 실제 저장된 장소가 어딘지
확인해 보고 싶으면

0:14:53.335,0:14:56.345
ls 명령에 -l 옵션을 줘서
폴더 내에 들어있는 것의 목록을

0:14:56.345,0:15:01.920
출력하면 됩니다
그러면 심볼링 링크가 걸린 곳을 확인 가능합니다

0:15:02.360,0:15:04.040


0:15:05.545,0:15:07.155


0:15:07.700,0:15:08.700


0:15:09.340,0:15:13.720
지금까지 우리가 한 것중에 약간
모호한게 있다면

0:15:13.720,0:15:15.620
모든걸 처음부터 끝까지 수행하는데

0:15:15.620,0:15:18.840
필요한 최소한의 코드양이
얼마나 되는가 입니다

0:15:18.845,0:15:21.935
여기 띄워진 화면을 넘어가지 않는
영역에서 보시는것이

0:15:21.935,0:15:25.385
고양이, 개를 분류하는 문제에 대한
세계적 수준의 결과물을 얻기 위해서

0:15:25.385,0:15:28.485
처음부터 끝까지 수행한 전체 과정 입니다

0:15:28.485,0:15:31.175
단 한가지 건너뛴 단계가 있는데

0:15:31.175,0:15:34.405
Kaggle에서 데이터를 다운로드 하고

0:15:34.405,0:15:36.745
압축을 푸는 과정 입니다.

0:15:37.095,0:15:40.075
말 그대로 모든 과정을
보여드리고 있는 겁니다

0:15:40.320,0:15:42.000


0:15:42.000,0:15:45.560
fastai 라이브러리를 임포트 합니다.
conv_learner를 임포트하면

0:15:45.560,0:15:48.980
기본적으로 다른 나머지것들을
모두 임포트 합니다

0:15:48.980,0:15:50.360


0:15:50.360,0:15:53.640
데이터셋이 있는 곳의 PATH를 지정해 주고

0:15:54.080,0:15:57.380
이미지 크기와, 배치 크기를 정해줍니다

0:15:57.380,0:15:57.880


0:15:58.575,0:16:01.575
tfms_from_model이 뭘 하는지
잠시후에 더 많이 배우게 되겠지만,

0:16:01.575,0:16:05.015
기본적으로 어떻게 데이터를
변형할지를 정의하는 겁니다

0:16:05.095,0:16:07.765
이 특정 모델에 알맞은 형태로

0:16:07.765,0:16:10.775
이미지 데이터를 변형하는데

0:16:10.775,0:16:13.775
이미지가 측면에서 촬영됐다고 가정하고 있고

0:16:13.775,0:16:16.565
최대 10% 확대를 허용하고 있습니다.

0:16:16.865,0:16:19.645
그리고 설정된 PATH에서

0:16:19.875,0:16:22.845
데이터를 가져오게 됩니다.

0:16:22.845,0:16:25.935
기억 하시겠지만, PATH 안에는
train, valid 같은 폴더가 있고

0:16:25.935,0:16:29.005
또 그 안에는 dogs와 cats 같은
같은 폴더가 있었죠.

0:16:29.005,0:16:31.660
한가지 알아두실건

0:16:31.660,0:16:35.455
train이나 valid의 폴더의 이름을 
다른 것으로 변경할 수 있는데요

0:16:35.455,0:16:38.465
데이터가 다른 폴더에 들어 있는 경우

0:16:38.465,0:16:41.645
그 폴더 이름을 train, valid로 변경해도 되지만

0:16:41.645,0:16:45.320
함수 옵션을 보시면, 폴더명을
이정해 줄 수도 있습니다.

0:16:45.800,0:16:46.360


0:16:46.360,0:16:49.720
또한 test에 대한 폴더 이름도 
지정 가능합니다

0:16:49.725,0:16:52.775
결과를 Kaggle에 제출하거나를 원하시면

0:16:52.775,0:16:55.415
레이블링되지 않은 테스트 데이터셋이

0:16:55.420,0:16:57.780
포함된 폴더명을 넣어줘야 합니다.

0:16:58.000,0:16:59.000


0:16:59.440,0:17:03.175
그리고 다음으로는 미리 학습된 
모델로부터 모델을 생성합니다

0:17:03.175,0:17:06.155
미리 학습된 모델로는 resnet50이 사용 되었고,

0:17:06.155,0:17:09.365
방금 생성한 data 객체를 넣어줍니다.
그리고나서 , fit() 메소드를 호출하게 됩니다

0:17:09.365,0:17:12.900
디폴트로는
마지막 몇개 계층을 제외한

0:17:12.900,0:17:16.860
모든 계층들이 freeze 됩니다.

0:17:17.640,0:17:19.840
그리고 결과가
보여지고요

0:17:19.840,0:17:20.340


0:17:20.540,0:17:23.725
약 2분 30초 정도 걸렸습니다

0:17:23.725,0:17:26.785
그리고  precompute=True를 설정하지
않았다는걸 알아두세요

0:17:26.785,0:17:30.480
이게 의미하는게 뭔지 약간 혼란스러운
분들이 계신것 같은데

0:17:30.880,0:17:33.605
단순히 첫번째 단계에서

0:17:33.605,0:17:36.585
뭔가를 빠르게 하기 위한 것입니다

0:17:36.585,0:17:39.665
그냥 건너뛰어도 상관 없는 부분입니다.

0:17:39.665,0:17:42.765
이 내용에 혼란을 느끼거나
이 내용이 어떤 문제를 일으킨다면

0:17:42.765,0:17:44.960
그냥 놔두고 건너뛰세요

0:17:45.680,0:17:48.595
단순히

0:17:48.595,0:17:51.375
몇 중간단계를 캐싱해서
재계산 할 필요 없게 만들어주는

0:17:51.380,0:17:55.400
일종의 지금길 입니다.
그리고 미리 계산된 activation을 사용할땐

0:17:55.400,0:17:57.515
data augmentation이

0:17:57.515,0:18:00.185
동작하지 않습니다.

0:18:00.185,0:18:03.285
data augmentati on을 요청했는데
precompute 값이 True이면

0:18:03.725,0:18:06.705
어떠한 data augmentation도 일어나지 않는 것이죠

0:18:06.705,0:18:10.040
왜나하면 캐시된 activation을 사용하기 때문입니다

0:18:10.680,0:18:13.665
여기서는 모든걸 가능한한 쉽게
설명드리기 위해서

0:18:13.665,0:18:16.525
precompute 부분을 포함시키지
않았습니다.

0:18:16.525,0:18:19.160
그리곤 길이가 1인 cycle을 세번 수행했습니다.

0:18:19.960,0:18:21.520
그 다음으로는

0:18:21.580,0:18:25.420
unfreeze를 호출해서, 이번엔
네트워크 전체가 학습되도록 설정 했습니다.

0:18:25.840,0:18:28.825
bn_freeze()를 그 다음으로 사용 했는데

0:18:28.825,0:18:31.935
아직 보지 못한 내용이고
잠시 후에 배우게 될 것인데

0:18:31.940,0:18:35.040
일단 지금 알아두셔야 할 
내용을 말씀드리겠습니다

0:18:35.040,0:18:36.860
resnet50나

0:18:37.185,0:18:40.075
resnext101 같이

0:18:40.075,0:18:43.385
엄청 크고 깊은 모델을 사용하는데

0:18:43.385,0:18:46.385
데이터셋이 개/고양이처럼

0:18:46.385,0:18:49.465
어떤 물체를 표준적인 방식으로

0:18:49.465,0:18:51.495
측면에서 촬영한 사진이

0:18:51.495,0:18:54.045
ImageNet의 데이터셋과

0:18:54.045,0:18:56.920
크기가 비슷한 200~500 픽셀 정도 된다면

0:18:57.820,0:19:01.280
아마도 unfreeze 할때

0:19:01.285,0:19:03.935
bn_freeze 함수를 
호출해야 할 겁니다

0:19:03.935,0:19:06.855
좀더 심화 학생들을 위한 설명은

0:19:06.855,0:19:09.935
batch normalization을 
평균쪽으로 움직여서

0:19:09.935,0:19:12.905
업데이트 하는 것입니다

0:19:12.905,0:19:15.955
이 코스의 중반 이후에
그게 무슨 의민지 배우게 될 겁니다

0:19:15.960,0:19:19.960
다른 라이브러리에서는 지원되지 않는데
꽤나 중요하다고 판단되는 것 중 하나입니다

0:19:19.960,0:19:22.535
쨋든 한번의 추가 에포크를

0:19:22.540,0:19:25.480
전체 네트워크를 학습시키기 위해 수행합니다

0:19:26.120,0:19:29.555
그리곤 마지막엔 TTA를 수행합니다

0:19:29.555,0:19:31.935
TTA를 수행해서
가능한한 최고의

0:19:31.935,0:19:34.815
예측 결과를 얻을 수 있도록 하는 것입니다

0:19:34.815,0:19:37.885
그래서 결과적으로
99.45%의 정확도를 얻었습니다

0:19:37.885,0:19:39.920
이게 전부 입니다

0:19:39.940,0:19:42.620
새로운 데이터를 가지고
시도하는 경우

0:19:43.025,0:19:46.085
지금까지 보여드린 것이

0:19:46.085,0:19:49.405
수행되어야 할 최소한의 과정 입니다.

0:19:49.405,0:19:52.445
그런데 여기서는 학습률 뭐로 사용할지

0:19:52.445,0:19:55.575
폴더 구조가 어떻게 생겼는지

0:19:55.575,0:19:58.815
이미 알고 있다고 가정한채
진행을 했습니다

0:19:59.065,0:20:00.105


0:20:01.285,0:20:03.905
쨋든 보여드린게
최소한의 과정입니다.

0:20:03.905,0:20:05.585
그리고, 한가지

0:20:06.255,0:20:09.325
fastai가 아닌 다른 라이브러리를 사용해서

0:20:09.325,0:20:12.355
동일한 과정을 어떻게 하는지
알려드리고 싶은데요

0:20:12.355,0:20:15.485
다른 라이브러리 중 설명드리기

0:20:15.485,0:20:18.745
가장 좋은 것은 Keras 입니다.

0:20:18.745,0:20:21.775
fastai가 PyTorch 위에 만들어진것 처럼

0:20:21.775,0:20:24.825
Keras도 다른 많은 종류의 백엔드 위에
만들어졌습니다.

0:20:24.825,0:20:27.435
요즘엔 대부분의 사람들이
백엔드로

0:20:27.435,0:20:28.795
TensorFlow를 사용합니다

0:20:29.105,0:20:31.835
하지만 MXNet (아마존) 또는

0:20:31.840,0:20:35.240
CNTK (마소) 를 백엔드로 사용할 수도 있습니다

0:20:36.700,0:20:40.180
git pull로 저장소 내용을 내려받으면

0:20:42.265,0:20:45.275
keras_lesson1 이라는 파일이 있는데요,

0:20:45.275,0:20:46.315
이 파일의 내용은

0:20:46.805,0:20:49.595
lesson1을 Keras로 동일하게
만들어 본 것입니다.

0:20:49.860,0:20:54.440
다른 라이브러리는 어떻게 하는지에 대한
느낌을 알게 해주기 위함이죠

0:20:57.320,0:21:01.175
일단 지금은 bn_freeze에 대해선
이야기 하지 않겠습니다.

0:21:01.180,0:21:06.060
단지, 모델이 resnet34보다 큰

0:21:06.180,0:21:09.480
resnet50 라던지 resnext101같은

0:21:09.485,0:21:12.455
모델을 사용할때

0:21:12.460,0:21:15.800
학습의 대상 데이터셋이

0:21:16.040,0:21:19.155
평범한 사진과 크기,
물체가 사진 전반을 차지하는등

0:21:19.155,0:21:21.945
ImageNet과 매우 유사하다면

0:21:21.945,0:21:24.865
unfreeze 이후에
learn.bn_freeze(True)를

0:21:24.865,0:21:27.895
아마도 추가해야 할 것입니다.

0:21:27.900,0:21:30.120
궁금하시면

0:21:30.120,0:21:33.600
bn_freeze 포함 또는 미포함
모두 학습을 시도해 보세요

0:21:33.600,0:21:37.420
좀더 심화 학생분들은 포럼에서
관련 내용을 토론하실 수 있겠지만

0:21:37.420,0:21:40.020
일단 저희는 전체 코스의 중반 이후인

0:21:40.020,0:21:43.080
CNN image in depth 부분에서

0:21:43.240,0:21:47.180
이 내용을 자세히 다룰 예정입니다.

0:21:51.640,0:21:54.620
Keras를 사용하는 법을 잠시 보여드리겠습니다

0:21:54.900,0:21:58.780
일단 이거저거 많이 임포트 합니다

0:21:58.780,0:22:00.780
그리고...

0:22:01.420,0:22:04.355
말씀드린것 처럼

0:22:04.355,0:22:07.405
train, valid 폴더,
그리고 dogs, cats 폴더 처럼

0:22:07.405,0:22:09.780
구조를 잡는건 레이블링된

0:22:09.780,0:22:13.320
이미지를 제공하는
일종의  표준적인 방식 입니다.

0:22:13.320,0:22:15.615
그리고 Keras도 이 방식을 사용합니다

0:22:15.620,0:22:19.780
어디에 학습용, 검증용 데이터셋이 있는지
배치 크기를 뭐로 설정할건지

0:22:19.960,0:22:24.040
알려줘야 하는거죠
(batch_size가 두번 정의되어서 삭제함)

0:22:24.140,0:22:27.145
보시다시피, Keras를 사용하면

0:22:27.145,0:22:31.040
전과 비교해서 훨씬 더 많은
코드가 동일한 일을 수행하는데 필요합니다

0:22:31.380,0:22:34.215
그리고 각 코드의 부분마다

0:22:34.215,0:22:37.125
설정해야할 값들이
아주 많습니다.

0:22:37.125,0:22:41.300
만약 값을 잘못 설정하면
모든게 망가져 버리겠죠

0:22:43.040,0:22:46.015
각 코드의 의미를 간단하게
요약해 드리겠습니다

0:22:46.020,0:22:48.520
기본적으로 Keras에서는

0:22:48.520,0:22:51.240
단 하나의 data 객체를 만들기 보단

0:22:51.240,0:22:54.195
일단 어떻게 data를 생성할지를 정하는

0:22:54.195,0:22:57.205
DataGenerator라는걸 정의 해야 합니다

0:22:57.205,0:23:01.220
DataGenerator 정의시, 어떤 종류의
data augmentation 을

0:23:01.220,0:23:04.100
하고 싶은지 명시 해주고

0:23:04.500,0:23:08.215
어떤 종류의 정규화 기법을 사용할지를

0:23:08.220,0:23:10.800
사용할지를 명시해줘야 합니다

0:23:10.800,0:23:12.320
반면에, fastai로는

0:23:12.540,0:23:15.435
뭐가 됐던지 ResNet50가

0:23:15.435,0:23:18.715
원하는게 있다면, 
그것을 해달라고 하기만 하면 됩니다.

0:23:18.715,0:23:21.735
뭐기 필요한지 야주 약간만 알면 됩니다

0:23:21.735,0:23:24.485
일반적으로, 인터넷에서 Keras 코드를
복사&붙여넣기 하면

0:23:24.485,0:23:28.440
잘 동작하는 코드라고 확신할 수 있습니다

0:23:29.240,0:23:32.165
그리고, Keras에는

0:23:32.165,0:23:35.045
표준적으로 가장 잘 동작하는

0:23:35.045,0:23:37.865
data augmentation 파라메터 값들이

0:23:37.865,0:23:40.915
정의되어 있지 않기 때문에,
여기 보시는 코드는 단순히

0:23:40.920,0:23:43.180
Keras 도큐먼트에서 복사해온 것입니다

0:23:43.180,0:23:45.035
최고의 파라메터

0:23:45.035,0:23:48.325
조합인지는 모르겠지만,
공식 문서에서 사용되는 것이라는 거죠

0:23:48.605,0:23:51.275
어떻게 data를 생성할지를

0:23:51.275,0:23:53.985
수평으로 뒤집거나 확대를 하거나

0:23:53.985,0:23:56.925
잘라내거나 하는 것으로 정의하고

0:23:56.925,0:23:59.705
그 내용을 기반으로 data 생성자 객체를
생성합니다

0:23:59.705,0:24:02.840
이때, 생성 대상이 되는 이미지가

0:24:02.880,0:24:06.015
들어있는 폴더를 지정해줍니다

0:24:06.020,0:24:08.100
fastai에서 사용하는 것과

0:24:08.120,0:24:11.240
동일한 폴더 구조를 가지는 폴더를
명시했습니다

0:24:11.480,0:24:14.560
몇 파라메터는 fastai 내용과

0:24:14.560,0:24:17.900
겹치는데요, 
생성하고자 하는 이미지의 크기라던지

0:24:17.900,0:24:20.575
미니 배치의 배치 크기라던지 말입니다

0:24:20.575,0:24:23.545
class_mode는 별로 자세히 안보셔도 되는데

0:24:23.545,0:24:25.935
예측 결과의 대상이 두가지인경우

0:24:25.935,0:24:28.465
'binary' 라고 적어주면 되고,

0:24:28.465,0:24:31.535
두가지 이상인 경우라면, 
"categorical" 이라고 적어주면 됩니다

0:24:31.535,0:24:34.915
여기서는 개냐? 고양이냐? 문제니까
'binary' 입니다

0:24:36.125,0:24:38.585
fastai 대비 좀 더

0:24:38.585,0:24:40.895
복잡해지는 부분으로는

0:24:40.895,0:24:43.725
검증 데이터셋에 대해서도
동일한 코드를 적어줘야 한다는 겁니다

0:24:43.725,0:24:46.995
TTA를 사용하지 않는다면 
data augmentation이 없는 data 생성자를

0:24:47.000,0:24:52.040
정의해 줘야 하는데,
직접 그런 부분까지 코드를 적어줘야 하는 것이죠

0:24:52.860,0:24:53.860
그리고

0:24:54.445,0:24:57.405
학습할때는 이미지들의 순서를

0:24:57.405,0:24:59.835
무작위로 섞어줘서, 무작위로 선택된

0:24:59.835,0:25:02.785
이미지들을 학습될 수 있도록 하는데

0:25:02.785,0:25:06.400
검증단계에서는 그러지 않아도 되므로
shuffle=False로 설정 하였습니다

0:25:06.400,0:25:09.015
검증 데이터셋을 무작위로 섞게 되면

0:25:09.015,0:25:12.505
모델이 얼마나 잘 하는지를 추적하지 못합니다
레이블과 순서가 달라지기 때문입니다

0:25:13.525,0:25:16.775
여기까지 보여드린 코드가
기본적으로 Keras를 사용하면

0:25:16.780,0:25:18.640
매번 작성해야 하는 것입니다

0:25:19.000,0:25:19.840


0:25:19.840,0:25:21.380
제가 이전 예제에서

0:25:21.385,0:25:24.415
ResNet50을 선택했던 이유는
Keras에는

0:25:24.415,0:25:27.385
ResNet34가 없기 때문인데,

0:25:27.385,0:25:30.065
fastai와 비교해보고 싶었기 때문입니다

0:25:30.260,0:25:31.260


0:25:32.200,0:25:35.120
그리고,
Keras에는 fastai와는 다르게

0:25:35.120,0:25:37.960
특정 데이터셋에 맞아 들어가는

0:25:37.960,0:25:41.115
모델을 생성하기 위한 방법이 없어서
직접 이부분을 코딩 해줘야 하죠

0:25:41.115,0:25:44.545
그 과정은 일단,
사용하려는 기본 모델을 생성하고

0:25:45.160,0:25:50.620
그 모델 위에 추가하려고하는
계층들을 직접 넣어줘야 합니다

0:25:51.500,0:25:54.415
이 코스 후반쯤 가면
왜 이 특정 3개의 계층이

0:25:54.420,0:25:57.820
추가됐는지를 알게 될 겁니다

0:25:59.020,0:26:01.915
여기까지 하면, 다음으로는

0:26:01.915,0:26:04.995
모델을 생성하면 되는데

0:26:05.125,0:26:08.175
Keras에서는 자동으로 freeze 하기위한

0:26:08.175,0:26:10.695
API가 없기 때문에

0:26:10.695,0:26:12.635
각 계층들을 loop 해서

0:26:12.985,0:26:15.835
freeze 하고자 하는 계층들에 대해서

0:26:15.835,0:26:19.105
trainable 값을 False로 설정해 줘야 합니다

0:26:19.755,0:26:22.875
또, Keras에는
fastai나 PyTorch에는 없는 개념인

0:26:22.875,0:26:25.895
모델을 컴파일(compile) 한다는 것이 있는데

0:26:25.895,0:26:29.045
일단 모델이 사용할 준비가 되었다면,
complie 해줘야 합니다.

0:26:29.045,0:26:31.855
이때, 어떤 optimizer를 사용할지
어떤 손실함수(loss) 를 사용할지

0:26:31.855,0:26:34.695
어떤 평가지표를 사용할지를
알려줘야 합니다.

0:26:35.140,0:26:38.100
fastai에서는 이런 것들을
알려줄 필요가 없습니다

0:26:38.100,0:26:41.220
어떤 것들을 사용할지 이미 정해져 있기 때문입니다

0:26:41.340,0:26:43.420
하지만, 이 디폴트 내용을

0:26:43.420,0:26:45.520
다른것으로 교체할 수도 있습니다

0:26:45.975,0:26:49.005
여기까지 완료 하게 되면
fastai에서 fit()을 호출한것과 다르게

0:26:49.005,0:26:51.785
Keras에서는 fit_generator()를 호출해야 합니다

0:26:51.785,0:26:55.280
이때, 앞에서 정의한
학습 데이터셋 생성자, 검증 데이터셋 생성자

0:26:55.280,0:26:58.200
두 개의 data 생성자를 넣어줘야 합니다

0:26:58.620,0:27:01.375
한가지 이해하기 힘든 부분이 있는데

0:27:01.375,0:27:04.185
Keras에서는 하나의 에포크에

0:27:04.185,0:27:07.165
몇개의 배치가 들어가는지를
알려줘야 합니다

0:27:07.165,0:27:11.240
학습 데이터셋이 크기를
배치 크기로 나눠줘야 하죠

0:27:11.880,0:27:15.360
그리고 에포크의 수를 알려줘야 하고

0:27:15.420,0:27:18.480
workers는 데이터 전처리에 사용되는

0:27:18.480,0:27:21.240
프로세스(작업자)의 수를 나타냅니다

0:27:21.440,0:27:23.600
fastai에도 있는 기능이지만

0:27:23.600,0:27:27.540
Keras에서는 디폴트로는 사용되지 않습니다

0:27:27.540,0:27:28.800


0:27:28.800,0:27:33.180
적당히 빠른 처리 속도를 원하면
workers 옵션을 포함 시키셔야 할 겁니다

0:27:33.480,0:27:36.415
기본적으로 여기까지가

0:27:36.420,0:27:41.300
추가된 마지막 계층들에 대한
미세조정을 하기 위한 코드 입니다

0:27:42.200,0:27:46.440
결과를 보시면, 검증 데이터셋에 대한
95%의 정확도를 얻었습니다

0:27:46.440,0:27:48.895
근데 95%로 도달하는 과정이 
약간 이상합니다

0:27:48.895,0:27:51.475
시작 했을때 49%인 정확도가

0:27:51.480,0:27:54.320
69%에서 95%로 변화 했습니다

0:27:54.760,0:27:58.080
왜 초반에 이렇게 낮은지 잘 모르겠군요.
제 생각엔 일반적이지 않은거 같아요

0:27:58.085,0:28:01.115
제 코드나, Keras에 버그가 있을지도 몰라서

0:28:01.115,0:28:04.125
누군가가 원인을 알아내주길
트위터에 글을 올렸는데요

0:28:04.125,0:28:06.775
아직까진 아무도 원인을 모릅니다

0:28:06.780,0:28:10.840
이러한 상황이
제가 fastai를 이 코스에서

0:28:10.840,0:28:13.675
사용하려는 이유 중 하나입니다.

0:28:13.675,0:28:16.675
뭔가를 망치기가 오히려 어렵거든요

0:28:16.680,0:28:19.780
제가 망치든 누군가가 망치든 말이에요

0:28:22.305,0:28:25.325
맞아요. 여기서 Keras의 백엔드는
TensorFlow가 사용 되었습니다

0:28:25.325,0:28:28.325
만약 이 코드를 직접 실행해 보고 싶으시면

0:28:28.325,0:28:31.335
Terminal 창에 가셔서

0:28:31.340,0:28:37.560
pip install tensorflow-gpu keras
명령을 실행해 주세요

0:28:38.000,0:28:40.735
fastai 환경의 일부가 아니니까

0:28:40.740,0:28:44.080
따로 설치해 주셔야 합니다

0:28:44.680,0:28:49.100
이 명령으로 설치되는 내용이
notebook 실행에 필요한 모든 것입니다

0:28:50.200,0:28:51.380


0:28:52.735,0:28:53.735
그리고

0:28:54.155,0:28:56.925
Keras에는 계층 그룹핑이나

0:28:56.925,0:28:59.855
차등 학습률이나,
부분적 unfreeze같은게 없습니다

0:28:59.855,0:29:02.865
그렇기 때문에, 뭘 하던지 간에

0:29:02.865,0:29:05.635
수동적으로 모든것을 적용해야 합니다

0:29:05.635,0:29:08.375
모든 계층들을 전부 출력해서
그 중 얼마나 많은 계층들을 미세조정할지

0:29:08.375,0:29:10.915
여기서는 140번째 이후의 모든 계층에 대해서

0:29:10.920,0:29:13.955
미세 조정을 적용 했습니다
미세 조정이 끝나면

0:29:13.960,0:29:16.740
다시한번 컴파일(compile)을
해 줘야 합니다

0:29:16.740,0:29:18.480
그리곤 학습을 다시 수행해야 하죠

0:29:18.975,0:29:21.785
다시 학습해도 마찬가지로

0:29:21.785,0:29:24.255
학습 데이터셋에 대한 정확도는
거의 비슷하게 유지 되었지만

0:29:24.260,0:29:27.220
검증 데이터셋에 대한 정확도에는
뭔가 문제가 있는거 같습니다

0:29:27.500,0:29:31.680
(잘못 말함)

0:29:31.680,0:29:34.740
Keras로 진행하면서
주로 알 수 있는 것은

0:29:35.020,0:29:38.375
약간 성가실 정도로
코드의 양이 많다는 것과

0:29:38.375,0:29:41.405
성능이 fastai와 비교해서
매우 다르다는 것입니다.

0:29:41.405,0:29:44.785
학습 데이터셋에 대해선 4번의 에포크 후에
97% 정도의 정확도를 얻었고

0:29:44.785,0:29:47.765
약 8분정도 소요 되었는데

0:29:47.765,0:29:51.255
fastai와 비교해 보면,

0:29:51.585,0:29:54.515
검증 데이터셋에 대한
정확도가 99.5% 정도이고

0:29:54.515,0:29:57.525
학습 시간도 약 4-5분 정도 걸려서

0:29:57.525,0:30:01.440
훨씰 빠르게 수행되었습니다

0:30:05.740,0:30:10.000
하시고자 하는 일이 뭔지에 따라 다릅니다

0:30:10.020,0:30:13.360
만약 모바일 기기로 배포해야 한다면

0:30:13.735,0:30:16.565
모바일에 대한 PyTorch의 지원은

0:30:16.565,0:30:19.075
아직 초기 단계이기 때문에

0:30:19.075,0:30:22.115
TensorFlow를 사용해야 할지도 모릅니다

0:30:22.115,0:30:25.035
또는 몸담고 있는 회사가

0:30:25.035,0:30:28.125
TensorFlow를 사용하기로
이미 결정했다면 이를 사용해야 하겠지요

0:30:28.125,0:30:31.115
이 코스에서 배운 내용을
TensorFlow로

0:30:31.115,0:30:34.065
변경하거나, 새로 작성해야 한다면

0:30:34.065,0:30:37.015
우선은 Keras를 사용해야 할 지도 모릅니다

0:30:37.015,0:30:40.105
하지만 최신예적인 결과를 얻기 위해선

0:30:40.240,0:30:42.880
fastai와 비교해서

0:30:43.160,0:30:46.180
기본적으로 좀 더 어렵고,
좀 더 시간을 할애해야 합니다

0:30:46.185,0:30:49.485
fastai에서 제공하는

0:30:49.485,0:30:52.365
모든 최신예 알고리즘들을

0:30:52.365,0:30:55.415
똑같이 만들어야 하기 때문에
동일한 수준의 결과를 얻는것은

0:30:55.415,0:30:57.385
쉽지 않을 것입니다.

0:30:58.100,0:31:02.620
하지만 기본적인
아이디어는 아주 유사합니다

0:31:02.620,0:31:04.275
그리고

0:31:04.275,0:31:06.905
저희가 fastai로 하는 것들을

0:31:06.905,0:31:09.995
똑같이 해내는게 불가능 하지 않다는 겁니다

0:31:09.995,0:31:12.565
하지만, 재시작하는 확률적 경사하강이나

0:31:12.565,0:31:14.955
차등 학습률,

0:31:14.955,0:31:18.025
batch normalization freeze 같은 것들을
구현해야 할 겁니다

0:31:18.025,0:31:20.965
하지만, 다행히(?)

0:31:20.965,0:31:24.345
포럼의 누군가가 fastai를

0:31:24.345,0:31:27.215
Keras 또는 Tensorflow 에 호환 가능한 형태

0:31:27.215,0:31:30.705
만드는걸 시도하고 있는것 같습니다

0:31:30.755,0:31:33.705
몇 주전에 구글에도 이야기를 했는데

0:31:33.705,0:31:36.825
fastai를 Tensorflow로 포팅하는데
 꽤나 흥미를 보이는것 같았습니다

0:31:37.185,0:31:40.285
이 강의를 온라인으로 들으실때 쯤이면

0:31:40.285,0:31:43.180
그런게 존재할 지도 모르겠군요

0:31:46.025,0:31:48.525
어쨋든

0:31:48.525,0:31:52.300
Keras와 TensorFlow는

0:31:53.440,0:31:56.095
다루는게 그렇게 어렵지 않으니까

0:31:56.095,0:31:58.945
사용해야 할 때가 온다면 걱정하지 마세요

0:31:58.945,0:32:02.365
이 코스를 완주하고나면,
수 일 내에 배울 수 있을 겁니다

0:32:07.705,0:32:10.955
현재까지 설명드린게

0:32:10.955,0:32:13.635
지난주의 숙제를

0:32:13.635,0:32:16.755
완료하기 위해서

0:32:16.755,0:32:18.985
알아둬야할 거의 모든 것입니다
(데이터셋만 개 품종으로 바뀌었죠)

0:32:19.405,0:32:20.875


0:32:21.655,0:32:23.925
상기 차원에서 말씀드리는 건데

0:32:24.025,0:32:27.225
지난주 강의의 마지막 부분에서

0:32:27.225,0:32:29.355
데이터를 탐구하는 방법을

0:32:29.765,0:32:32.805
조금 보여드렸습니다.

0:32:32.805,0:32:36.175
분류 카테고리들이 뭐가 있으며

0:32:36.180,0:32:38.900
이미지 크기들이 어떻게 구성되는지
같은 것들 말입니다

0:32:38.960,0:32:41.985
만약 그 부분이 기억 안나시거나
지난주의 내용이 이해가 잘 안되시면

0:32:41.985,0:32:44.695
지난주의 강의를 다시 한번
시청하시길 바랍니다

0:32:44.985,0:32:48.055
한가지 이야기 하지 않은 것이 있는데

0:32:48.055,0:32:51.085
어떻게 Kaggle에 결과를
제출하는지에 대한 것입니다

0:32:51.085,0:32:54.395
어떻게 예측 결과를 얻는지에 대한 것으로
그 부분을 보여드리도록 하겠습니다

0:32:54.985,0:32:57.895
이번주의 Wiki에는 이미 어떻게 하는지

0:32:57.895,0:33:01.135
적어뒀으니 확인해 보시기 바랍니다

0:33:01.135,0:33:04.255
일단 Kaggle 웹사이트에 가보시면

0:33:04.255,0:33:07.255
모든 경연들은 'evaluation' 이라는 섹션이 있습니다

0:33:07.255,0:33:10.265
이 섹션이 뭐를 제출해야 하는지에 대해서
설명을 해줍니다

0:33:10.265,0:33:13.605
그 섹션의 내용의 일부 중 두 줄을 복사해서
보이시는 화면에 붙여넣었습니다

0:33:13.945,0:33:17.395
이게 의미하는 것은
한 파일을 제출해야 하는데

0:33:17.585,0:33:20.935
그 파일의 첫번째 줄에는
문자 그대로 id 부터

0:33:21.240,0:33:25.180
, (콤마)로 이어지는 모든 개 품종들이 열거 됩니다

0:33:25.180,0:33:27.415
그리고나서, 
그 다음 줄 부터는

0:33:27.420,0:33:29.660
예측 결과 하나하나에 대한

0:33:29.660,0:33:34.360
이미지 id와 예측 결과에 표시되는
각 개 품종별 확률값을 넣어줘야 합니다

0:33:34.720,0:33:37.400
이 파일을 어떻게 만들어야 할까요?

0:33:37.820,0:33:40.855
우선 저희가 만든 data 객체에는

0:33:40.855,0:33:43.715
.classes 속성값이 있는데

0:33:43.715,0:33:46.525
알파벳 순서대로 모든 
분류 카테고리의

0:33:46.525,0:33:48.085
목록(배열)을 표현합니다

0:33:49.420,0:33:50.780
그리고

0:33:51.580,0:33:54.840
모든 서로다른 분류 카테고리(클래스)를 가져왔고

0:33:55.695,0:33:58.735
data 객체에 있는 .test_ds 속성은
테스트 데이터셋을 의미합니다

0:33:58.740,0:34:04.700
테스트 데이터셋의 .fnames 속성값은
테스트 데이터셋에 포함된 모든 파일이름 목록을 가집니다

0:34:04.800,0:34:07.795
한가지 상기시켜 드릴 내용이 있는데

0:34:07.800,0:34:10.080
개 품종 데이터셋은

0:34:10.080,0:34:13.455
각 분류 카테고리가 서로다른
폴더로 존재하는

0:34:13.455,0:34:16.195
Keras 가 원하는 형태(포맷)로 제공되지 않았습니다

0:34:16.195,0:34:18.965
대신에 각 레이블에 대한 정보를
CSV 파일로 제공합니다

0:34:18.965,0:34:23.040
그래서 CSV 파일이 있을땐

0:34:23.860,0:34:26.865
ImageClassifierData 클래스의
from_path 메소드 대신에

0:34:26.865,0:34:30.025
from_csv 메소드를 사용했습니다

0:34:30.025,0:34:33.025
Keras에는 이와 동일한 기능의
함수가 없어서

0:34:33.025,0:34:36.055
Kaggle 포럼에서는 사람들이

0:34:36.055,0:34:38.725
Keras 에서 사용되는 형태로

0:34:38.725,0:34:41.845
변환하는 스크립트를 공유하곤 합니다

0:34:41.845,0:34:45.380
fastai를 사용사면, 단순히 CSV 파일을 
from_csv 메소드에 던져주기만 하면 됩니다.

0:34:46.000,0:34:49.015
CSV 파일은
data 객체에게

0:34:49.015,0:34:52.295
어떤 분류 종류들이 있는지를
자동으로(?) 알려주고

0:34:52.785,0:34:55.815
테스트 데이터셋의 폴더에 있는

0:34:55.820,0:34:59.940
이미지 파일들이 뭐가 있는지도
알아낼 수 있습니다

0:35:00.540,0:35:03.200
이 두 가지의 정보를 가지고 있으면

0:35:03.720,0:35:06.625
Kaggle에 결과를 제출할
준비가 갖춰진 것입니다

0:35:06.625,0:35:10.620
개와 고양이 예제에서 본 것 처럼,
항상 TTA를 사용하는게 좋다고 생각 하는데

0:35:10.620,0:35:12.960
결과를 많이 향상시켜 주기 때문이죠

0:35:12.960,0:35:15.740
특히나 만든 모델이 비교적 덜 좋다고 
생각되면 더욱 그렇습니다

0:35:16.120,0:35:19.120
이를 위해서 learn.TTA 메소드를 
호출하면 되는데

0:35:19.460,0:35:25.920
learn.TTA 메소드에
is_test 파라메터 값을

0:35:26.220,0:35:29.640
True로 지정해주면,
TTA를 사용한 예측 대상을

0:35:30.000,0:35:34.500
검증 데이터셋이 아닌
테스트 데이터셋으로 지정함을 의미합니다

0:35:35.020,0:35:39.700
그리고 당연한 것이지만,
테스트 데이터셋에 대해서는

0:35:40.080,0:35:45.280
정확도 값을 구하지 못합니다. 왜냐하면, 
테스트 데이터들은 레이블링되어 있지 않으니까요

0:35:46.160,0:35:49.155
디폴트로서, 대부분의 PyTorch 기반의 모델은

0:35:49.155,0:35:52.165
예측 결과에 대한 Log(로그) 값을
돌려주는데요,

0:35:52.165,0:35:57.800
이 값들을  확률값들로 되돌려 놓으려면,
 np.exp 메소드에 이 값을 던져주면됩니다

0:35:58.180,0:36:02.040
현재 예제에서 테스트 데이터셋은
10,357개의 이미지로 구성되어 있고

0:36:02.155,0:36:04.925
분류 대상이 되는 개 품종의 종류는
120개 정도가 존재합니다

0:36:04.925,0:36:09.320
예측 확률값이 들어있는 행렬(matrix)의
크기를 확인해 보면 알 수 있습니다

0:36:09.720,0:36:13.020
그리고, 이 결과를
아까 보신 형태의

0:36:13.160,0:36:15.620
포맷으로 만들어 내야 합니다

0:36:15.980,0:36:18.975
그러기 위한 가장 쉬운 방법은
pandas 를 사용하는 것입니다

0:36:18.975,0:36:21.865
아직 pandas를 잘 모르신다면,
온라인에 많은 자료가 있고

0:36:21.865,0:36:24.845
저희가 운영하는 머신러닝 코스에서도

0:36:24.845,0:36:27.855
pandas를 많이 사용하니까 확인해 보시기 바랍니다

0:36:27.860,0:36:32.460
간단하게 말씀드리면, 
pd.DataFrame 에 아까의 확률 결과 행렬을 넣어주고

0:36:32.460,0:36:37.040
행들의 이름이 분류 카테고리들 이라고
(ds.column = data.classes) 알려줍니다

0:36:37.500,0:36:41.100
그리고, id를 첫번째 행의 이름으로 삽입하고

0:36:41.100,0:36:45.220
id 행의 열값들을 파일이름으로 채워줍니다

0:36:45.220,0:36:49.100
이때, 파일이름의 시작부분에는

0:36:49.420,0:36:52.980
필요 없는 다섯 글자(test/)가 포함되어 있어서

0:36:53.040,0:36:55.080
이 부분을 제외한

0:36:55.080,0:36:59.080
파일이름의 부분만 잘라냈습니다

0:37:00.940,0:37:03.360
여기까지 하면,
결과 DataFrame은

0:37:03.400,0:37:05.580
화면에 보시는것 처럼 구성 됩니다

0:37:05.900,0:37:09.820
정확히 우리가 원하는 형태 입니다

0:37:09.820,0:37:12.260
그러면, Dataframe 객체의

0:37:12.260,0:37:19.300
아.. 변수이름을 잘못 입력 했네요
ds가 아니라 df로 변경하겠습니다

0:37:19.300,0:37:23.060
DataFrame 이니까 df 으로 말이죠

0:37:24.380,0:37:29.140
이 시점에서 df.to_csv 메소드를
호출할 수 있는데

0:37:29.520,0:37:32.395
이 결과 파일의 크기가 꽤나 크다는 것을
종종 눈치채실 겁니다

0:37:32.400,0:37:35.860
그래서, 결과를 gzip으로 
압축하는게 좋은 생각일 수 있습니다

0:37:35.860,0:37:39.000
그러면 자동으로 결과가
압축되어 저장되게 됩니다

0:37:39.000,0:37:42.760
결과적으로 to_csv 메소드는
CSV 파일을 생성하는데, 이때 CSV 파일을

0:37:42.760,0:37:46.200
압축해서, Jupyter Notebook이 구동중인
곳에다 저장을 해 줍니다

0:37:46.440,0:37:49.240
서버에서 구동중이시면
Kaggle에 제출하기 위해서

0:37:49.245,0:37:52.465
이 파일을 내 컴퓨터로 옮겨와야 하거나

0:37:52.465,0:37:56.880
kg submit 형태의 
Kaggle CLI를 사용해도 됩니다

0:37:57.120,0:38:00.780
저는 보통 내 컴퓨터로 옮겨오는 편입니다

0:38:00.785,0:38:04.005
결과가 올바른지 다시한번
확인해 보기 위해서 말이죠

0:38:04.175,0:38:07.355
파일을 다운로드 하기 위한
손수윈 방법을 소개해 드리겠습니다

0:38:07.355,0:38:10.845
FileLink 라는 것을
아까 압축한 파일의 경로로 생성하면

0:38:10.995,0:38:14.395
그 파일의 경로에 대한 링크를 생성해 주는데
이 링크를 클릭하게되면

0:38:14.400,0:38:19.000
그 파일을 서버로부터
내 컴퓨터로 다운로드 할 수 있습니다

0:38:19.560,0:38:22.420
한번 클릭해 보겠습니다

0:38:22.640,0:38:25.120
그리고 어딘가에 저장을 하고

0:38:25.360,0:38:33.720
저장된 곳에 가보면,

0:38:34.040,0:38:40.380
제출용 파일이 다운로드된 것을
확인할 수 있습니다

0:38:40.680,0:38:43.420
이 파일을 열어보면

0:38:43.820,0:38:46.920
정확히 제가 요청한 형태로

0:38:46.925,0:38:49.995
id 와 120개 서로 다른 개 품종 이름이 있습니다

0:38:50.120,0:38:52.980
이것은 데이터의 첫번째 줄인데,
파일이름이 있고

0:38:52.980,0:38:55.280
120 개의 서로다른 확률값이 저장되어 있습니다

0:38:55.800,0:39:01.580
파일이 다운로드 되면, 이것을
Kaggle 에 제출할 수 있습니다

0:39:02.500,0:39:06.300
지금까지 한 것을 보면,
인터넷에서 어떤 파일이든

0:39:06.580,0:39:11.280
크롬 확장 프로그램을 사용해서

0:39:11.500,0:39:14.580
AWS나 Paperspace 서버로 집어 넣거나

0:39:14.580,0:39:16.655
할 수 있습니다.

0:39:16.655,0:39:19.585
또한, FileLink 라는 것을 사용해서
우리의 서버로부터

0:39:19.585,0:39:22.525
파일을 손수비게 다운로드 할 수 있는걸 배웠습니다.

0:39:22.645,0:39:25.845
좀더 터미널 커맨드 사용에 익숙하신 분은
SCP 명령을 사용 할 수도 있습니다

0:39:25.845,0:39:29.105
저는 모든걸 Notebook에서 하는걸
좀 더 선호하는 편입니다

0:39:30.245,0:39:31.245


0:39:32.965,0:39:35.845
지난주에 한가지 질문 받은게 있는데

0:39:35.845,0:39:38.875
단 한장의 이미지 파일에 대해서

0:39:39.275,0:39:42.295
결과를 예측하고 싶은 경우

0:39:42.525,0:39:45.215
어떻게 하는지에 대한 것입니다.

0:39:45.215,0:39:47.805
예를들어서,
검증 데이터셋의 첫번째 파일을

0:39:47.805,0:39:50.625
가져옵니다.
파일 이름을 출력해 봤고요

0:39:50.940,0:39:54.240
그리고, 언제든지
기본적인 파이썬 라이브러리인

0:39:54.500,0:39:59.340
Image.open()을 사용해서
이미지를 열어볼 수 있습니다

0:40:00.480,0:40:01.480


0:40:02.485,0:40:05.255
그리고 뭘 할 수 있는지에 대해서

0:40:05.255,0:40:07.555
가장 짧은 코드로 설명 드리겠습니다

0:40:07.560,0:40:11.080
단순히 learn.predict_array를 호출 하면 되는데

0:40:11.220,0:40:15.940
이때, 파라메터로 해당 이미지를
전달해주면 됩니다

0:40:17.560,0:40:20.505
전달되는 이미지는
변형될 필요가 있습니다.

0:40:20.505,0:40:25.420
전에 tfms_from_model()을 보신 적이 있을 건데

0:40:25.420,0:40:29.800
전에 이 함수는 하나의 값만을 리턴 하는 형태로
사용 됐었습니다

0:40:29.805,0:40:32.515
하지만, 사실상 내부적으로는
두 가지 값인

0:40:32.515,0:40:35.535
trn_tfms 하고, val_tfms 을 리턴합니다.
(학습용, 검증용)

0:40:35.535,0:40:38.555
즉, 두 종류의 데이터셋에 대해서
분할이 가능한 겁니다

0:40:38.560,0:40:42.540
여기 코드에서는
학습용 데이터 변형이 적용 되었는데,

0:40:42.540,0:40:45.940
사실은 검증용 데이터 변형이
적용 되어야 겠지요

0:40:46.080,0:40:47.560
이 함수가 호출되면

0:40:47.760,0:40:50.720
변형된 이미지들이 포함된

0:40:50.725,0:40:54.135
배열을 되돌려 주게 됩니다

0:40:54.645,0:40:57.085
생성된 모델에 전달되거나

0:40:57.085,0:41:00.115
얻어진 결과든 모든 것들은

0:41:00.115,0:41:02.895
보통 미니 배치 형태라고
가정됩니다

0:41:02.895,0:41:06.025
쉽게 말하면 여러장의 이미지들이라는 것이죠

0:41:06.025,0:41:09.500
numpy 사용법에 대해선 나중에 좀 더
이야기 할 것인데요,

0:41:10.080,0:41:13.035
여기서 우리는 단 한장의 이미지만
있는 상황 이라서

0:41:13.035,0:41:15.885
이 한장의 이미지를
미니 배치 형태로 바꿔줘야 합니다

0:41:15.885,0:41:18.775
다른말로 표현하자면,
Tensor 라는 형태를 생성해야 한다는 겁니다

0:41:18.780,0:41:22.360
한장의 이미지는 행x열x채널 로 이루어 지지만

0:41:22.400,0:41:26.940
미니배치의 형태는
이미지 갯수x행x열x채널이 되는 거죠

0:41:27.660,0:41:30.700
한장의 이미지지만
4차원의 형태로 표현해야 합니다

0:41:30.705,0:41:33.715
numpy에 이를 손쉽게 하는 방법이 있는데

0:41:33.720,0:41:37.760
배열의 인덱스에 None을 넣어주면

0:41:38.100,0:41:41.595
첫 부분에, 추가적인 차원을 추가해 줍니다

0:41:41.595,0:41:44.635
하나의 이미지 형태를

0:41:44.635,0:41:47.585
하나의 이미가 들어간 미니배치 형태가 되는거죠

0:41:47.585,0:41:50.305
단 한장의 이미지에 대해서

0:41:50.660,0:41:53.300
PyTorch나 Fastai를 사용해서

0:41:53.300,0:41:55.220
뭔가를 하려고 하실때,

0:41:55.480,0:41:58.540
마주칠 수 있는 상황으로

0:41:58.545,0:42:01.625
4차원의 입력이 요구되는데

0:42:01.625,0:42:04.625
주어진건 3차원인 경우가 있을 수 있습니다

0:42:05.165,0:42:08.145
그리고 배열의 첫번째 요소가

0:42:08.145,0:42:11.135
뭔가 이상한 값을 가진다면

0:42:11.140,0:42:15.880
그 배열은 미니배치인 경우가 있을 겁니다
(초보자들 한테 해주는 말인듯)

0:42:18.580,0:42:25.600
지금까지 보여드린 코드가 실전에서
사용해야 하는 모든것을 말해줍니다

0:42:26.560,0:42:27.560


0:42:27.700,0:42:31.060
그러면 이번에는 약간의 이론을
공부해볼 차례 입니다

0:42:31.060,0:42:33.880
컨볼루션 뉴럴넷의 내부에서

0:42:33.885,0:42:36.705
실제로 무슨일이 벌어지는지에 대해서 말입니다

0:42:36.705,0:42:37.700


0:42:38.520,0:42:43.220
레슨1에서의 내용을 기억하실지도 모르겠군요

0:42:44.400,0:42:46.320
그때

0:42:47.300,0:42:50.020
약간의 이론적인 내용을

0:42:50.380,0:42:53.735
여기 보시는 멋진 웹사이트 (http://setosa.io/ev) 로
설명 드렸었습니다

0:42:53.735,0:42:56.945
시각적으로 뭔가를 설명해주는
웹사이트 입니다

0:42:57.055,0:43:00.065
우리가 배운 내용은
컨볼루션이란 기본적으로

0:43:00.065,0:43:05.680
딥러닝에서 거의 항상 3x3 크기를 가지는
행렬(Matrix)가 있을때

0:43:05.920,0:43:09.560
이 행렬의 각 요소들과
사진의 3x3 영역의 각 요소들을

0:43:09.560,0:43:12.255
서로 곱하고

0:43:12.260,0:43:14.740
각 곱해진 값들을 모두 더하면

0:43:14.740,0:43:19.020
결과 사진(오른쪽)의 특정 한 지점(픽셀)
의 값을 얻게 되는 것입니다

0:43:19.520,0:43:23.300
이번에는 이 모든 것들이 함께 어떻게

0:43:23.680,0:43:27.840
여기 보시는 Zeiler와 Burgers의 논문에 나온 다양한
계층들로 바뀌게 되는지

0:43:27.840,0:43:30.200
살펴보도록 하겠습니다

0:43:30.435,0:43:32.795
그러기 위해서
이번에도

0:43:32.795,0:43:35.785
저보다 똑똑한 누군가의 자료를 활용하도록 하겠습니다

0:43:35.785,0:43:39.420
이 자료는 Otavia Good 이라는 사람이 작성한 것으로

0:43:39.420,0:43:41.535
이 분은 Word Lens라는걸

0:43:41.535,0:43:44.725
만드신 분인데, Word Lens는 현재

0:43:44.725,0:43:47.495
구글 번역기의 일 부분으로 들어가 있습니다

0:43:47.495,0:43:50.745
해보신 분도 있을텐데

0:43:50.745,0:43:55.040
카메라로 외국어 단어가 있는 곳을 가리키면

0:43:55.040,0:43:56.880
실시간으로

0:43:56.885,0:44:00.265
변역된 결과를 외국어 단어 위에 표시해 줍니다

0:44:00.755,0:44:03.825
그리고 Otavia가 지금부터 보실

0:44:03.825,0:44:07.820
멋진 비디오를 공유해 줬지요
그는 현재 구글에 있습니다

0:44:08.300,0:44:11.495
이 비디오를 여러분께 보여주고자 합니다

0:44:11.495,0:44:14.505
왜냐하면 무슨 일이 일어나는지를
아주 잘 설명해 주고 있기 때문인데요

0:44:14.505,0:44:17.575
비디오를 시청하신 후에

0:44:17.575,0:44:20.305
네트워크를 구성하는 
전체적인 컨볼루션 계층의 순서를

0:44:20.305,0:44:23.475
어떻게 구현하는지에 대해서
MS 엑셀을 이용해서 보여 드리겠습니다

0:44:23.475,0:44:26.085
시각적으로 공부하시는 분이나
스프레드시트로 공부하시는 분이나

0:44:26.085,0:44:29.385
모두 이 내용을 이해하실 수 있도록 말이죠

0:44:29.435,0:44:30.515


0:44:31.195,0:44:34.205
이 코스 나중에 하게 될 것 중 하나로

0:44:34.205,0:44:36.915
숫자를 인식하는 방법을 배우게 될 건데요

0:44:36.915,0:44:40.185
처음부터 끝까지 어떻게 하는지
모든 것을 배울 겁니다

0:44:40.455,0:44:43.465
이 비디오는 문자를 인식하는 경우에 대한 것인데

0:44:43.465,0:44:46.505
여기에 'A'가 있습니다
하지만 이 문자 'A"는 명백히

0:44:46.505,0:44:49.915
사실상 숫자들의 격자 입니다.

0:44:49.915,0:44:52.595
그리고, 지금 보고 계시는건

0:44:52.595,0:44:55.565
첫번째 컨볼루션 필터가
작업하는 것을 보여줍니다

0:44:55.565,0:44:58.175
여기서 보여주는 모든 내용은

0:44:58.180,0:45:00.860
모든것들이 이미 학습되어 있다고 가정합니다

0:45:00.860,0:45:04.460
필터를 이미지 위에서
오른쪽 아래 방향으로 닦아 내려갑니다

0:45:04.460,0:45:07.255
그러면서 왼쪽 부분을 검게 만드는데
여기서 사용된 커널의 값은 대략

0:45:07.255,0:45:09.835
-1 0 1
-1 0 1
-1 0 1
형태가 됩니다

0:45:09.835,0:45:12.575
이미지 각각의 3x3 부분에 대해서

0:45:12.580,0:45:16.460
방금 말씀드린 커널의 행렬과 값을 곱하게 됩니다

0:45:16.460,0:45:19.520
행렬의 곱셈이 아니라,
각 요소끼리의 곱셈 입니다 (element wise)

0:45:19.860,0:45:22.800
그래서 뭔 일이 일어났냐 하면

0:45:22.805,0:45:25.545
커널의 흰색 모서리가 'A'의 모서리와

0:45:25.545,0:45:27.105
맞아 들어 가지만

0:45:27.480,0:45:30.540
커널의 검은색 모서리는 맞아들어가지 않을때

0:45:30.540,0:45:33.115
양성반응인 초록색을 얻게 됩니다

0:45:33.115,0:45:36.055
그 반대가 되는 모든 부분에 대해서는
음성반응인 빨간색을 얻게 됩니다

0:45:36.060,0:45:39.700
방금 보신게 처음 하나의 필터에 대한 것이고

0:45:40.600,0:45:43.545
첫번째 커널의 결과를 얻은 것이었습니다

0:45:43.545,0:45:45.880
지금 보시는 것은 또다른 새로운 커널로

0:45:45.880,0:45:48.395
커널 윗 부분이 하얀색(1)입니다

0:45:48.395,0:45:51.085
'A' 문자를 표현하는 행렬의

0:45:51.085,0:45:53.965
모든 3x3 부분들을 스캔해서,

0:45:53.965,0:45:56.415
커널의 9개 비트와 곱하고,

0:45:56.415,0:45:59.085
빨간색과 초록색 부분들과

0:45:59.085,0:46:02.155
얼마나 그 색이 짙은지를
찾아내게 됩니다

0:46:02.155,0:46:05.135
그리고, 지금까지 2개의
필터가 있는데

0:46:05.135,0:46:08.225
하나는 아랫쪽, 다른 하나는 왼쪽
경계선에 대한 필터로

0:46:08.225,0:46:10.885
위 결과에서, 윗쪽 경계선이
빨간색이고

0:46:10.885,0:46:12.980
아랫쪽 경계선이
초록색입니다.

0:46:12.980,0:46:16.580
아래 결과에선, 왼쪽 경계선은 초록색
오른쪽 경계선은 빨간색입니다

0:46:16.760,0:46:18.920
이 다음 단계에선

0:46:18.920,0:46:22.055
ReLU (Rectified Linear Unit) 라는
'비선형성'이 추가 됩니다

0:46:22.055,0:46:25.545
이 함수는 음성값들을 모두 0으로 만드는데
보시다 시피 빨간색이 모두 사라졌습니다

0:46:25.995,0:46:28.885
다시 보면, 계층 1에서는
문자 'A'를 입력 받고

0:46:28.885,0:46:31.865
계층 2는 두 가지 컨볼루션 필터가
적용된 결과를 보여주고

0:46:31.865,0:46:34.340
계층 3에서는
모든 빨간색 부분을

0:46:34.340,0:46:37.735
없애 버린 결과를 보실 수 있습니다

0:46:37.735,0:46:40.815
ReLU이 적용된 결과이죠

0:46:40.815,0:46:43.815
계층 4는 max pull이라고 불리는 것인데

0:46:43.820,0:46:47.420
직전 계층의 각 2x2 픽셀 중
가장 큰 값을 대표로 뽑아서

0:46:47.520,0:46:50.880
2x2 행렬을 1x1로 대체하게 됩니다

0:46:50.980,0:46:55.420
결과적으론, 전체 크기가 절반으로
줄어들게 되는 것입니다

0:46:55.420,0:46:59.280
그 다음으로는
정확히 동일한 가정을 반복합니다

0:46:59.280,0:47:03.415
3x3 필터를 직전단계에서 구해진

0:47:03.415,0:47:06.725
두 개의 결과에 대해서 적용합니다

0:47:06.920,0:47:09.420
그리고 또 다시

0:47:09.420,0:47:12.000
빨간색 부분을 제거합니다.
ReLU를 사용해서

0:47:12.000,0:47:17.620
모든 음수값을 제거하고
양성 반응이 된 부분만을 남깁니다

0:47:17.620,0:47:18.320


0:47:18.785,0:47:21.245
이런 식으로 컨볼루션 뉴럴넷의

0:47:21.245,0:47:24.200
다음 계층으로 이동하게 됩니다

0:47:24.200,0:47:27.520
뒷쪽에 있는 계층(이전 컨볼루션 계층)을
보시면

0:47:27.545,0:47:30.535
아랫쪽, 왼쪽 경계선과 같이

0:47:30.535,0:47:33.585
꽤나 해석 가능한 수준 입니다.
하지만, 그 다음 계층에서는

0:47:33.585,0:47:36.645
컨볼루션의 결과들을 조합하기 때문에

0:47:36.645,0:47:39.635
직관적으로 무슨일이 일어나는지

0:47:39.635,0:47:41.885
훨씬 더 불분명해지기 시작합니다

0:47:42.205,0:47:44.975
그 다음으로 또 다른 max pool을 수행하여

0:47:44.980,0:47:47.260
모든 2x2나 3x3 부분들을

0:47:47.260,0:47:51.000
이들이 가지고 있는 가장 큰 값의 숫자를
1x1 형태로 표현하여 대체합니다

0:47:51.000,0:47:54.440
예를 들어서, 왼쪽 상단의 2x2는 모두
검은색 이라서, 1x1의 검은색으로 교체되는 거죠

0:47:54.440,0:47:57.920
그리곤, 이렇게 만들어진 결과를 가지고

0:47:57.920,0:48:02.180
'A', 'B', 'C', 'D', 'E' 일때 기대되는 
값들이 들어 있는

0:48:02.180,0:48:05.700
일종의 템플릿과 비교를 하게 되는데

0:48:06.020,0:48:08.860
얼마나 가깝게 각 템플릿과
들어맞는지를 보는 것입니다

0:48:08.995,0:48:12.055
이 비교 또한 완전히 똑같은
방식으로 할 수 있는데

0:48:12.060,0:48:15.540
여기 보이는 결과에 대한  
4x8 행렬의 모든 요소값을

0:48:15.540,0:48:18.380
각 템플릿에 대한 4x8 행렬의 
모든 요소값과

0:48:18.380,0:48:20.415
곱한 후, 각 템플릿마나 나온

0:48:20.415,0:48:23.565
곱셈 결과를 더해줍니다

0:48:23.565,0:48:26.800
그러면, 각각에 대해서 
얼마나 빈번하게 맞아들어가는지 vs

0:48:26.800,0:48:29.420
얼마나 빈번하게 맞아들어 가지 않는지를 
알 수 있는데

0:48:29.420,0:48:32.600
이 결과는 각 문자가 될 확률로

0:48:32.600,0:48:34.860
변환됩니다

0:48:34.860,0:48:38.660
이 예제에서는 'A'라는 템플릿과
아주 잘 맞아 들어 가는 결과인 것입니다

0:48:38.840,0:48:42.260
여기선 어떤 학습 과정도 하지 않았습니다

0:48:42.260,0:48:45.660
미리 학습된 모델이 있을때
동작하는 방식을 보여드린 것입니다

0:48:45.660,0:48:49.000
인터넷에서 ImageNet에 대하여 학습된
미리 학습된 모델을 다운로드 하고,

0:48:49.000,0:48:51.500
ImageNet의 입력 이미지에 어떠한
변형도 가하지 않거나

0:48:51.500,0:48:54.360
어떤 모델을 학습시킨 후

0:48:54.360,0:48:56.625
테스트 데이터셋이나 새로운 이미지에

0:48:56.625,0:48:59.635
적용시킬 때

0:48:59.635,0:49:02.435
지금까지 보신 것과 비슷한
과정이 수행된다고 볼 수 있습니다

0:49:02.435,0:49:05.535
기본적으로 입력 데이터를

0:49:05.535,0:49:08.535
하나의 컨볼루션 계층에 여러개의
컨볼루션 필터를

0:49:08.540,0:49:10.220
적용하고,

0:49:10.680,0:49:13.720
음성 반응부분을 버리기 위한
ReLU를 적용하고,

0:49:13.720,0:49:16.800
그 다음으로는 max pool을 수행 하는데

0:49:17.560,0:49:20.295
이 세 단계를 여러번 반복하게 됩니다.

0:49:20.295,0:49:23.265
그러면, 새로운 문자

0:49:23.265,0:49:25.875
'A'든 'B'든 무슨 문자든지 간에

0:49:25.875,0:49:28.765
이 과정을 적용시킬 수 있는 것입니다

0:49:28.765,0:49:29.765


0:49:30.535,0:49:33.605
보셨듯이
아주 멋진 시각화 자료로

0:49:33.605,0:49:36.685
저라면 이렇게 못 만들었을 것 같아서

0:49:36.685,0:49:40.065
Otavia에게 감사를 드리고 싶군요

0:49:40.115,0:49:42.955
사실 이 시각화는 수작업으로 만들어진게 아니라

0:49:42.955,0:49:45.845
실제로 동적으로 컨볼루션을

0:49:45.845,0:49:48.865
처리하기 위한 컴퓨터 소프트웨어를 제작한 후

0:49:48.865,0:49:50.815
이를 구동하여 만들어진 것입니다

0:49:51.555,0:49:54.565
저는 좀더 스프레드시트를 사용하는 사람인데요

0:49:54.565,0:49:57.605
여기 보시면

0:49:57.605,0:50:00.555
똑같은 것이 스프레드시트로 표현되어 있습니다

0:50:00.555,0:50:03.825
이 내용은 깃헙 저장소에서 찾으실 수 있는데요

0:50:03.945,0:50:07.035
해당 저장소를 복제(git clone) 한 후,
스프레드시트 파일을 열거나

0:50:07.035,0:50:09.865
github.com/fastai 로 가셔서

0:50:09.865,0:50:12.925
이 파일을 클릭하셔도 됩니다

0:50:12.925,0:50:18.280
정확히 어디에 파일이 있는지 보여드리겠습니다

0:50:18.600,0:50:22.000
https://github.com/fastai/fastai
저장소로 가셔서

0:50:22.220,0:50:24.835
courses 폴더로 들어 가시고

0:50:24.840,0:50:28.860
dl1 폴더를 선택합니다.
그러면 excel 폴더가 있는게 보일 겁니다

0:50:28.860,0:50:31.260
이 폴더 안에
모든 엑셀파일이 들어 있고

0:50:31.260,0:50:33.785
여기서 바로 다운 받거나
저장소를 복제해도 되는데

0:50:33.785,0:50:37.320
이번에 저희가 보게될 파일은
conv-example.xlsx 입니다

0:50:37.780,0:50:40.340
이 파일을 열어 보시면

0:50:40.340,0:50:42.080
좌측 상단에

0:50:42.505,0:50:45.845
Input이 있는데

0:50:45.915,0:50:48.755
이 예제 에서 사용된 Input은 숫자 7 입니다

0:50:48.755,0:50:51.905
이 데이터를 MNIST라고 불리는 
데이터셋에서 가져왔는데

0:50:51.905,0:50:54.985
나중에 상세한 내용을 좀 더 들여다 볼 것입니다

0:50:54.985,0:50:57.995
그 데이터 중, 무작위로 하나를 선택해서

0:50:57.995,0:51:01.315
엑셀에 넣은 것입니다.
보시면 아실텐데,  모든 픽셀 값의 범위가

0:51:01.485,0:51:04.065
0 부터 1 사이로 되어 있습니다

0:51:04.640,0:51:07.540
아주 빈번하게 이 범위는

0:51:07.740,0:51:11.360
1바이트로 표현 가능한 0 ~ 255 이거나

0:51:11.560,0:51:15.980
0~1 사이의 실수가 되는데,
뭐가 되었든지 딱히 문제가 될 것은 없습니다

0:51:16.580,0:51:19.075
PyTorch에 대해서 배울때쯤

0:51:19.075,0:51:22.035
일반적으로, 이 문제를 실수(float)로
다루게 되기 때문에

0:51:22.035,0:51:24.315
문제 해결의 단계 중 하나로서

0:51:24.320,0:51:28.140
주어진 숫자들을 0~1 사이의 값으로
변환하는 일을 하게 됩니다

0:51:28.760,0:51:31.520
여기서 저는 엑셀의 조건문을 사용해서

0:51:31.525,0:51:34.405
높은 값을 가진 셀을
더 빨갛게 색칠하도록 만들었습니다

0:51:34.405,0:51:38.320
그 결과 숫자 7을 명확히 보실 수 있을 겁니다

0:51:38.780,0:51:41.400
하지만 여기엔 
많은 숫자들이 단순히 엑셀로

0:51:41.405,0:51:44.455
임포트되어 있는 것입니다

0:51:44.460,0:51:46.460
그래서 이 숫자들이 입력의 행렬 입니다.

0:51:47.320,0:51:51.120
Otavia가 앞에서 뭘 했는지 상기해 보면

0:51:51.440,0:51:56.920
이 입력에 2개의 필터를 적용했었습니다.

0:51:57.260,0:52:00.195
그리고, 엑셀 시트의 중간 부분에 보시면

0:52:00.200,0:52:02.900
상단 경계선을 감지해내는 3x3 필터 하나를

0:52:02.900,0:52:04.260
생성해 뒀습니다

0:52:04.455,0:52:07.405
필터의 상단 부분은 1,

0:52:07.405,0:52:10.445
중간 부분은 0, 그리고 하단 부분은 -1의 
값으로 설정하였습니다

0:52:10.445,0:52:13.920
이 필터가 적용된 결과인 오른쪽의
값들 중 하나를 예로서 살펴 봅시다.

0:52:13.920,0:52:16.255
아무 값을 선택하고
F2 키를 누르면

0:52:16.260,0:52:19.540
왼쪽에서 하이라이트되는 부분이 보이실 텐데

0:52:19.540,0:52:24.140
입력 데이터 중 선택된 값이 계산된
대상 3x3 부분입니다

0:52:24.580,0:52:27.360
그 3x3 부분의 값들을 살펴보면
상단에 1.0, 1.0, 1.0 값들은 각각

0:52:27.360,0:52:29.720
필터 상단의 값들인 1, 1, 1과 곱해집니다

0:52:30.180,0:52:32.280
그리고 하단의 0.1, 0.0, 0.0 값들은 각각

0:52:32.540,0:52:34.660
필터 하단의 값들인 -1, -1, -1과 곱해집니다

0:52:34.660,0:52:36.400
(곱해진 값들이 더해지고, 
더해진 값이 ReLU를 거치는건 빼먹음)

0:52:36.400,0:52:38.995
다른 말로 표현하면,
ReLU를 거친 값 중 양수는

0:52:39.000,0:52:43.800
계속 양수이고, 음수는 0이 됩니다

0:52:44.540,0:52:48.520
다른 부분들도 살펴 보겠습니다

0:52:48.980,0:52:50.880


0:52:51.675,0:52:54.895
이 부분은 거의 다 0의 값들로
이루어져 있군요

0:52:54.900,0:52:58.400
좀 더 흥미로운 부분을 보여드리겠습니다

0:53:00.140,0:53:04.580
윗 부분에 큰 숫자들이 있지만
아랫부분에도 큰 숫자들이 있습니다

0:53:04.580,0:53:08.360
결과적으로 이 값들이 커널과 연산되면
음수가 됩니다 (곱셈 + 덧셈)

0:53:08.980,0:53:13.500
그래서 패턴을 잘 살펴보시면
확성화 되는 부분(양수)은

0:53:13.740,0:53:16.500
경계선이 있는 곳입니다

0:53:17.760,0:53:21.080
그리고 오른쪽에 있는 숫자 3은
(각각의 모든 양의 수)

0:53:21.300,0:53:23.520
활성화 (activation) 이라고 부릅니다

0:53:25.120,0:53:27.240
제가 'activation' 라는 말을 할때는

0:53:27.420,0:53:30.440
단일 숫자를 의미합니다

0:53:31.760,0:53:34.440
이 단일 숫자인 activation은

0:53:34.580,0:53:38.900
입력단의 몇 숫자들에 
(3x3 픽셀 영역)

0:53:39.400,0:53:43.760
선형적 연산을 적용하여

0:53:44.000,0:53:47.320
(여기서는 커널과의 컨볼루션 연산)

0:53:47.335,0:53:50.285
계산된 결과의 값입니다

0:53:50.955,0:53:53.965
activation 숫자를 계산한 공식을 보시면

0:53:53.965,0:53:56.940
입력이 커널에 곱해지고,

0:53:56.940,0:53:59.200
곱해진 각 요소들이 더해집니다

0:53:59.780,0:54:01.420
SUM 으로 더하고

0:54:01.500,0:54:03.340
SUM 안의 내용이 곱셈관련 입니다

0:54:03.740,0:54:08.040
이렇게 더해진 값을 가지고
MAX(0, 더해진 값) 을 수행합니다

0:54:08.340,0:54:12.100
이 MAX 부분이 ReLU 입니다

0:54:12.740,0:54:15.960
이름이 뭔가 팬시해 보이지만,
실제로 의미하는건

0:54:15.960,0:54:19.640
엑셀에서는 MAX(0, C) 입니다

0:54:20.540,0:54:21.560


0:54:21.560,0:54:26.060
많은 산업에 있는 사람들이 
"뤨루" 라고 하는걸 보실 수 있을 텐데요,

0:54:26.060,0:54:29.820
"뤨루"는 rectified linear unit(ReLU)를
의미하는 것이고

0:54:29.820,0:54:32.500
MAX(0, C)를 의미하는 것입니다

0:54:32.500,0:54:35.500
제가 뭔가를 단순화한게 아니라
실제 의미를 설명드린 겁니다

0:54:35.505,0:54:38.505
제가 뭔가를 단순화해서 설명할땐,
단순화 한다고 이야기하는데

0:54:38.505,0:54:41.585
그렇지 않을땐 그게 전부입니다

0:54:41.585,0:54:44.925
그러니까 ReLU의 모든것은
MAX(0, C)라고 보시면 됩니다

0:54:44.925,0:54:47.760
그리고 컨볼루션의 모든것은

0:54:47.760,0:54:50.800
입력의 NxN 부분에 커널을 곱한 후,
더하는 과정이라고 보시면 됩니다

0:54:51.360,0:54:54.400
그러니까
컨볼루션 뉴럴넷에서의

0:54:54.600,0:54:57.900
하나의 계층에 대한 모든것이

0:54:58.000,0:55:00.760
엑셀을 사용해서
구현된 것입니다

0:55:00.820,0:55:04.220
그리고, 결과적으로 일어난 일은

0:55:04.845,0:55:07.705
수직 경계선들을 지우고

0:55:07.705,0:55:11.165
수평 경계선들을 하이라이트(강조)
한 것입니다

0:55:11.855,0:55:14.915
또 다시 설명 드리지만
여기서 가정된 것은

0:55:14.915,0:55:17.915
네트워크가 이미 학습된 상태고

0:55:17.920,0:55:22.560
학습이 끝난 시점에, 이런 형태의 
컨볼루션 필터를 생성 했다는 것입니다.

0:55:23.580,0:55:27.740
아래쪽으로 내려가 보시면,
두번째 컨볼루션 필터도 있습니다

0:55:28.020,0:55:31.175
단순히 다른 값들로 채워진 9개의
요소를 가지는 행렬 입니다

0:55:31.180,0:55:34.560
PyTorch 에서는 이 두개의 필터를
9개의 숫자를 가지는 독립적인

0:55:34.560,0:55:37.520
독립적인 두 개의 배열로 저장하지 않고

0:55:37.585,0:55:40.315
하나의 텐서(Tensor)로서 저장을 합니다

0:55:40.315,0:55:43.145
다시 상기시켜 드리자면
텐서 라는것은

0:55:43.445,0:55:46.505
배열인데 차원이 여러개가 될 수 있는 것입니다

0:55:46.505,0:55:49.665
'배열' 이라고 표현해도

0:55:49.665,0:55:52.420
동일한 의미를 가진다고
보셔도 됩니다

0:55:52.420,0:55:55.840
단지 PyTorch에서는 이를 항상 텐서라고
표현하기 때문에, 저도 그렇게 부를 겁니다

0:55:55.840,0:55:58.525
어쨋든, 텐서에 저장이 되는데

0:55:58.525,0:56:00.820
하나의 추가적인 축(차원)이 더 존재해서

0:56:00.820,0:56:03.820
각 필터의 값들이 위로 쌓이게 되는 것입니다

0:56:03.820,0:56:08.860
'필터'와 '커널'은 
거의 똑같은 의미로 사용 됩니다

0:56:08.860,0:56:11.260
3x3으로 표현된

0:56:11.260,0:56:13.145
행렬 또는

0:56:13.145,0:56:16.635
여러개 필터가 쌓여진 3차원 텐서에서

0:56:16.635,0:56:18.635
하나의 3x3 부분이죠

0:56:19.035,0:56:22.155
두번째 커널에 대한 결과는

0:56:22.155,0:56:25.295
위의 첫번째 커널 결과에 대한 공식을
그냥 복사해 온 것입니다

0:56:25.365,0:56:28.385
두번째 커널의 경우는

0:56:28.385,0:56:32.600
수직 경계선을 찾아냄을
보실 수 있을 겁니다

0:56:34.680,0:56:38.160
이제까지 하나의 계층을 만들었는데요

0:56:38.300,0:56:41.640
구체적으로, 이 계층은

0:56:41.645,0:56:44.915
숨겨진 계층(hidden layer) 이라고 부릅니다

0:56:44.915,0:56:47.855
입력 계층도, 출력 계층도 아닌

0:56:47.855,0:56:51.025
다른 모든 종류의 계층은 숨겨진 계층 입니다

0:56:51.380,0:56:54.720
그리고, 이 예제의 숨겨진 계층은

0:56:54.980,0:56:59.235
계층의 차원 크기가 2 입니다

0:56:59.240,0:57:01.720
왜냐하면

0:57:01.880,0:57:06.100
두개의 필터(커널)가 존재하기 때문입니다

0:57:06.860,0:57:10.420
그리고, 다음으로는
무슨일이 벌어질까요?

0:57:10.420,0:57:13.080
다음 계층을 하나 더 해볼텐데요,

0:57:13.240,0:57:16.275
계속해서 진행할수록

0:57:16.275,0:57:19.425
문제가 빠르게 더욱 복잡해 지게 됩니다

0:57:19.425,0:57:22.200
왜냐하면 다음 계층에서
사용되는 하나의 필터는

0:57:22.200,0:57:26.840
두개의 3x3 행렬을 포함하는데

0:57:26.840,0:57:28.520
직전 계층의

0:57:28.525,0:57:31.485
특정 3x3 부분을 계산할때,
직전 계층의 첫 번째 필터의

0:57:31.485,0:57:34.155
결과 뿐만 아니라, 두 번째 필터의 
동일한 3x3 부분의 결과에 대해서도

0:57:34.155,0:57:37.425
동시에 계산되어야 하기 때문입니다

0:57:37.425,0:57:40.405
하나의 계층 (필터의 결과들)이 PyTorch에서는

0:57:40.405,0:57:43.665
하나의 다차원 텐서에 표현(저장)

0:57:43.715,0:57:46.865
되기 때문에

0:57:46.865,0:57:51.660
이것을 두개의 3x3 커널이라고 생각하기 보단

0:57:51.840,0:57:55.620
하나의 2x3x3 형태의 커널이라고
생각해야 합니다

0:57:55.840,0:58:00.300
오른쪽 두 번째 계층의 결과를 계산하기 위해서

0:58:00.540,0:58:04.980
첫 번째 3x3 커널과, 직전 계층의 첫번째 결과를
계산 (곱셋 후 덧셈) 하고

0:58:05.240,0:58:06.660
거기에

0:58:06.840,0:58:12.460
두번째 3x3 커널과, 직전 계층의 두번째 결과를
계산 (곱셋 후 덧셈) 한 것을

0:58:12.620,0:58:14.620
더해줍니다

0:58:14.920,0:58:15.920


0:58:16.200,0:58:19.620
직전계층의 윗 부분 결과가
커널의 빨간색 부분에 의해 계산되고

0:58:19.625,0:58:22.915
아랫 부분 결과는
커널의 초록색 부분에 의해 계산 되는 거죠

0:58:23.200,0:58:24.920
시간이 지남에 따라, 여러분은

0:58:25.120,0:58:28.195
고차원적인 텐서(배열)에 대한

0:58:28.200,0:58:33.600
선형적 연산에
매우 편안함을 느끼셔야 합니다

0:58:33.600,0:58:34.660


0:58:34.665,0:58:37.845
이걸 그림으로 그리기는
매우 어렵습니다

0:58:37.845,0:58:39.980
겨우 한 화면에 하나가 표현 되었지요

0:58:40.260,0:58:43.180
하지만, 머릿속에 개념적으로
이것들을 그려나가는

0:58:43.180,0:58:45.800
방법을 터득하셔야 합니다

0:58:45.800,0:58:48.120
Geoffrey Hinton 교수가 가르친

0:58:48.125,0:58:51.205
2012년 Coursera의 뉴럴넷 수업에서

0:58:51.205,0:58:54.195
컴퓨터 과학자들이 어떻게

0:58:54.195,0:58:57.065
고차원적인 공간을 생각해야 하는지에 대한

0:58:57.065,0:58:59.695
팁이 있는데, 이것의 기본적인 내용은

0:58:59.695,0:59:03.095
2차원 공간을 일단 시각화 하고,
이걸 기반으로

0:59:03.265,0:59:06.635
머릿속으로 아주 빠르게
고차원을 생각해 보는 것입니다

0:59:06.985,0:59:10.135
여기 우리도 화면에 2차원 공간을
시각화 했는데

0:59:10.140,0:59:13.460
이보다 더 많은 차원이 존재할 수 있다고

0:59:13.520,0:59:16.720
스스로 믿으려고 노력하셔야 합니다

0:59:16.720,0:59:19.840
개념적으로 보면, 다르지 않습니다

0:59:19.840,0:59:22.760
엑셀에서는

0:59:22.765,0:59:25.720
3차원 텐서를 다룰 수 없어서

0:59:25.725,0:59:28.645
여러개의 2차원 텐서의 연산결과를

0:59:28.645,0:59:31.815
더해줘야 했습니다

0:59:31.815,0:59:34.765
만약 엑셀에 3차원을 표현할 방법이 있다면

0:59:34.765,0:59:37.805
두개로 나누지 않고, 하나로 할 수 있었겠죠

0:59:38.325,0:59:39.325
어쨋든

0:59:39.425,0:59:42.375
더해진 값을 ReLU라는

0:59:42.380,0:59:45.540
MAX(0, 에 적용하게 됩니다

0:59:45.760,0:59:49.100
그래서, 여기의 선택된 영역이
두번째 계층이 됩니다

0:59:49.445,0:59:52.375
사람들이 서로 다른 아키텍쳐를 만든다고 할때

0:59:52.375,0:59:55.155
아키텍쳐라는 것의 의미는

0:59:55.155,0:59:58.065
첫번째 계층의

0:59:58.065,1:00:00.685
커널이 얼마나 큰지

1:00:00.685,1:00:03.835
첫번째 계층에
몇개의 커널이 사용되는지를 말합니다

1:00:03.835,1:00:07.015
여기 예제는 두개의 커널이 사용되었고

1:00:07.015,1:00:10.435
각 커널의 크기는 3x3 이었습니다

1:00:10.435,1:00:13.545
그러니까 제가 만든 아키텍쳐는

1:00:13.545,1:00:17.260
두개의 3x3 컨볼루션 커널로
시작을 합니다

1:00:17.620,1:00:19.700
그리고, 두번째 계층에서는

1:00:19.840,1:00:22.845
또 다른 두 개의 커널이 있는데

1:00:22.845,1:00:26.105
각 커널의 크기는 2x3x3 가 됩니다

1:00:26.105,1:00:29.355
윗쪽에 첫번째 2x3x3가 있고

1:00:29.440,1:00:33.080
아랫쪽에 두번째 2x3x3가 있죠

1:00:33.460,1:00:36.715
그리고 기억하셔야 할 내용으로

1:00:36.720,1:00:40.480
결과에 있는 숫자 하나하나는
하나의 activation 입니다

1:00:40.480,1:00:42.640
두번째 계층의 activation은

1:00:42.640,1:00:47.720
직전 계층의 두 개의 결과(activation 행렬)와

1:00:47.960,1:00:51.000
두번째 계층의 커널인 2x2x3로 
계산된 것입니다

1:00:51.035,1:00:54.065
그리고 사람들이 일반적으로

1:00:54.065,1:00:56.835
계층에 이름을 붙여주는데

1:00:56.835,1:00:59.955
첫번째 계층에는

1:00:59.960,1:01:06.640
conv1 라는 이름을,

1:01:07.160,1:01:11.840
두번째 계층에는
conv2 라는 이름을 사용합니다

1:01:11.845,1:01:14.845
네트워크 구조를 요약해서 출력해보면

1:01:14.845,1:01:19.640
이렇게 모든 계층들에 이름이
붙어 있는것을 보실 수 있을 겁니다

1:01:20.460,1:01:24.160
Conv2 이후엔 무슨 일이 일어나는지도
살펴 봅시다

1:01:24.160,1:01:27.065
아키텍쳐의 일부분으로

1:01:27.065,1:01:30.035
max pool을 사용하는지도

1:01:30.040,1:01:35.440
결정해야 하는데,
우리도 max pool을 적용할 것입니다

1:01:36.160,1:01:39.695
max pooling은 엑셀에서 시각화가

1:01:39.695,1:01:42.785
좀 어렵긴 하지만, 표현을 해 봤는데요

1:01:42.785,1:01:45.325
max pooling을 잠시 설명 드리자면

1:01:45.325,1:01:48.005
2x2 max pooling을 하게 되면

1:01:48.005,1:01:51.345
해상도의 높이와 폭 모두를
절반으로 줄이는걸 의미합니다

1:01:51.345,1:01:55.500
max pooling의 결과
하나를 확인해 보시면

1:01:55.700,1:01:58.575
직전 계층의 2x2(4개 숫자)를

1:01:58.575,1:02:01.615
그 숫자들 중의 가장 큰 숫자로
대체한 것을 보실 수 있습니다

1:02:01.615,1:02:04.415
해상도를 절반으로 줄여 나가기 때문에

1:02:04.420,1:02:07.400
매 두개의 셀 마다 값이 있는것이구요

1:02:08.200,1:02:11.620
직전 계층하고 비슷해 보이는

1:02:11.895,1:02:14.715
모양을 가지고 있지만

1:02:14.715,1:02:17.695
모든 2x2 영역을

1:02:17.700,1:02:19.840
최대값으로 대체하면서

1:02:19.920,1:02:23.060
해상도가 절반으로 줄어든 모양이 됩니다

1:02:23.060,1:02:25.860
그리고, 고를 수 있는 모든 2x2가 대상이 아니라

1:02:25.860,1:02:28.040
하나의 2x2가 BQ에서 시작되면

1:02:28.260,1:02:30.860
그 다음의 2x2는

1:02:31.080,1:02:34.200
BS에서 시작되는 것으로

1:02:34.200,1:02:38.240
서로 겹치는 부분이 없고,
해상도가 줄어드는 이유가 됩니다

1:02:38.240,1:02:40.640
스프레드시트 사용에

1:02:40.640,1:02:44.080
친숙한 분들은 직접 파일을 열어서
확인해 보셔도 좋을것 같습니다

1:02:44.240,1:02:48.960
그리고, max pooling을 수행한 다음에

1:02:49.340,1:02:53.280
여러가지 다른 방법을 수행할 수 있는데

1:02:53.440,1:02:55.940
저는 여러분께

1:02:56.140,1:02:59.240
클래식한 약간 오래된 방법을 보여드릴 겁니다

1:02:59.245,1:03:02.235
하지만, 요즘에 사용되는 방법을
간단히 소개드리자면

1:03:02.240,1:03:04.940
전체 크기에 대해서, 또다른

1:03:04.940,1:03:07.740
max pooling을 적용하는 것입니다

1:03:07.960,1:03:13.100
하지만, 예전에 사용되던 아키텍쳐에서는

1:03:13.360,1:03:17.500
Fully Connected 계층 이라는것을
수행 하는데,

1:03:17.500,1:03:21.420
max pooling 계층의
모든 각각의 activation에 대해서

1:03:21.600,1:03:24.300
독립적인 가중치를 부여해  주게 됩니다

1:03:24.660,1:03:28.800
그러고 나면,

1:03:28.800,1:03:32.760
각 activation과 이에 해당하는 가중치가
곱해진 값들을 모두 더해서

1:03:32.760,1:03:35.880
최종적으로 하나의 값을 계산하게 됩니다

1:03:35.880,1:03:38.940
이때 계산이 되는 대상은

1:03:39.220,1:03:43.840
직전 계층의 결과물인
두 개의 3차원 텐서가 됩니다

1:03:43.925,1:03:46.965
이렇게 계산되는 과정이
Fully Connected 계층 이라고 불립니다

1:03:46.965,1:03:49.535
매번 부분부분 이동하면서 계산하는

1:03:49.535,1:03:52.685
컨볼루션하고는 다른 것으로

1:03:52.685,1:03:55.925
여기서는 아주 큰 가중치에 대한 행렬을
만들게 됩니다

1:03:55.925,1:03:58.985
몇 조그만 3x3으로 계산한 것과는 다르게

1:03:58.985,1:04:01.875
여기서 사용된 가중치는
입력이 되는 전체 행렬과 크기가 똑같습니다

1:04:02.280,1:04:05.480
한번 상상해 보시면 알 수 있을텐요,

1:04:05.480,1:04:09.260
fully connected 계층을 많이 사용하는 
아키텍쳐는

1:04:09.260,1:04:10.960
엄청나게 많은

1:04:10.960,1:04:15.040
가중치를 가지게 되는데,
이는 과적합이 발생할 수 있고

1:04:15.100,1:04:18.340
속도가 느릴 수 있다는 의미를 가집니다

1:04:18.500,1:04:19.680
앞으로

1:04:19.865,1:04:22.725
최초로 19개의 깊은 계층을
성공적으로 사용했던

1:04:22.725,1:04:25.775
VGG라는 아키텍쳐를 자주 보게 될 텐데요

1:04:25.780,1:04:30.140
VGG 에서는 4096개의 가중치를 가지는

1:04:30.140,1:04:35.340
fully connected 계층이 포함되어 있는데

1:04:35.340,1:04:42.500
이 계층은 4096개의 activations들과
연결되어 있어서

1:04:42.500,1:04:45.895
결과적으로 계산되어야 할

1:04:45.900,1:04:49.040
그 크기는

1:04:49.040,1:04:55.400
(4096 x 4096 x 커널의 갯수)가 됩니다.

1:04:55.400,1:04:58.020
제 기억이 맞다면

1:04:58.020,1:05:02.300
VGG에는 대략 3억개의 가중치를 위한
파라메터가 존재하는데

1:05:02.300,1:05:05.340
그 중 2.5억개 정도가

1:05:05.340,1:05:09.540
fully connected 계층을 위해서
사용 되었습니다

1:05:09.540,1:05:11.240
코스 나중에

1:05:11.240,1:05:14.380
이 거대한 fully connected 계층 사용을

1:05:14.385,1:05:17.325
어떻게 피할 수 있는지 배우게 될 겁니다

1:05:17.325,1:05:20.365
지금까지 사용했던 ResNet이나
ResNext는 내부적으로

1:05:20.365,1:05:24.220
큰 fullly connected 계층을 
사용하고 있지 않습니다

1:05:24.220,1:05:28.100
질문이 있나요?

1:05:29.395,1:05:31.695
>> 예를 들어서

1:05:31.695,1:05:34.595
>> 입력에 세 개의 채널이 있으면

1:05:34.600,1:05:37.340
>> 이 입력에 대한 필터의

1:05:37.340,1:05:40.260
>> 모양이 어떻는지 말해주실 수 있나요?

1:05:40.260,1:05:43.700
좋은 질문 이네요
입력이 세 개의 채널로 이루어 졌다면,

1:05:43.700,1:05:48.480
그 생김새는 Conv1과 유사할 겁니다

1:05:48.480,1:05:51.660
Conv1에는 두 개의 채널이 있습니다

1:05:51.660,1:05:57.040
그리고 두 개의 채널을 가진 Conv1에
사용된 필터는

1:05:57.060,1:06:00.035
필터당 두 개의 채널을 가져야 합니다

1:06:00.040,1:06:01.300
이 예제의

1:06:01.460,1:06:06.180
입력이 Conv1으로 시작된다고
상상해 보시면 될 것 같습니다

1:06:06.680,1:06:09.795
입력이 여러개의 채널로 구성되면

1:06:09.795,1:06:13.245
사용되는 필터는 이런식으로
생겼다는 것이죠

1:06:13.615,1:06:16.705
이미지는 종종 색을 가지는데

1:06:16.705,1:06:20.180
즉, 세 개, 빨강/초록/파랑
또는 알파 채널이 있음을 의미합니다

1:06:20.400,1:06:25.020
몇개의 채널로 이미지가 구성되던지간에
그 채널의 수가 필요한 입력의 크기 입니다

1:06:25.020,1:06:28.220
최근에 Yanette 이라는 학생분이
뭔가를 해보고 있는데

1:06:28.220,1:06:31.040
색을 가진 ImageNet에 학습된 모델을

1:06:31.040,1:06:33.795
의학 사진에 대해서 사용하는 것인데

1:06:33.795,1:06:36.535
이 사진은 한개의 채널만을 가집니다

1:06:36.540,1:06:41.400
한개의 채널인 입력을, 세 개의(컬러) 채널로 
학습된 모델에 적용하기 위해서

1:06:41.740,1:06:45.240
한개의 채널인 이미지에 대한
세 개의 복사본을 만들었습니다

1:06:45.240,1:06:48.700
그러면, 세 개의 똑같은 행렬이

1:06:48.700,1:06:52.240
만들어지게 되는 것이고
세 개의 채널이 되는 것입니다

1:06:52.560,1:06:55.340
중복되는 정보를 만들어 내기 때문에

1:06:55.345,1:06:58.145
이상적인 방법은 아니지만

1:06:58.145,1:07:01.055
컨볼루션 필터가 세개의 채널을 요구할때

1:07:01.055,1:07:04.045
사용해 볼 수 있는

1:07:04.045,1:07:07.540
방법입니다

1:07:08.680,1:07:10.740
kaggle에 보시면

1:07:10.745,1:07:13.665
빙산을 찾아내는 경연이 있는데

1:07:13.805,1:07:16.595
여기서 사용되는 이미지는
위성 사진으로

1:07:16.595,1:07:19.715
두 개의 채널로 이루어져 있습니다

1:07:19.715,1:07:22.735
그러면, 그 두 채널 중 하나를 골라서

1:07:22.735,1:07:25.655
복사해서 세번째 채널로 만들 수 있습니다

1:07:25.655,1:07:28.365
또는, Kaggle에서 사람들이 사용하는 방법으로

1:07:28.365,1:07:30.920
두 채널의 평균으로 세번째 채널을 만들기도 합니다

1:07:30.920,1:07:33.395
이것 또한 이상적인 방법은 아니지만,

1:07:33.400,1:07:37.200
미리 학습된 네트워크를 사용하기 위한
한가지 방법 입니다

1:07:37.500,1:07:39.480
저도 이와 관련해서

1:07:39.500,1:07:42.060
여러가지를 시도해 봤습니다

1:07:42.080,1:07:45.120
세개 채널의 ImageNet 모델을

1:07:45.120,1:07:48.855
네개의 채널을 가지는 데이터에
사용하고 싶었던 적이 있습니다

1:07:48.860,1:07:53.060
위성 사진 이었는데,
네번째 채널에 근적외선 정보가 있었습니다

1:07:53.180,1:07:57.320
그래서 제가 취했던 방법은
단순하게

1:07:57.320,1:08:02.760
컨볼루션 필터에 0으로 채워진 
추가적인 깊이(level)를 추가해준 것입니다

1:08:02.760,1:08:07.095
그러면, 처음에 근적외선 정보를
무시한채 시작하게 되는 거죠

1:08:07.100,1:08:10.220
다음주에 배우실 내용인데

1:08:10.260,1:08:15.920
여기 보시는것과 같은 조심스럽게
학습된 필터값을 사용하는것 대신에

1:08:15.960,1:08:19.260
무작위로 선택된 값들로

1:08:19.300,1:08:22.375
일단 학습을 시작을 하게 됩니다

1:08:22.380,1:08:24.940
그리곤, 무작위로 선택된 값들에 대하여

1:08:24.940,1:08:28.460
전에 개념적으로 봤던,
확률적 경사하강을 수행해서

1:08:28.460,1:08:31.140
이 무작위의 값들을 조금씩 조금씩

1:08:31.140,1:08:35.620
계속해서, 조금 더 나은 값으로
향상시켜 나가게 됩니다

1:08:37.460,1:08:42.220
여기서 7분간의 쉬는시간을 갖도록 하겠습니다

1:08:45.720,1:08:51.020
(다시 돌아와서)
그러면, 다음으론 무슨 일이 일어날까요?

1:08:51.100,1:08:57.000
지금까지 우리는
fully connected 계층을 수행하는것 까지를

1:08:57.140,1:08:59.480
배웠습니다

1:08:59.940,1:09:03.900
max pooling 계층의 결과를
fully connected 계층으로 넣어줬죠

1:09:03.900,1:09:07.460
약간의 선형대수 내용인데

1:09:07.460,1:09:11.115
fully connected 계층이 실제로 하는일은

1:09:11.120,1:09:14.800
행렬의곱셈 입니다.
(matrix product)

1:09:14.800,1:09:23.680
열과 행을 순서대로 곱해나가면서
그 결과를 더해주는 것이죠

1:09:27.580,1:09:30.500
그런데, 실제로는

1:09:30.500,1:09:34.480
이 결과값 (단일 숫자) 이 10개의 숫자(0~9) 중

1:09:34.480,1:09:38.440
어느것인지 계산하기 위해서는

1:09:38.540,1:09:43.420
충분하지 않습니다

1:09:44.060,1:09:47.620
사실은 10개의 값을 계산해야 합니다

1:09:47.620,1:09:50.115
그러기 위해선

1:09:50.115,1:09:52.165
우리가 한 것처럼, 한 세트의

1:09:52.635,1:09:55.785
fully connected 가중치들 만으로는
부족합니다

1:09:55.785,1:09:58.835
제가 '세트' 라고 말한 이유는

1:09:58.835,1:10:01.715
여기 가중치들은 3차원 모양의
텐서기 때문입니다

1:10:01.720,1:10:05.920
이 한 세트 대신에, 
10개 세트가 필요한 것이죠

1:10:05.960,1:10:09.480
그러면, 대충 느낌이 오실텐데
이 텐서가

1:10:09.480,1:10:12.535
좀 더 고차원 적이게 되는 것입니다

1:10:12.535,1:10:15.675
엑셀로는 이 모든걸 표현하기 어려웠지만

1:10:15.675,1:10:19.135
한 세트의 fully connected 를
10번 한다고 상상해 보세요

1:10:19.135,1:10:22.165
그러면, 10개의 서로다른
계산된 숫자를 얻을 수 있게 됩니다

1:10:22.165,1:10:25.015
정확히 동일한 과정을 통해서 말이죠

1:10:25.020,1:10:28.220
이 10개의 결과는

1:10:28.220,1:10:33.760
2 x m x n 같은 형태의 가중치 텐서와

1:10:33.760,1:10:36.860
연결되는 것입니다

1:10:37.420,1:10:41.620
그래서, 얻게된 10개의 숫자를 가지고

1:10:41.620,1:10:44.820
다음으로 수행되는 일은

1:10:44.820,1:10:48.120
다른 엑셀시트로 설명 드리겠습니다

1:10:48.120,1:10:51.535
직접 열어보신 분을 위해서, 파일명은
entropy_examples.xlsx 이고

1:10:51.540,1:10:55.340
이 파일엔 두개의 시트가 있습니다

1:10:55.340,1:10:58.000
그 중 하나의 이름은 softmax 이구요

1:10:58.440,1:11:01.820
여기서 사용된 예제는
0~9 숫자를 예측하는것이 아니라

1:11:01.820,1:11:05.580
고양이/개/비행기/물고기/건물 다섯개의
카테고리의 분류를 예측하는 것으로

1:11:05.580,1:11:09.620
분류 예측 대상을 바꿔서 설명 드리는점을
양해 바랍니다

1:11:10.060,1:11:12.960
직전에 이야기한

1:11:12.965,1:11:15.955
fully connected 계층을 통해서

1:11:15.955,1:11:19.065
결과로 5개의 숫자를 얻었다고
가정해 봅시다

1:11:19.065,1:11:22.155
그리고 이 숫자들에는 ReLU가 
적용되지 않았습니다

1:11:22.160,1:11:25.580
마지막 계층에는 ReLU가 사용되지 않습니다

1:11:26.160,1:11:29.280
그러면, 구해진 5개의 숫자를 가지고

1:11:29.280,1:11:33.135
각각의 숫자를 각각의 카테고리에 대한
확률값으로 변형하려고 합니다

1:11:33.140,1:11:35.800
0~1 값의 범위를 가지는 확률값으로
바꾸려는 것인데요,

1:11:35.800,1:11:38.400
각각의 카테고리에 대해서
고양이일 확률

1:11:38.400,1:11:41.720
개일 확률, 비행기일 확률
물고기일 확률, 건물일 확률로 바꾸는 것입니다

1:11:42.155,1:11:45.195
그리고 이 확률값들은

1:11:45.200,1:11:48.260
두 가지의 특징을 가지는데, 
첫번째는 그 값의 범위가 0~1 이라는 것이고

1:11:48.260,1:11:52.360
두번째는 이 확률값들을 모두 더하면
1이 된다는 것입니다

1:11:52.360,1:11:55.120
반드시 이 다섯개 중 하나로
분류 되어야 한다는 것이죠

1:11:55.475,1:11:58.455
이것을 가능하게 하기 위해서,
이 계층에서는 다른 종류의

1:11:58.460,1:12:00.040
활성 함수가 사용됩니다.
(ReLU도 활성 함수의 일종)

1:12:00.260,1:12:02.845
그러면, 활성 함수란 무엇일까요?

1:12:02.845,1:12:05.515
활성 함수란,

1:12:05.515,1:12:08.855
activation 값에 적용되는 함수입니다

1:12:08.860,1:12:11.820
예를 들어서, 앞서 사용했던

1:12:11.820,1:12:15.060
MAX(0, 어떤값) 은
activation에 적용된

1:12:15.065,1:12:17.325
함수였습니다

1:12:17.840,1:12:21.840
활성 함수는 항상 단일 숫자를 입력받아서

1:12:21.840,1:12:24.800
단일 숫자를 출력으로 내놓습니다

1:12:24.800,1:12:27.100
MAX(0, X) 이라는 활성함수는

1:12:27.100,1:12:29.660
X 라는 단일 숫자를 입력 받아서

1:12:29.660,1:12:32.900
결과로 ReLU가 적용된 X 값을 출력 하는 것이죠

1:12:33.600,1:12:36.280
활성함수가 뭔지에 대한 설명이었습니다

1:12:36.480,1:12:39.585
그리고, 레슨1에서 봤던

1:12:39.585,1:12:44.340
파워포인트 슬라이드 내용을 기억해보면

1:12:44.900,1:12:47.620
각 계층들은

1:12:47.620,1:12:49.540
단순히

1:12:49.540,1:12:51.900
선형적 함수였습니다

1:12:52.255,1:12:55.315
그리곤, 각 계층 직후에

1:12:55.315,1:12:58.365
비선형성이 필요하다고 말했었죠

1:12:58.365,1:13:02.360
만약 여러개의 선형적인 계층들을 
함께 쌓아 올린다면

1:13:02.360,1:13:05.420
그 결과로 얻는것 또한 선형적 계층이 됩니다

1:13:05.840,1:13:12.020
(노이즈)

1:13:12.840,1:13:16.460
만약 여러개의 선형적인 함수들을 
함께 쌓아 올린다면

1:13:16.460,1:13:19.420
그 결과로 얻는것 또한 선형적 함수가 됩니다

1:13:19.440,1:13:23.360
이 함수를 보여주는 것 만으로는
멋진 딥러닝을 할 수 없습니다

1:13:23.360,1:13:25.660
우리가 또 배웠던 것은

1:13:25.900,1:13:29.580
선형 함수를 쌓아 올릴때, 쌓아 올리기 전에

1:13:29.740,1:13:33.100
각 선형함수 마다 비선형성을 추가하면

1:13:33.105,1:13:36.315
무작위의 복잡한 모양을 생성 할 수 있다는 것입니다

1:13:36.315,1:13:39.595
그래서, 모든 은닉계층 이후에 
우리가 사용했던 비선형성은

1:13:39.595,1:13:42.185
ReLU (rectified linear unit) 입니다

1:13:43.180,1:13:46.800
비선형성 이라는 것은 활성함수인 것입니다

1:13:46.920,1:13:49.560
그리고 활성함수는 비선형성인 것이구요

1:13:49.835,1:13:52.955
딥러닝에 대해서 이야기 하는 겁니다

1:13:52.955,1:13:55.625
다른 많은 분야에, 비선형성의 많은 다른
정의가 있지만

1:13:56.105,1:13:59.125
딥러닝에서는 제가 말씀드린
의미라고 보시면 됩니다

1:13:59.125,1:14:02.060
활성함수란
어떤종류의 함수가 되던지간에

1:14:02.060,1:14:04.920
단일 숫자인 activation을 입력 받아서
단일 숫자의 출력 (변형된 activation)을

1:14:04.920,1:14:07.600
내놓는 것입니다.
MAX(0, X)가 그것의 한 예이구요

1:14:07.980,1:14:10.895
그리고 이번에는 다른 종류의
활성함수를 이야기 해보려고 합니다

1:14:10.895,1:14:13.865
ReLU 보다는 약간 더 복잡한데

1:14:13.865,1:14:17.275
그렇게 까지 복잡하진 않습니다
이 활성함수의 이름은 softmax 입니다

1:14:17.360,1:14:21.000
softmax 는 오직 마지막 계층에서만
적용됩니다

1:14:21.000,1:14:23.075
그 이유는

1:14:23.080,1:14:26.680
softmax 활성함수로서

1:14:26.680,1:14:30.380
항상 0~1의 범위를 가지는
여러개의 숫자들을 출력하는데

1:14:30.380,1:14:34.100
이 숫자들의 합은 1이 되기 때문입니다

1:14:34.580,1:14:38.500
softmax는 마지막에 우리가 원하는
확률값들을 출력해주는 것이죠

1:14:38.840,1:14:40.600
이론적으로는

1:14:40.600,1:14:43.620
이 함수가 반드시 필요한 것은 아닙니다

1:14:43.735,1:14:47.105
뉴럴넷에게 우리가 원하는

1:14:47.125,1:14:50.055
형태의 결과와 최대한 비슷한 형태인

1:14:50.060,1:14:52.600
확률값들을 구해주도록

1:14:52.660,1:14:55.600
학습시킬 수도 있습니다

1:14:55.605,1:14:58.545
하지만, 딥러닝에선 일반적으로

1:14:58.545,1:15:01.605
희망하는 특징이 가능한한 쉽게

1:15:01.605,1:15:04.820
표현 가능한 형태로 아키텍쳐를 만들 수 있다면

1:15:04.820,1:15:08.240
결과적으로 더 좋은 모델을
가지게 됩니다

1:15:08.240,1:15:11.620
훨씬 더 빨리, 더 적은 수의 파라메터로
학습을 할 수 있는 것입니다

1:15:12.140,1:15:15.620
이 예제에서, 우리는 이미
확률값들이 0~1의 범위를 가져야 하는 것과

1:15:15.620,1:15:18.575
그 값들이 모두 더해지면
1이 되어야 하는 것을 알고 있습니다

1:15:18.575,1:15:21.685
그렇기에, 만약 항상 이 두 특성을 모두 가지는

1:15:21.685,1:15:24.265
활성함수를 만들 수 있다면,

1:15:24.265,1:15:28.800
우리가 만들 뉴럴넷은 일을 더 잘 하게 되는 것입니다
일을 더 쉽게 할 수 있도록 해주는 것이죠

1:15:28.800,1:15:32.280
이 활성함수가 하는 일을
직접 배울 필요가 없으니까요

1:15:32.900,1:15:36.280
softmax 가 동작하는 방식은

1:15:36.300,1:15:39.840
일단 모든 음수값들을 제거하는 것입니다

1:15:39.880,1:15:43.860
음수의 확률이란건 없으니까요

1:15:43.895,1:15:46.895
음수값을 음수가 아니게 만드는

1:15:46.895,1:15:49.875
한가지 방법으로는 음수 값을
함수에 넣는 것인데요

1:15:49.880,1:15:54.900
음수 값에 첫번째로 적용된 함수는 EXP 입니다
(exponential)

1:15:55.500,1:15:58.260
전에 말씀드린 것 같은데요

1:15:58.460,1:16:01.505
딥러닝을 하면서
많이 친숙해져야 할

1:16:01.505,1:16:03.975
수학적인 내용 중 하나로는

1:16:04.225,1:16:06.855
LOG와 EXP가 있습니다

1:16:06.855,1:16:09.835
이 둘은 모든 딥러닝과 머신러닝에서

1:16:09.835,1:16:12.865
거의 항상 등장 합니다

1:16:13.800,1:16:18.000
예를 들어서

1:16:18.000,1:16:21.980
여러분이 반드시 알아야 할 것 중 하나로

1:16:21.980,1:16:33.160
ln(x · y) = ln(x) + ln(y)
같은 공식이 있습니다

1:16:33.160,1:16:36.800
이런 공식이 있다는것이 중요하다기 보단

1:16:36.800,1:16:38.955
이 공식이 의미하는 것과

1:16:38.955,1:16:41.515
이 공식이 흥미로운 이유가
곱셈을 덧셈으로 변형 가능한데

1:16:41.520,1:16:43.440
아주 유용하고 편리하구나 같은

1:16:43.460,1:16:45.480
감각을 가지는게 중요합니다

1:16:45.700,1:16:47.840
그리고 다음 공식

1:16:47.840,1:16:54.280
ln(x/y) = ln(x) - ln(y)

1:16:54.280,1:16:57.280
또한 매우 편리합니다
무슨 말인지 아시겠나요?

1:16:57.280,1:16:59.720
나눗셈을 하기 보다는

1:16:59.725,1:17:01.985
뺄셈을 할 수 있는 거에요

1:17:02.415,1:17:05.435
그리고 또,

1:17:05.435,1:17:08.615
ln(x) = y 라는 것은

1:17:08.615,1:17:11.815
e^y = x와 동일한 것입니다

1:17:11.820,1:17:13.620
다른말로 표현 해 보면,

1:17:13.880,1:17:18.520
ln와 e는 서로간에 반전이 된다는 것이죠

1:17:19.140,1:17:22.125
다시 말씀드리지만,
이런 것들을

1:17:22.125,1:17:25.085
정말로 이해하고 계셔야 합니다

1:17:25.085,1:17:27.640
LOG와 EXP를 사용 안한지 꽤 됐다면,

1:17:27.640,1:17:30.300
엑셀이나 Juypter Notebook에서

1:17:30.300,1:17:32.820
어떤 모양을 가지는지,
서로 어떻게 결합될 수 있는지

1:17:32.820,1:17:35.560
한번 그래프를 그려보면 도움이 될 수 있습니다.

1:17:35.560,1:17:39.460
중요한건 이들을 사용하는데
거부감이 없어야 한다는 거에요

1:17:40.480,1:17:44.840
다시 softmax로 돌아가서
여기서 EXP를 사용하고 있었는데요

1:17:44.840,1:17:48.000
우리는 EXP (e의 거듭제곱) 은
양수가 된다는 사실을 알고 있습니다

1:17:48.300,1:17:53.320
EXP (e의 거듭제곱)에 대한 또 다른 사실은
거듭제곱 이기 때문에

1:17:53.640,1:18:00.420
미세하게 큰 숫자 (4.08이 2.85보다 약간 큼) 가
사용 되더라도

1:18:00.420,1:18:03.880
그 크기는 크게 차이가 나게 됩니다

1:18:03.885,1:18:06.445
우리는 딥러닝을 하면서
이 두가지 특징 모두를

1:18:06.445,1:18:08.020
이용해야 합니다

1:18:08.640,1:18:09.640


1:18:09.880,1:18:13.275
다시 정리하면, fully connected 계층의
결과물인 숫자들을

1:18:13.280,1:18:17.360
EXP (e)의 거듭제곱의 
지수로 사용하게 됩니다

1:18:18.860,1:18:25.940
그리곤, EXP로 나온 변형된 결과들을
모두 더해줍니다

1:18:25.940,1:18:30.360
C7 셀에 보시면, 이들의 SUM (합)이 있습니다

1:18:30.600,1:18:33.120
그리고 나선, 합을 계산한 후

1:18:33.300,1:18:36.240
D행에서, 각 카테고리마다

1:18:36.240,1:18:40.000
EXP의 결과 값을 C7셀에 있는
모든 EXP의 결과값들의 합으로 나눠 줍니다

1:18:40.480,1:18:43.180
이 공식의 정의에 따르면

1:18:43.180,1:18:46.535
이렇게 나눠진 값들 (D행의)을
다시 모두 더하면

1:18:46.540,1:18:48.760
반드시 1이 되게 됩니다

1:18:49.360,1:18:52.900
또한, EXP 결과들의 합(C7)으로 
나누고 있기 때문에

1:18:52.960,1:18:56.000
나눠진 값의 범위는 반드시 
0~1 사이가 되게 됩니다.

1:18:56.120,1:19:01.640
여기까지가 softmax에 대한 모든 설명 입니다

1:19:03.040,1:19:04.560
한번

1:19:04.560,1:19:09.215
매번 무작위의 수를 생성해 보겠습니다

1:19:09.220,1:19:13.120
생성할때 마다 그 softmax의 결과를 보시면

1:19:13.120,1:19:14.935
비교적 많은 것들이

1:19:14.935,1:19:18.245
0에 가까운 값을 가지는 반면

1:19:18.245,1:19:21.680
하나 정도가 1에 가까운 값을 가집니다

1:19:21.680,1:19:24.220
그이유는

1:19:24.220,1:19:27.440
방금전 말씀드린 대로
EXP를 수행할때 거듭제곱의

1:19:27.440,1:19:31.280
한 지수 값이 다른 것들보다 약간만 커도
EXP의 결과가 훨씬 큰 값이 되기 때문입니다

1:19:31.480,1:19:36.620
제가 B행의 셀들에, -5 ~ 5 사이의 
무작위 수를 대입해 주긴 했지만

1:19:36.620,1:19:41.900
softmax의 결과들은
별로 무작위라고 보이지 않습니다

1:19:42.260,1:19:45.860
그들 중, 한개만이 큰 값을 가지려는
경향이 있고

1:19:45.860,1:19:48.960
다른것들은 작은 값을 가지려는
경향이 있기 때문입니다

1:19:49.220,1:19:51.840
그리고, 이것 또한 
우리가 원하는 것 중 하나입니다

1:19:51.860,1:19:54.575
입력 이미지가

1:19:54.575,1:19:57.515
고양이/개/비행기/물고기/건물 중

1:19:57.515,1:20:00.775
어떤것인지를 구분하려고 할때,

1:20:00.840,1:20:05.460
이 분류 카테고리 중 하나로
지목하고 싶은 것입니다

1:20:05.460,1:20:09.795
softmax는 이런 여러가지
좋은 속성을 가지고 있습니다

1:20:09.795,1:20:12.985
확률값들을 내뱉는데, 이 확률값들을
모두 더하면 1이 되도록 해 주고

1:20:12.985,1:20:15.760
그들 중 특정 하나를

1:20:15.760,1:20:18.620
특히나 강하게 선택하려는 경향이 있습니다

1:20:19.280,1:20:22.980
이게 바로 softmax 입니다

1:20:23.260,1:20:25.840
질문하세요?

1:20:26.240,1:20:27.280


1:20:27.685,1:20:30.645
>> 어떤 이미지가 있는데

1:20:30.645,1:20:34.360
>> 고양이, 개등 여러개의 분류 카테고리로부터

1:20:34.360,1:20:36.620
>> 분류를 하려면

1:20:36.625,1:20:38.955
>> 어떤 함수를 사용해야 하나요?
(코딩의 함수 이야기)

1:20:39.360,1:20:43.900
바로 지금 보여드릴 생각 이었습니다

1:20:44.280,1:20:47.140
일단은 왜 이것을 해야 할지 생각해 봅시다

1:20:47.140,1:20:51.260
이것이 적용 가능한 한 가지 문제로는
다중-레이블 분류 (multi label classification)가

1:20:51.260,1:20:55.320
있습니다. 지금 보고 계신 Notebook은
lesson2-image_models.ipynb 인데요

1:20:55.320,1:20:58.840
이 Notebook의 내용은 
구체적으로는

1:20:58.840,1:21:01.720
planet (위성사진 관련) 경연 입니다

1:21:02.340,1:21:06.460
위성사진 경연에는

1:21:07.040,1:21:10.540
우리가 전에 본것과
약간 비슷한 구석이 있습니다

1:21:10.545,1:21:13.845
전에 본 내용은 개와 고양이 분류였는데

1:21:13.880,1:21:16.240
보시는 각 사진은 고양이 또는 개이지

1:21:16.300,1:21:19.740
둘다가 되거나, 둘 다가 아닐 수는 없었습니다

1:21:19.740,1:21:23.080
하지만, 위성사진 경연에서는

1:21:23.140,1:21:26.105
이렇게 보이는 사진이
주어지는데요

1:21:26.105,1:21:29.065
각 사진들은 "날씨"에 의해서 분류 됩니다

1:21:29.065,1:21:31.975
총 4가지의 날씨가 있는데

1:21:31.975,1:21:35.415
그 중 두개로 haze(실안개)와 clear(화창함)
가 있습니다

1:21:36.215,1:21:39.125
이 날씨 종류 이외에

1:21:39.125,1:21:42.145
사진 속에 포함될 수 있는
추가적인 특징 목록으로

1:21:42.145,1:21:45.595
agriculture (농경지대)과

1:21:45.905,1:21:48.675
primary (1차 열대우림)과

1:21:48.675,1:21:51.925
water (강이나 협곡)같은 것들이 있습니다

1:21:52.075,1:21:55.005
오른쪽 사진은 화창한 날의

1:21:55.005,1:21:58.065
위성사진으로,  농경지대와 1차 열대우림

1:21:58.065,1:22:00.735
그리고 강/협곡이 찍혀있습니다

1:22:00.735,1:22:03.595
왼쪽 사진은 실안개 날의

1:22:03.600,1:22:07.200
1차 열대우림만이 찍혀 있습니다

1:22:07.200,1:22:08.485
우리는

1:22:08.485,1:22:11.340
이 위성사진으로 부터

1:22:11.340,1:22:14.120
여러가지 것들을 예측하고자 하는데

1:22:14.120,1:22:18.460
이 상황에서는
softmax가 좋은 대안은 아닐 겁니다

1:22:18.720,1:22:21.520
왜냐하면 softmax는 여러가지를 것들을 
예측하기 위한게 아니기 때문입니다.

1:22:21.520,1:22:24.895
저는 이 문제에 대해서, 
활성함수를 인격화 해보기를 권장합니다.

1:22:24.895,1:22:27.625
어떤 성격/인격을 가지고 있다고 말이죠

1:22:27.625,1:22:30.345
softmax의 성격은

1:22:30.345,1:22:33.025
뭔가 하나를 골라내려고 한다는 것입니다

1:22:33.265,1:22:36.205
많은 사람들이 이 사실을
종종 잊어버리는데요

1:22:36.205,1:22:40.540
심지어 유명한 논문의, 
존경받는 연구자들 조차

1:22:40.540,1:22:44.480
다중-레이블 분류 문제에 대해서

1:22:44.485,1:22:47.915
softmax를 빈번하게 사용하곤 합니다

1:22:48.160,1:22:50.500
이 사실은 꽤나 우스꽝스러운 일인데요

1:22:50.640,1:22:55.400
이들이 사용하는 활성함수의
성격을 이해하지 못하고 있기 때문이지요

1:22:56.060,1:22:58.540
하나의 입력 데이터가

1:22:58.540,1:23:01.720
여러개의 카테고리로 분류될 수 있는

1:23:01.720,1:23:05.460
다중-레이블 분류 문제를 풀기 위해서는
몇가지를 바꿔야만 합니다. (활성 함수의)

1:23:05.520,1:23:09.740
그런데, 한가지 좋은 소식은 fastai를 사용하면
아무것도 바꾸지 않아도 된다는 겁니다

1:23:10.000,1:23:12.380
fastai 라이브러리는 일단

1:23:12.400,1:23:15.240
CSV 에 있는 레이블들을 읽게 되는데

1:23:15.240,1:23:18.580
이때 하나의 아이템당

1:23:18.780,1:23:21.320
두개 이상의 레이블이 있으면

1:23:21.320,1:23:24.995
자동으로 다중-레이블 모드로 작동 방식이
변경되게 됩니다

1:23:24.995,1:23:28.095
내부적으로 어떻게 동작 하는지도
보여드릴 것입니다.

1:23:28.100,1:23:33.680
다만, 좋은 소식은 자동으로 그렇게
되기 때문에, 크게 신경쓰지 않아도 된다는 겁니다

1:23:34.640,1:23:37.980
이러한 다중-레이블 분류 문제를

1:23:37.980,1:23:40.040
풀어야 할때,

1:23:40.040,1:23:42.860
데이터들을 폴더로 분류하는

1:23:42.860,1:23:48.160
전통적인 Keras 스타일의 방식을
사용 못하는게 명백합니다

1:23:48.160,1:23:50.060
왜냐하면

1:23:50.060,1:23:53.220
어떤 데이터가 동시에 여러개의 폴더에

1:23:53.240,1:23:56.215
알맞게 존재할 수 없기 때문이죠

1:23:56.220,1:24:01.360
그렇기 때문에 from_csv 같은 방법을
사용해야만 하는 것이구요

1:24:07.240,1:24:12.720
그 과정들을 한번 보여 드리겠습니다

1:24:12.720,1:24:16.840
이것이 레이블들의 정보를 가진 CSV 파일입니다

1:24:16.845,1:24:19.915
이 부분은 side_on 대신에 top_down을

1:24:19.920,1:24:23.540
사용한 것만 빼면
전과 완벽하게 동일한 함수입니다.

1:24:23.540,1:24:26.040
top_down이 위 아래를 뒤집는다고

1:24:26.040,1:24:29.635
전에 말씀 드렸었지만, 
사실은 사각형의

1:24:29.640,1:24:34.200
8개의 가능한 대칭인, 
90°/180°/270°/0° 로 돌려가면서

1:24:34.200,1:24:38.480
각각의 각도 지점이 뒤집어질 수 있습니다

1:24:38.540,1:24:41.555
잠시동안 생각해보면

1:24:41.555,1:24:44.595
이 8개의 대칭이 하나의 사각형에서

1:24:44.600,1:24:48.960
만들 수 있는 대칭의 모든 목록이라는걸
아실 수 있을 겁니다

1:24:48.960,1:24:52.280
이것은 8개의 dihedral group 이라고 불리고

1:24:52.280,1:24:54.660
실제 코드를 보시면

1:24:54.660,1:24:59.000
transform_dihedral 이라는 부분이 나타나는데
이러한 동작 방식을 구현한 것이죠

1:24:59.000,1:25:01.295
어쨋든 이 top_down 이라는 부분은

1:25:01.300,1:25:03.900
8개의 dihedral  group의 대칭에 대해서

1:25:03.920,1:25:06.880
사진을 뒤집어 버립니다

1:25:06.885,1:25:09.055
그리고 여기에 더해서,

1:25:09.055,1:25:12.205
개/고양이 문제에서 본것 처럼
미세하게 사진을 회전하거나

1:25:12.205,1:25:14.200
약간 사진을 확대하거나

1:25:14.200,1:25:18.260
색감과 밝기를 조절하는등의
이미지 변형(강화)도 같이 이루어 집니다

1:25:18.260,1:25:21.740
어쨋든, get_data 함수를 만든 이유는

1:25:21.740,1:25:25.020
원하는 크기의 이미지를

1:25:25.020,1:25:28.760
신속하게 불러오기 위함인데,
이 함수를 사용해서

1:25:28.760,1:25:31.900
여기서 선택된 이미지 크기는 256x256 입니다

1:25:32.060,1:25:34.955
일단 data 객체를 만들고 나면

1:25:34.955,1:25:37.805
전에 보신것 처럼, 이 객체 안에는

1:25:37.805,1:25:40.755
val_ds, test_ds, train_ds 같은 배열이

1:25:40.760,1:25:43.580
들어 있는데, 이 배열의 인덱스에 접근하여

1:25:43.580,1:25:46.780
특정 이미지를 들고와서
출력해 볼 수 있었습니다

1:25:46.940,1:25:49.700
이 객체 안에는 또, val_dl/test_dl/train_dl

1:25:49.700,1:25:53.960
라는것이 있는데, dl은 data loader를 의미합니다.
ds는 data set을 의미 했구요

1:25:54.260,1:25:56.855
이 컨셉은 PyTorch에서 빌려왔습니다

1:25:56.860,1:25:59.400
PyTorch dataset, data loader같은 것을

1:25:59.400,1:26:02.380
구글링 해보면,
정확한 의미를 파악해볼 수 있습니다

1:26:02.860,1:26:05.895
그 의미를 간단하게 말씀드리자면,

1:26:05.900,1:26:09.560
ds는 하나의 이미지 또는 
데이터를 들고 있는 하나의 객체고

1:26:09.560,1:26:11.895
dl은 미니배치를 의미합니다

1:26:11.895,1:26:14.595
좀 더 구체적으로는
변환된(강화된) 미니 배치 이미지를

1:26:14.600,1:26:17.260
의미합니다.

1:26:17.260,1:26:19.800
data 객체를 만들때

1:26:19.800,1:26:23.740
얼마나 많은 프로세스를 사용하고 싶은지를 정하는
num_workers 와

1:26:23.740,1:26:27.075
어떤 방식의 강화를 적용하고 싶은지를 정하는 
tfms 같은

1:26:27.075,1:26:30.085
파라메터의 값을 지정해 줄 수도 있는
이유이기도 합니다

1:26:30.085,1:26:33.045
어쨋든, data loader로 부터는
각 이미지를 달라고 요청할 수 없고

1:26:33.045,1:26:35.875
미니 배치형태만을 접근할 수 있습니다

1:26:35.875,1:26:38.615
또한, 특정 미니배치를 지정해서 얻을 수 없고

1:26:38.615,1:26:41.575
항상 다음의 미니배치 만을 접근하게 됩니다

1:26:41.580,1:26:44.545
루프를 돌면서, 한번에 한개의 미니배치에
접근하게 되는 것이지요

1:26:44.740,1:26:46.140
파이썬에 보면

1:26:46.160,1:26:48.720
이렇게 루프를 수행하는 녀석을

1:26:48.720,1:26:52.015
generator 또는 iterator라고 부르는데요
(버전에 따라 다르지만, 동일함)

1:26:52.015,1:26:55.015
data loader를 iterator로 바꿔주기 위해선

1:26:55.020,1:26:58.100
파이썬의 표준 기능인 iter를 사용하면 됩니다

1:26:58.100,1:27:00.975
파이썬의 언어로서의 기본적인

1:27:00.975,1:27:04.015
함수로, iterator를 리턴하게 됩니다

1:27:04.015,1:27:07.215
그리고 리턴된 iterator는

1:27:07.215,1:27:10.245
파이썬의 기본 제공되는 표준 함수인파

1:27:10.245,1:27:13.305
next 에 전달될 수 있는데, 전달되면 
그 iterator로 부터

1:27:13.305,1:27:18.100
"그 다음 미니배치를 줘" 라는 요청을 하게 됩니다

1:27:18.440,1:27:22.720
이 부분이 제가 PyTorch에서 
정말 좋아하는 것 중 하나입니다

1:27:22.725,1:27:25.375
현대적인 파이썬의 기능을

1:27:25.375,1:27:28.335
충분히 활용하도록끔 해주거든요

1:27:28.335,1:27:31.055
반면에 TensorFlow는 뭔가를 하기 위한

1:27:31.060,1:27:35.720
그들만의 세상을 만들어 냈습니다

1:27:35.720,1:27:38.700
크로스 플랫폼적인 의미도 있지만

1:27:38.700,1:27:43.580
어떤 플랫폼에도 잘 맞아들지 못한다는
의미가 되기도 합니다

1:27:44.440,1:27:49.075
파이썬을 잘 아신다면,
PyTorch는 아주 자연스럽게

1:27:49.075,1:27:51.905
받아들여 질 겁니다.
만약 파이썬을 잘 모르신다면

1:27:51.905,1:27:55.800
PyTorch는 Python도 동시에 배울 수 있는
좋은 이유가 될 수도 있겠죠

1:27:56.120,1:27:59.135
예를 들어서, PyTorch의 뉴럴넷 모듈은

1:27:59.135,1:28:02.245
파이썬의 표준적인 모양을 띕니다

1:28:02.245,1:28:05.105
파이썬 공부에 더 많은 시간을 투자하면

1:28:05.105,1:28:08.255
그 보상이 PyTorch로 이어질 수 있는 것입니다

1:28:08.260,1:28:13.240
어쨋든, 여기서 다음 미니배치를 "검증 data loader"
로 부터 가져오기 위해서

1:28:13.240,1:28:16.480
파이썬의 표준적인 방식인
iterator와 next를 사용 했습니다

1:28:16.480,1:28:20.375
이 문장을 실행하면, 두 가지를 리턴하는데

1:28:20.375,1:28:23.395
미니배치에 있는 이미지와 레이블 정보 입니다

1:28:23.595,1:28:26.935
표준적인 파이썬 방식으로
이 두개를 쪼개서 리턴 받았습니다

1:28:27.020,1:28:29.380
그리고, 여기 y는 하나의 미니배치에

1:28:29.380,1:28:31.660
포함된 레이블을 보여줍니다

1:28:34.880,1:28:40.700
제가 설정했던 배치 크기가
(찾아보고 있음)

1:28:40.960,1:28:45.660
사실상 디폴트로 사용되는 배치 크기는 64 입니다

1:28:45.660,1:28:50.140
보시면 배치크기를 명시적으로 전달 안했죠

1:28:50.260,1:28:53.920
기억하시죠? Shift+Tab 하면, 파라메터가 
뭐가 있고, 각 디폴트 값이 뭔지 확인 가능합니다

1:28:54.000,1:28:56.560
그래서, 디폴트 배치 크기는 64 였습니다

1:28:56.565,1:28:59.565
그래서 y를 출력해 보니

1:28:59.565,1:29:03.020
뭔가 크기가 64x17인 것을 발견할 수 있는데

1:29:03.020,1:29:06.200
17은 17개의 분류 카테고리가 있다는 것입니다

1:29:06.860,1:29:10.280
그러면 y의 0번째 내용을
한번 살펴 봅시다

1:29:10.280,1:29:14.980
0번째 이미지에 대한 레이블 목록이
확인 가능합니다

1:29:15.300,1:29:18.420
여기서 또 파이썬 표준 함수인 zip을

1:29:18.425,1:29:21.655
사용하는데, 인자로 두 개의 배열(list)를 받아서

1:29:21.660,1:29:25.640
각 배열의 동일 인덱스의 내용들을 묶어줍니다

1:29:25.640,1:29:31.175
data.classes (카테고리 목록)과
0번째 이미지의 레이블값들 (0또는 1로 구성)을

1:29:31.180,1:29:33.960
zip 하면, 검증 데이터셋에서 가져온

1:29:33.960,1:29:36.680
미니배치의 0번째 이미지가

1:29:36.680,1:29:39.540
농경지대를 가지고 있고,
화창한 날씨에 찍혔으며

1:29:39.560,1:29:42.400
1차 열대우림도 가지고 있고,
화전도 가지고 있고

1:29:42.400,1:29:45.800
강/협곡도 가지고 있다는걸 알 수 있습니다.

1:29:45.800,1:29:48.760
이 결과에서 보듯이

1:29:48.760,1:29:51.440
다중-레이블 분류에 대한

1:29:51.480,1:29:54.480
문제라는 것을 알 수 있기도 합니다

1:29:55.160,1:29:58.080
아까 설명한 softmax 엑셀로 돌아가보면

1:29:58.080,1:30:01.580
단일-레이블 분류 문제를 다뤘는데요

1:30:01.580,1:30:04.500
개/고양이/비행기/물고기/건물 중 하나를
선택하는 것이었죠

1:30:04.965,1:30:08.105
우리가 아직 보지 않은 내부적인 내용으로

1:30:08.105,1:30:10.680
내부적으로

1:30:10.720,1:30:13.140
fastai와 PyTorch는

1:30:13.140,1:30:18.080
레이블들을 "one hot encode된 레이블" 이라는
것으로 변형을 하게 됩니다

1:30:18.080,1:30:20.560
만약 이미지가 개라고 가정해 보면,

1:30:20.580,1:30:23.540
"개"라고 표현하기 위한 실제 값은

1:30:23.560,1:30:27.440
보시는것 처럼 (0, 1, 0, 0, 0) 과 같이
구성 됩니다

1:30:27.700,1:30:31.900
Ottavia의 비디오의 마지막 부분을
기억 하실 겁니다

1:30:31.900,1:30:34.205
ABCDE 템플릿에

1:30:34.205,1:30:37.345
얼마나 잘 맞아들어가는지에 대한

1:30:37.345,1:30:39.080
내용 이었습니다

1:30:39.080,1:30:42.840
이 맞아들어가는지를 알아내기 위해
실제로 일어나는 일은

1:30:42.840,1:30:45.980
기본적으로 행렬의 곱셈을 수행하는 것입니다.

1:30:46.565,1:30:49.645
마지막엔 fully connected 계층이 있고

1:30:49.645,1:30:52.575
이 계층은 output activation을 계산하고

1:30:52.580,1:30:55.560
그 activations들은 softmax 과정을 거칩니다

1:30:55.620,1:30:59.615
그리곤, softmax의 결과는 one hot encode된 
레이블값과 비교되게 됩니다

1:30:59.620,1:31:02.500
우리가 가정했던건 이미지가 "개"라는 것으로

1:31:02.500,1:31:05.740
E3 부분이 1로 되어 있습니다.

1:31:05.745,1:31:08.885
actuals의 값에서 softmax의 결과를 빼서

1:31:08.885,1:31:11.520
나온 값들을 모두 더하면,

1:31:11.520,1:31:14.700
얼마나 많은 에러가 있는지를
알 수 있게 됩니다

1:31:14.720,1:31:17.460
지금 우리는 손실함수 라는 내용을
건너뛰었는데

1:31:17.460,1:31:20.960
다음주에 배울 내용이긴 합니다만
지금 보여드리는게 바로 그 내용입니다

1:31:21.640,1:31:22.640
그러면

1:31:22.720,1:31:24.800
단 하나만이 1의 값을 가지는 형태인

1:31:24.860,1:31:27.915
one hot encode 가 되었다면

1:31:27.915,1:31:30.945
모든 0을 다 포함해서 
저장하는 행위는

1:31:30.945,1:31:32.700
엄청나게

1:31:32.740,1:31:35.140
비효율적입니다

1:31:35.140,1:31:38.560
대신에 이렇게 해볼 수 있을지도 모릅니다

1:31:38.560,1:31:41.580
각 카테고리마다 인덱스를

1:31:41.600,1:31:45.020
0 1 2 3 4 처럼 부여해서

1:31:45.020,1:31:48.680
actuals 값을 (0 1 0 0 0) 처럼 저장하는 것 대신

1:31:48.920,1:31:52.760
단순히 인덱스 값을 저장해볼 수 있겠죠

1:31:52.940,1:31:55.080
예를 들어서,

1:31:55.080,1:31:58.075
개/고양이나 
개 품종을 분류하는

1:31:58.080,1:32:00.620
문제를 생각해 보시면

1:32:00.620,1:32:06.100
0과 1의 값이 많이 있는 형태가 아니라
단 하나의 정수값만을 저장하면 되는 것입니다

1:32:06.100,1:32:09.860
그 카테고리의 인덱스 값 말이에요

1:32:10.320,1:32:12.080
그리고

1:32:12.080,1:32:15.165
PyTorch는 이 인덱스를 가지고 내부적으로

1:32:15.165,1:32:17.975
one hot encode된 벡터로 변환하게 됩니다

1:32:17.975,1:32:20.915
내부적으로 일어나는 일로,
실제로 보게될 일은 없는 것입니다

1:32:20.915,1:32:23.915
또한 PyTorch는

1:32:23.915,1:32:26.935
one hot encode된 것과

1:32:26.935,1:32:29.885
그렇지 않은 것에 대해서

1:32:29.885,1:32:32.500
다른 종류의 손실함수를 사용합니다

1:32:32.500,1:32:35.840
설명드린 것은 fastai 라이브러리 내부에

1:32:35.840,1:32:39.420
숨겨져 있는 것으로, 여러분이 직접 걱정할
필요가 없는 것입니다

1:32:39.480,1:32:42.020
한가지 좋은점은

1:32:42.020,1:32:44.880
이러한 방식이

1:32:44.885,1:32:47.995
다중-레이블 분류 에서도

1:32:47.995,1:32:51.165
내부적으로는 단일-레이블 분류와

1:32:51.165,1:32:53.980
동일한 과정이 적용된다는 것입니다

1:32:54.720,1:32:57.700
>> softmax 함수에 사용된

1:32:57.720,1:33:01.700
>> LOG의 밑(base)을 바꾸는게 
의미가 있을까요?

1:33:02.255,1:33:05.055
아니요.

1:33:05.060,1:33:10.640
좀 더 수학을 해보도록 하죠

1:33:10.940,1:33:20.140
log_a(b) = ln(b) / ln(a)

1:33:20.140,1:33:25.340
공식을 보시면, 밑을 바꾼다는것은
단순히 선형적으로 스케일링 되는 것입니다

1:33:25.345,1:33:28.335
선역적 스케일링이라는 것은

1:33:28.340,1:33:33.560
뉴럴넷이 아주 쉽게 학습 할 수 있는 것이구요

1:33:36.520,1:33:39.640
좋은 질문 이었어요

1:33:39.640,1:33:42.800
여기 보이는 이미지는

1:33:42.800,1:33:45.540
농경지대, 1차열대우림, 화전

1:33:45.540,1:33:48.320
강/협곡, 화창한 날씨 정보를 포함합니다

1:33:48.320,1:33:52.380
한가지 짚고 넘어갈 것이 있는데
제가 이 이미지를 처음 출력했을때

1:33:52.385,1:33:55.795
색이 많이 바래서, 제대로 보기 힘들었습니다

1:33:55.820,1:33:59.220
하지만, 배웠다 시피
이미지라는건

1:33:59.240,1:34:03.300
단순히 행렬의 값들로 이루어져 있습니다

1:34:03.300,1:34:06.880
여기 코드에 *1.4 가
되어 있는걸 보실 수 있을텐데

1:34:07.020,1:34:10.355
좀 더 이미지를 또렷하게 해 주기 위해서 입니다

1:34:10.355,1:34:13.355
제가 여러분이 친숙해졌으면 하는 부분으로

1:34:13.360,1:34:16.860
이미지는 단순히 행렬의 값으로 이루어져 있다는 것과

1:34:16.860,1:34:19.415
이 값들을 조작해 볼 수 있다는 것입니다

1:34:19.415,1:34:22.535
예를 들어서, 
"사진이 색이 바랬네?"

1:34:22.540,1:34:26.880
"그러면 값을 곱해서 밝기를 조절하면 되겠구나"
처럼 말이죠

1:34:27.420,1:34:30.495
어쨋든,
아마 이 부분이 화전 같고

1:34:30.495,1:34:33.525
여기는 강이고
여기는 1차 열대우림이고

1:34:33.525,1:34:36.480
이쪽은 아마도 농경지대 같아 보이네요

1:34:39.080,1:34:42.695
이 모든 배경 정보를

1:34:42.695,1:34:45.705
사용하기 위한 방법은

1:34:45.705,1:34:49.920
우리가 전에 했던 것과
정확히 동일합니다

1:34:50.540,1:34:53.460
이 planet 경연을 가지고

1:34:53.465,1:34:56.495
이것저것 해보면 알 수 있는 
한가지 흥미로운 사실은

1:34:56.500,1:34:59.160
이 이미지들은 ImageNet의 이미지와는
완전히 다르다는 것입니다

1:34:59.600,1:35:02.655
그리고, 제 생각에 거의 대부분의

1:35:02.655,1:35:05.645
컨볼루션 뉴럴넷이 연관된

1:35:05.645,1:35:08.605
이미지 관련 문제들은

1:35:08.605,1:35:11.755
ImageNet과는 상이합니다

1:35:11.755,1:35:14.565
의학적인 이미지가 될 수도 있고

1:35:14.565,1:35:17.580
서로다른 금속 튜브를

1:35:17.580,1:35:20.800
분류하는 경우도 있고

1:35:20.805,1:35:23.885
위성 사진으로 작업하는 경우같은

1:35:23.885,1:35:26.935
여러가지 상황이 있을 수 있습니다

1:35:26.935,1:35:27.935


1:35:28.775,1:35:31.555
그러니까, 지금 planet 경연과 같은

1:35:31.555,1:35:34.545
문제로 실험을 해보는건

1:35:34.545,1:35:37.505
좋은 경험이 될 것입니다

1:35:37.505,1:35:40.465
일단 이미지 크기를 64x64로

1:35:40.465,1:35:42.320
바꾸는 것으로 시작하였습니다

1:35:42.320,1:35:45.960
초기값은 256x256 이었구요

1:35:45.960,1:35:50.480
그런데, 사이즈를 이렇게 조절하는건
개/고양이 문제에서는 사용안할거 같습니다

1:35:50.480,1:35:52.060
왜냐하면

1:35:52.060,1:35:55.615
ImageNet에 미리 학습된 
모델을 가지고 시작 했는데

1:35:55.615,1:35:58.715
시작부터가 이미 꽤나
완벽했기 때문입니다

1:35:58.715,1:36:01.885
이미지 크기를 64x64로 줄여서

1:36:01.885,1:36:04.745
다시 모든 것을 학습시키게 되면

1:36:04.745,1:36:07.735
미리 학습된 아주 좋은 가중치값들을

1:36:07.735,1:36:10.525
파괴(망치게) 하게 됩니다

1:36:10.785,1:36:13.495
대부분의 ImageNet에 학습된 모델들은

1:36:13.495,1:36:16.595
224x224 또는 299x299 크기의 이미지에
대해서 학습 되었습니다

1:36:16.595,1:36:19.205
그렇기 때문에 64x64에 대해서
다시 학습을 시키면

1:36:19.205,1:36:21.400
이 모든것이 바뀌게 되는겁니다

1:36:21.600,1:36:23.320
다른 한편으로는

1:36:23.340,1:36:25.660
ImageNet 데이터셋에는

1:36:25.720,1:36:29.420
이렇게 생긴 이미지가 전혀 없습니다,
위성사진이 전혀 없는 것이죠

1:36:29.535,1:36:32.405
그렇기 때문에, 현재 저희에게

1:36:32.405,1:36:34.800
ImageNet에 학습된 모델이

1:36:34.800,1:36:37.300
유용할 수 있는 부분은

1:36:37.300,1:36:39.940
경계선을 찾아내는 계층과

1:36:39.940,1:36:42.960
그라데이션 같은걸 찾아내는 계층,

1:36:43.020,1:36:47.580
그리고, 질감이나 반복적인 패턴을 찾아내는
두번째 계층 정도가 될 수 있을 겁니다

1:36:47.580,1:36:49.940
어쩌면 계층3도 약간 복잡한 질감이나 패턴을

1:36:49.940,1:36:53.820
찾아내니까 유용할지도 모르겠군요.
하지만 여기까지 정도입니다

1:36:54.180,1:36:57.420
다시 말해서,
위성 사진 같은것을 사용할때

1:36:57.420,1:37:00.860
작은 이미지로 학습을 시작하는것은

1:37:00.860,1:37:03.900
꽤나 잘 동작하게 도와줍니다

1:37:03.900,1:37:07.075
그래서 이 예제에서는 64x64 크기를
제일 처음으로 지정해주고

1:37:07.080,1:37:09.760
이에대한 몇 데이터를 들고 왔습니다

1:37:09.760,1:37:12.680
그리곤 모델을 생성했고

1:37:12.680,1:37:15.915
사용하기 위한 학습률을 찾는 과정을 거쳤습니다

1:37:15.920,1:37:19.640
약간 흥미롭게도, 발견된 학습률이 꽤나 
값이 컸습니다

1:37:19.680,1:37:22.680
ImageNet과는 아주 다르기 때문에

1:37:22.680,1:37:24.900
마지막 계층에 대해서

1:37:24.900,1:37:27.480
더이상 어떤 향상도 이뤄지지 않는 지점에

1:37:27.480,1:37:31.080
도달할때까지, 더 많은 학습(epoch) 이
 필요한것 처럼 보이는 군요

1:37:31.080,1:37:34.320
마지막 계층 학습 이후에
unfreeze를 수행했는데

1:37:34.320,1:37:39.280
이때 선택된 차등 학습률들도, ImageNet과 
유사한 상황에 사용된 것과는 상이합니다

1:37:39.280,1:37:41.095
초반 계층들에 대한

1:37:41.095,1:37:44.275
학습률로는 0.2/9을 설정 해 줬고

1:37:44.275,1:37:47.005
중간 계층들에 대한 학습률은
0.2/3로 설정해 줬습니다

1:37:47.005,1:37:49.860
ImageNet과 유사한 상황에서는

1:37:49.920,1:37:53.380
각각을 10의 배수로 값을 바꿔 줬었죠

1:37:53.380,1:37:56.495
다시 말씀드리자면, 초반 계층들은

1:37:56.495,1:37:59.355
ImageNet과 비교 할 때, 위성사진을 위해서

1:37:59.360,1:38:03.380
뭔가 더 가까워질만한 부분이 없습니다.
(학습률이 낮게 설정된 이유)

1:38:03.540,1:38:07.400
차등 학습률을 정의한 후, unfreeze를 수행했고
차등학습률로 학습을 한동안 진행했습니다

1:38:07.420,1:38:09.880
결과 그래프를 보시면

1:38:09.880,1:38:11.220
여기가 첫번째,

1:38:11.220,1:38:12.380
여기는 두번째,

1:38:12.380,1:38:14.820
여기에 세번째 주기(cycle)가
있는걸 보실 수 있습니다

1:38:15.300,1:38:18.100
그리고 나선, 이미지 크기를 두배 증가시켰습니다

1:38:18.100,1:38:22.220
다시 학습을 한동안 수행했고, unfreeze를 한 다음
차등학습률에 대한 학습을 수행했습니다

1:38:22.220,1:38:24.720
그리고 또다시 이미지 크기를 두배 증가시켰고

1:38:24.720,1:38:27.500
다시 학습을 한동안 수행했고, unfreeze를 한 다음
차등학습률에 대한 학습을 수행했습니다

1:38:27.500,1:38:29.920
그리고 마지막에 TTA를 추가 했습니다

1:38:29.925,1:38:32.535
전에 보셨다 시피, 여기까지 진행한 결과는

1:38:32.535,1:38:35.875
약 30등 정도 하는 결과를 보여줬습니다

1:38:35.875,1:38:38.765
제 생각엔 아주 좋은 결과라고 생각 합니다

1:38:38.765,1:38:41.280
몇 개월 전만 해도, 아주 똑똑한 사람들 조차도

1:38:41.280,1:38:45.220
이 문제에 대해서, 아주 힘겹게
도전해야 했거든요

1:38:46.220,1:38:50.100
사람들이 두 가지 질문을 해주셨는데요
그 중 하나는

1:38:50.340,1:38:54.120
data.resize가 하는일이 뭐냐는 것이었습니다

1:38:54.360,1:38:59.680
몇가지 부분들을 보여드려야 할 것 같습니다

1:38:59.740,1:39:03.520


1:39:03.520,1:39:07.500
어떤 종류의 강화기법을 적용할지를
정의할때,

1:39:07.500,1:39:11.415
이미지 사이즈 정보를 인자로 넘겨 줍니다

1:39:11.420,1:39:13.260
data loader 가 하는 일 중 하나는

1:39:13.260,1:39:17.220
요청이 있을때 마다(on demand)

1:39:17.220,1:39:20.140
이미지 크기를 키우거나 줄이는 것입니다

1:39:21.120,1:39:24.220
이 부분은 data.resize 와는 관련이 없는 부분입니다

1:39:24.340,1:39:28.840
이 부분은 어떤 값이 들어오던지 간에

1:39:28.880,1:39:32.015
data loader가 데이터를 리턴하기 직전에

1:39:32.020,1:39:34.980
명시된 크기로 이미지를 변환 해주는 부분 입니다

1:39:35.460,1:39:38.755
만약 초기의 입력 크기가 1000x1000 이라고
가정을 해 보면,

1:39:38.755,1:39:41.925
각 미니배치 마다, 그 크기의 JPEG 
파일들을 읽어들인 후

1:39:41.925,1:39:44.945
64x64 의 크기로 축소하게 되는 과정이

1:39:44.995,1:39:47.815
사실상, 컨볼루션 뉴럴넷을 학습시키는 시간보다

1:39:48.260,1:39:51.780
더 오래 걸리게 됩니다

1:39:51.780,1:39:53.800
기본적으로

1:39:53.800,1:39:56.340
resize가 하는 일은

1:39:56.340,1:40:00.120
sz*1.3 보다 큰 이미지는 사용하지
않을 것이라는걸 알려주는 것인데

1:40:00.120,1:40:04.015
한번만 수행되고,  sz*1.3 크기의

1:40:04.020,1:40:06.960
새로운 JPEG 파일들을 생성하게 됩니다

1:40:06.980,1:40:09.765
그리고 생성된 JPEG 는

1:40:09.765,1:40:14.960
가장 짧은 모서리 길이가 sz*1.3인
사각형 모양을 가집니다

1:40:14.960,1:40:17.980
이 기능을 속도향상의 이유가 아니라면

1:40:17.980,1:40:20.100
사용할 이유는

1:40:20.100,1:40:23.800
어디에도 없습니다. 다만, 입력 이미지의 크기가
너무나도 크다면

1:40:24.125,1:40:27.175
많은 시간을 절약해 줄 것입니다.

1:40:27.175,1:40:30.045
종종 Kaggle 커널이나, 포럼에 보시면

1:40:30.045,1:40:32.840
다른분들이 bash 스크립트 같은것을

1:40:32.840,1:40:35.035
적어 놓는데, 그 내용인즉

1:40:35.035,1:40:37.985
모든 이미지를 loop 하면서,
크기를 재조정 하는 것입니다.

1:40:37.985,1:40:40.895
여러분은 그럴필요 없이
이 함수를 사용하시면 되는 것이죠

1:40:40.895,1:40:43.515
일회성으로 수행되어 크기가 재조정된

1:40:43.520,1:40:47.320
이미지를 생성해 주고,
만약 이미 생성된 이미지가 있으면

1:40:47.340,1:40:50.440
그 생성된 이미지를 사용하게 됩니다

1:40:51.600,1:40:55.780
단순히 속도향상을 위한 편리한 기능의 함수 입니다

1:40:57.120,1:40:58.120


1:40:58.645,1:41:01.965


1:41:02.485,1:41:05.025


1:41:05.765,1:41:07.465


1:41:07.885,1:41:10.835


1:41:10.835,1:41:12.645


1:41:13.525,1:41:16.425


1:41:16.425,1:41:17.545


1:41:18.065,1:41:20.695


1:41:20.695,1:41:23.775


1:41:23.775,1:41:26.665


1:41:26.665,1:41:29.755


1:41:29.755,1:41:31.115


1:41:31.685,1:41:32.685


1:41:33.485,1:41:36.275


1:41:36.275,1:41:39.345


1:41:39.345,1:41:42.705


1:41:42.785,1:41:43.785


1:41:45.605,1:41:48.605


1:41:48.605,1:41:51.545


1:41:51.545,1:41:54.715


1:41:54.715,1:41:57.945


1:41:58.215,1:42:01.155


1:42:01.155,1:42:02.045


1:42:02.045,1:42:05.065


1:42:05.065,1:42:08.195


1:42:08.735,1:42:11.795


1:42:11.795,1:42:14.665


1:42:14.665,1:42:17.385


1:42:17.385,1:42:20.395


1:42:20.395,1:42:22.955


1:42:23.445,1:42:25.235


1:42:25.975,1:42:27.205


1:42:27.865,1:42:30.625


1:42:30.625,1:42:32.875


1:42:32.875,1:42:35.815


1:42:36.015,1:42:39.095


1:42:39.205,1:42:42.245


1:42:43.085,1:42:44.815


1:42:46.085,1:42:49.125


1:42:49.125,1:42:50.125


1:42:50.335,1:42:53.355


1:42:53.675,1:42:55.235


1:42:55.925,1:42:58.685


1:42:59.115,1:43:02.175


1:43:02.175,1:43:05.315


1:43:05.575,1:43:08.255


1:43:08.255,1:43:09.695


1:43:11.135,1:43:14.335


1:43:16.575,1:43:19.605


1:43:19.605,1:43:22.055


1:43:22.615,1:43:24.035


1:43:24.495,1:43:27.615


1:43:27.615,1:43:30.735


1:43:30.735,1:43:32.045


1:43:32.395,1:43:35.255


1:43:35.545,1:43:39.015


1:43:39.365,1:43:42.575


1:43:42.575,1:43:43.575


1:43:44.185,1:43:45.185


1:43:45.685,1:43:46.685


1:43:47.135,1:43:48.135


1:43:50.255,1:43:53.275


1:43:53.275,1:43:56.365


1:43:56.365,1:43:58.085


1:43:58.425,1:44:01.395


1:44:01.395,1:44:04.565


1:44:04.885,1:44:07.825


1:44:08.085,1:44:10.285


1:44:10.775,1:44:11.775


1:44:11.915,1:44:13.245


1:44:13.985,1:44:16.955


1:44:16.955,1:44:19.815


1:44:19.815,1:44:21.705


1:44:22.455,1:44:25.455


1:44:25.455,1:44:28.565


1:44:28.565,1:44:31.115


1:44:31.185,1:44:34.175


1:44:34.175,1:44:37.225


1:44:37.225,1:44:40.255


1:44:40.255,1:44:43.315


1:44:43.315,1:44:44.515


1:44:45.345,1:44:47.865


1:44:48.345,1:44:50.615


1:44:50.615,1:44:53.695


1:44:53.695,1:44:56.725


1:44:57.475,1:45:00.655


1:45:00.655,1:45:03.825


1:45:03.825,1:45:06.935


1:45:06.935,1:45:10.015


1:45:10.115,1:45:12.915


1:45:12.915,1:45:15.325


1:45:15.865,1:45:18.975


1:45:18.975,1:45:19.955


1:45:19.955,1:45:23.215


1:45:23.625,1:45:24.625


1:45:24.645,1:45:27.645


1:45:27.645,1:45:30.885


1:45:30.885,1:45:33.785


1:45:33.785,1:45:37.005


1:45:37.145,1:45:39.555


1:45:39.555,1:45:41.995


1:45:42.985,1:45:45.935


1:45:45.935,1:45:47.495


1:45:48.865,1:45:51.915


1:45:51.915,1:45:55.245


1:45:55.505,1:45:56.595


1:45:57.615,1:45:59.255


1:46:00.395,1:46:01.395


1:46:03.125,1:46:04.575


1:46:05.275,1:46:08.225


1:46:08.225,1:46:09.435


1:46:09.775,1:46:11.715


1:46:12.155,1:46:13.155


1:46:13.445,1:46:16.475


1:46:16.475,1:46:17.825


1:46:18.435,1:46:21.455


1:46:21.455,1:46:24.875


1:46:24.875,1:46:27.725


1:46:27.725,1:46:30.715


1:46:30.715,1:46:31.715


1:46:31.895,1:46:32.895


1:46:32.975,1:46:34.085


1:46:36.205,1:46:37.625


1:46:38.245,1:46:41.085


1:46:41.085,1:46:42.965


1:46:45.935,1:46:48.465


1:46:49.715,1:46:50.715


1:46:51.645,1:46:54.515


1:46:54.785,1:46:58.155


1:46:58.525,1:47:00.165


1:47:00.735,1:47:04.135


1:47:04.335,1:47:07.435


1:47:07.435,1:47:10.235


1:47:10.355,1:47:12.725


1:47:13.525,1:47:16.495


1:47:16.495,1:47:19.525


1:47:19.525,1:47:22.905


1:47:22.945,1:47:25.805


1:47:30.285,1:47:33.295


1:47:33.295,1:47:36.205


1:47:36.205,1:47:39.275


1:47:39.745,1:47:42.745


1:47:42.745,1:47:45.725


1:47:45.725,1:47:48.575


1:47:48.705,1:47:51.825


1:47:52.015,1:47:55.145


1:47:55.145,1:47:57.795


1:47:57.795,1:48:00.685


1:48:00.685,1:48:03.695


1:48:03.695,1:48:05.505


1:48:07.025,1:48:09.075


1:48:09.075,1:48:11.965


1:48:12.075,1:48:14.895


1:48:14.895,1:48:17.695


1:48:17.695,1:48:20.235


1:48:20.685,1:48:22.225


1:48:22.865,1:48:25.855


1:48:25.855,1:48:29.185


1:48:29.335,1:48:32.225


1:48:32.225,1:48:35.275


1:48:35.275,1:48:38.095


1:48:38.295,1:48:41.285


1:48:41.285,1:48:44.385


1:48:44.655,1:48:47.785


1:48:48.195,1:48:51.375


1:48:51.375,1:48:54.415


1:48:54.415,1:48:57.105


1:48:57.365,1:49:00.375


1:49:00.375,1:49:03.165


1:49:03.375,1:49:06.435


1:49:06.435,1:49:09.165


1:49:09.165,1:49:10.165


1:49:10.595,1:49:13.625


1:49:13.675,1:49:14.675


1:49:15.635,1:49:19.105


1:49:19.135,1:49:21.675


1:49:21.995,1:49:24.395


1:49:24.395,1:49:27.435


1:49:27.855,1:49:29.905


1:49:30.815,1:49:31.815


1:49:32.305,1:49:34.895


1:49:34.895,1:49:35.895


1:49:36.315,1:49:39.425


1:49:39.425,1:49:42.285


1:49:42.285,1:49:45.645


1:49:46.095,1:49:49.105


1:49:49.285,1:49:50.775


1:49:51.415,1:49:52.705


1:49:53.635,1:49:56.645


1:49:56.645,1:49:59.285


1:49:59.285,1:50:01.775


1:50:01.775,1:50:04.765


1:50:04.765,1:50:07.735


1:50:07.805,1:50:10.995


1:50:10.995,1:50:14.045


1:50:14.045,1:50:17.035


1:50:17.035,1:50:20.315


1:50:20.495,1:50:23.265


1:50:23.265,1:50:24.265


1:50:24.845,1:50:27.945


1:50:27.945,1:50:30.965


1:50:30.965,1:50:33.805


1:50:33.975,1:50:36.985


1:50:36.985,1:50:39.935


1:50:39.935,1:50:43.025


1:50:43.025,1:50:44.955


1:50:45.675,1:50:48.645


1:50:48.645,1:50:51.645


1:50:51.725,1:50:54.785


1:50:54.785,1:50:57.825


1:50:57.825,1:50:59.155


1:50:59.835,1:51:03.185


1:51:03.185,1:51:06.205


1:51:06.205,1:51:09.165


1:51:09.165,1:51:10.315


1:51:11.515,1:51:14.535


1:51:14.535,1:51:15.535


1:51:16.955,1:51:19.965


1:51:19.965,1:51:22.975


1:51:22.975,1:51:25.765


1:51:25.765,1:51:29.225


1:51:29.265,1:51:31.665


1:51:31.665,1:51:34.685


1:51:34.685,1:51:36.485


1:51:36.935,1:51:39.355


1:51:41.005,1:51:44.375


1:51:44.625,1:51:46.985


1:51:46.985,1:51:49.495


1:51:49.495,1:51:52.385


1:51:52.385,1:51:53.755


1:51:54.155,1:51:57.195


1:51:57.195,1:52:00.295


1:52:00.295,1:52:03.145


1:52:03.145,1:52:04.565


1:52:05.355,1:52:07.295


1:52:08.825,1:52:10.345


1:52:10.765,1:52:11.765


1:52:12.845,1:52:13.845


1:52:14.425,1:52:16.945


1:52:17.255,1:52:20.295


1:52:20.295,1:52:23.095


1:52:23.095,1:52:26.185


1:52:26.185,1:52:29.115


1:52:29.115,1:52:32.195


1:52:32.195,1:52:33.195


1:52:33.665,1:52:36.485


1:52:36.485,1:52:39.545


1:52:39.545,1:52:42.105


1:52:42.105,1:52:45.375


1:52:46.055,1:52:49.115


1:52:49.115,1:52:52.265


1:52:52.265,1:52:53.825


1:52:54.375,1:52:57.405


1:52:57.405,1:52:59.505


1:52:59.505,1:53:01.955


1:53:01.955,1:53:05.315


1:53:05.445,1:53:08.365


1:53:08.365,1:53:11.335


1:53:11.335,1:53:14.055


1:53:14.055,1:53:16.745


1:53:16.745,1:53:18.675


1:53:19.055,1:53:22.165


1:53:22.165,1:53:25.125


1:53:25.125,1:53:27.685


1:53:28.075,1:53:31.425


1:53:32.115,1:53:35.185


1:53:35.185,1:53:37.215


1:53:37.585,1:53:38.585


1:53:38.585,1:53:41.685


1:53:41.685,1:53:45.105


1:53:45.195,1:53:48.145


1:53:48.145,1:53:50.865


1:53:50.865,1:53:54.235


1:53:54.235,1:53:57.025


1:53:57.025,1:54:00.095


1:54:00.095,1:54:02.615


1:54:02.615,1:54:05.655


1:54:05.655,1:54:07.955


1:54:07.955,1:54:11.115


1:54:11.535,1:54:14.875


1:54:14.875,1:54:17.825


1:54:17.825,1:54:20.145


1:54:20.145,1:54:23.185


1:54:23.185,1:54:26.285


1:54:26.285,1:54:29.205


1:54:29.205,1:54:31.995


1:54:31.995,1:54:35.125


1:54:35.125,1:54:36.125


1:54:36.535,1:54:39.225


1:54:39.225,1:54:40.245


1:54:41.415,1:54:42.855


1:54:43.515,1:54:46.285


1:54:46.285,1:54:49.385


1:54:49.385,1:54:52.365


1:54:52.365,1:54:55.425


1:54:55.425,1:54:56.335


1:54:56.335,1:54:59.295


1:55:02.625,1:55:03.725


1:55:04.115,1:55:07.045


1:55:07.045,1:55:08.365


1:55:10.045,1:55:12.665


1:55:13.895,1:55:16.645


1:55:16.645,1:55:19.205


1:55:19.205,1:55:21.705


1:55:21.705,1:55:24.725


1:55:24.725,1:55:27.805


1:55:27.805,1:55:30.795


1:55:30.795,1:55:32.505


1:55:35.915,1:55:38.955


1:55:38.955,1:55:40.945


1:55:40.945,1:55:44.005


1:55:44.235,1:55:46.765


1:55:46.765,1:55:49.805


1:55:49.805,1:55:52.725


1:55:52.725,1:55:55.775


1:55:55.775,1:55:58.935


1:55:58.935,1:56:01.825


1:56:01.825,1:56:04.875


1:56:04.875,1:56:07.845


1:56:07.845,1:56:10.885


1:56:10.885,1:56:13.825


1:56:14.005,1:56:16.845


1:56:16.845,1:56:19.765


1:56:19.765,1:56:22.545


1:56:22.545,1:56:24.845


1:56:24.845,1:56:27.695


1:56:28.005,1:56:31.175


1:56:31.175,1:56:33.955


1:56:33.955,1:56:36.055


1:56:36.155,1:56:38.625


1:56:38.625,1:56:41.575


1:56:41.575,1:56:44.605


1:56:44.605,1:56:47.935


1:56:48.175,1:56:49.175


1:56:50.615,1:56:53.685


1:56:53.685,1:56:57.025


1:56:58.015,1:57:00.025


1:57:01.765,1:57:03.325


1:57:04.085,1:57:06.195


1:57:06.765,1:57:09.805


1:57:09.805,1:57:11.575


1:57:12.035,1:57:12.945


1:57:12.945,1:57:16.005


1:57:16.005,1:57:19.445


1:57:19.555,1:57:20.555


1:57:21.365,1:57:24.365


1:57:24.365,1:57:27.375


1:57:27.375,1:57:30.115


1:57:30.115,1:57:31.995


1:57:32.335,1:57:35.375


1:57:35.375,1:57:38.205


1:57:38.205,1:57:41.415


1:57:41.415,1:57:42.995


1:57:43.415,1:57:46.235


1:57:46.235,1:57:49.635


1:57:49.635,1:57:52.705


1:57:52.705,1:57:55.715


1:57:56.585,1:57:59.585


1:57:59.585,1:58:02.595


1:58:02.595,1:58:05.285


1:58:05.285,1:58:07.225


1:58:07.225,1:58:10.405


1:58:10.405,1:58:12.515


1:58:12.995,1:58:15.945


1:58:15.945,1:58:19.245


1:58:19.325,1:58:22.475


1:58:22.475,1:58:25.645


1:58:25.645,1:58:29.135


1:58:29.255,1:58:32.075


1:58:32.465,1:58:35.215


1:58:35.215,1:58:37.885


1:58:37.885,1:58:40.645


1:58:40.645,1:58:43.565


1:58:43.565,1:58:45.085


1:58:45.555,1:58:46.555


1:58:46.865,1:58:48.255


1:58:50.355,1:58:52.775


1:58:53.425,1:58:56.765


1:58:56.955,1:58:59.345


1:58:59.345,1:59:01.955


1:59:01.955,1:59:05.105


1:59:05.105,1:59:08.295


1:59:08.295,1:59:11.225


1:59:11.225,1:59:14.245


1:59:14.245,1:59:17.375


1:59:17.375,1:59:20.405


1:59:20.405,1:59:23.335


1:59:23.335,1:59:26.505


1:59:26.505,1:59:29.405


1:59:29.405,1:59:32.575


1:59:32.575,1:59:34.585


1:59:38.685,1:59:41.415


1:59:41.415,1:59:42.415


1:59:42.675,1:59:45.405


1:59:45.405,1:59:48.485


1:59:48.485,1:59:51.405


1:59:51.405,1:59:54.195


1:59:55.405,1:59:56.405


1:59:58.165,2:00:00.935


2:00:00.935,2:00:02.125


2:00:02.435,2:00:05.215


2:00:05.545,2:00:08.785


2:00:08.785,2:00:11.735


2:00:11.895,2:00:13.445


2:00:13.855,2:00:15.915


2:00:15.915,2:00:18.865


2:00:18.865,2:00:21.585


2:00:21.585,2:00:22.985


2:00:23.435,2:00:25.625


2:00:26.105,2:00:29.145


2:00:29.235,2:00:31.745


2:00:32.825,2:00:34.375


2:00:34.795,2:00:38.105


2:00:38.255,2:00:41.285


2:00:41.285,2:00:42.735


2:00:43.045,2:00:45.675


2:00:45.675,2:00:48.915


2:00:48.915,2:00:51.915


2:00:51.955,2:00:54.915


2:00:55.625,2:00:58.555


2:00:58.555,2:01:01.195


2:01:01.195,2:01:04.425


2:01:04.425,2:01:07.315


2:01:07.435,2:01:10.725


2:01:10.725,2:01:13.775


2:01:13.775,2:01:16.855


2:01:16.855,2:01:19.975


2:01:19.975,2:01:21.835


2:01:22.295,2:01:24.815


2:01:24.815,2:01:27.765


2:01:27.765,2:01:30.085


2:01:31.545,2:01:34.395


2:01:34.395,2:01:37.365


2:01:37.365,2:01:40.245


2:01:40.245,2:01:43.135


2:01:43.135,2:01:46.175


2:01:46.175,2:01:49.235


2:01:49.235,2:01:52.185


2:01:52.185,2:01:54.455


2:01:54.855,2:01:57.665


2:01:57.865,2:01:59.085


2:01:59.555,2:02:02.625


2:02:02.625,2:02:05.565


2:02:05.565,2:02:08.625


2:02:08.625,2:02:11.455


2:02:11.455,2:02:14.465


2:02:14.465,2:02:17.455


2:02:17.455,2:02:19.295


2:02:20.115,2:02:21.365


2:02:22.195,2:02:25.285


2:02:25.285,2:02:27.005


2:02:27.005,2:02:29.375


2:02:29.375,2:02:32.275


2:02:32.275,2:02:35.435


2:02:35.435,2:02:38.675


2:02:38.675,2:02:41.355


2:02:44.055,2:02:46.775


2:02:47.535,2:02:49.925


2:02:50.275,2:02:52.895


2:02:52.895,2:02:55.905


2:02:55.905,2:02:58.885


2:02:58.885,2:02:59.885


2:03:00.535,2:03:03.565


2:03:03.565,2:03:06.515


2:03:06.715,2:03:08.185


2:03:09.545,2:03:12.495


2:03:12.495,2:03:15.465


2:03:15.465,2:03:18.715


2:03:19.015,2:03:22.195


2:03:22.195,2:03:25.055


2:03:25.055,2:03:27.625


2:03:28.035,2:03:30.775


2:03:31.115,2:03:32.115


2:03:32.305,2:03:35.655


2:03:35.825,2:03:38.455


2:03:38.455,2:03:41.465


2:03:41.465,2:03:44.405


2:03:44.405,2:03:47.445


2:03:47.445,2:03:50.465


2:03:50.465,2:03:53.555


2:03:53.555,2:03:56.325


2:03:56.325,2:03:59.105


2:03:59.105,2:04:01.365


2:04:01.835,2:04:04.485


2:04:04.485,2:04:07.905


2:04:09.055,2:04:12.015


2:04:12.015,2:04:14.125


2:04:14.125,2:04:17.055


2:04:17.055,2:04:19.925


2:04:19.925,2:04:22.855


2:04:22.855,2:04:25.945


2:04:25.945,2:04:29.145


2:04:29.145,2:04:32.375


2:04:32.375,2:04:35.415


2:04:35.415,2:04:38.645


2:04:38.645,2:04:41.655


2:04:41.655,2:04:44.745


2:04:44.745,2:04:46.025


2:04:46.525,2:04:47.525


2:04:47.645,2:04:50.675


2:04:50.675,2:04:53.965


2:04:53.965,2:04:56.705


2:04:56.705,2:04:59.365


2:04:59.415,2:05:02.455


2:05:02.455,2:05:03.665


2:05:04.065,2:05:06.135


2:05:07.055,2:05:09.295


2:05:09.645,2:05:12.985


2:05:16.775,2:05:18.875


2:05:19.295,2:05:22.455


2:05:22.455,2:05:25.465


2:05:25.465,2:05:27.855


2:05:28.635,2:05:31.685


2:05:31.685,2:05:34.865


2:05:34.865,2:05:36.055


2:05:36.615,2:05:39.045


2:05:39.855,2:05:42.835


2:05:42.905,2:05:45.325


2:05:46.785,2:05:50.035


2:05:50.235,2:05:52.785


2:05:52.785,2:05:55.755


2:05:55.755,2:05:58.465


2:05:58.465,2:05:59.965


2:06:01.855,2:06:02.855


2:06:02.925,2:06:06.005


2:06:06.005,2:06:09.085


2:06:09.085,2:06:11.945


2:06:11.945,2:06:14.925


2:06:14.925,2:06:17.975


2:06:17.975,2:06:20.965


2:06:20.965,2:06:23.485


2:06:24.005,2:06:25.265


2:06:25.865,2:06:27.775


2:06:28.725,2:06:29.995


2:06:30.635,2:06:33.675


2:06:34.395,2:06:35.505


2:06:36.745,2:06:38.205


2:06:38.785,2:06:41.985


2:06:43.295,2:06:46.255


2:06:46.255,2:06:48.785


2:06:48.785,2:06:51.795


2:06:51.795,2:06:54.065


2:06:54.885,2:06:57.695


2:06:57.695,2:07:00.315


2:07:00.815,2:07:02.005


2:07:02.375,2:07:03.515


2:07:04.585,2:07:07.775


2:07:07.775,2:07:10.065


2:07:10.575,2:07:13.815


2:07:13.815,2:07:16.605


2:07:16.605,2:07:19.635


2:07:20.085,2:07:21.475


2:07:21.935,2:07:25.315


2:07:25.315,2:07:27.195


2:07:28.095,2:07:31.015


2:07:31.015,2:07:34.055


2:07:34.055,2:07:36.665


2:07:36.665,2:07:38.815


2:07:40.015,2:07:41.015


2:07:41.315,2:07:42.785


2:07:43.305,2:07:46.295


2:07:46.295,2:07:47.295


2:07:47.785,2:07:50.835


2:07:50.835,2:07:51.835


2:07:52.885,2:07:53.885


2:07:54.565,2:07:57.315


2:07:58.745,2:07:59.745


2:08:00.925,2:08:03.535


2:08:05.055,2:08:08.045


2:08:08.045,2:08:09.185


2:08:10.045,2:08:12.645


2:08:12.645,2:08:15.375


2:08:15.495,2:08:16.695


2:08:17.355,2:08:19.635


2:08:19.635,2:08:21.365


2:08:22.705,2:08:25.215


2:08:26.395,2:08:27.395


2:08:30.465,2:08:31.795


2:08:33.165,2:08:36.195


2:08:36.195,2:08:39.245


2:08:39.395,2:08:42.495


2:08:42.495,2:08:45.205


2:08:45.385,2:08:48.305


2:08:48.305,2:08:51.185


2:08:51.185,2:08:54.275


2:08:54.275,2:08:57.165


2:08:57.165,2:08:58.165


2:09:00.135,2:09:03.165


2:09:03.165,2:09:05.815


2:09:07.165,2:09:09.665


2:09:09.665,2:09:12.825


2:09:14.105,2:09:16.705


2:09:17.095,2:09:20.125


2:09:20.125,2:09:21.775


2:09:22.525,2:09:23.525


2:09:24.445,2:09:27.005


2:09:28.075,2:09:29.075


2:09:29.645,2:09:32.755


2:09:32.755,2:09:35.645


2:09:35.645,2:09:38.795


2:09:39.135,2:09:42.475


2:09:42.475,2:09:44.935


2:09:44.935,2:09:47.605


2:09:47.605,2:09:50.615


2:09:50.615,2:09:52.715


2:09:53.065,2:09:56.005


2:09:56.695,2:09:59.875


2:09:59.875,2:10:02.415


2:10:02.415,2:10:05.775


2:10:08.815,2:10:12.045


2:10:12.045,2:10:14.525


2:10:16.905,2:10:19.885


2:10:19.885,2:10:23.025


2:10:23.025,2:10:25.755


2:10:25.995,2:10:28.695


2:10:29.035,2:10:31.755


2:10:32.355,2:10:35.215


2:10:35.415,2:10:38.265


2:10:38.265,2:10:41.255


2:10:41.255,2:10:43.635


2:10:43.635,2:10:46.645


2:10:46.645,2:10:49.255


2:10:49.885,2:10:51.325


2:10:52.205,2:10:53.205


2:10:55.285,2:10:58.235


2:10:58.235,2:11:01.265


2:11:01.265,2:11:04.295


2:11:04.295,2:11:07.295


2:11:07.295,2:11:09.975


2:11:09.975,2:11:13.015


2:11:13.015,2:11:16.245


2:11:16.245,2:11:19.365


2:11:19.365,2:11:20.435


2:11:20.825,2:11:21.825


2:11:23.545,2:11:26.465


2:11:26.465,2:11:28.965


2:11:28.965,2:11:32.005


2:11:32.005,2:11:35.115


2:11:35.115,2:11:38.085


2:11:38.085,2:11:40.415


2:11:40.415,2:11:43.285


2:11:43.285,2:11:46.605


2:11:46.605,2:11:49.185


2:11:49.275,2:11:52.165


2:11:52.165,2:11:55.435


2:11:55.455,2:11:57.355


2:11:57.705,2:12:00.855


2:12:00.855,2:12:03.375


2:12:03.795,2:12:06.835


2:12:06.835,2:12:09.375


2:12:09.415,2:12:11.795


2:12:12.065,2:12:14.575


2:12:14.575,2:12:17.675


2:12:17.675,2:12:20.585


2:12:20.585,2:12:23.525


2:12:23.525,2:12:26.535


2:12:26.535,2:12:29.375


2:12:29.375,2:12:31.565


2:12:31.565,2:12:34.555


2:12:35.775,2:12:38.755


2:12:38.755,2:12:41.995


2:12:42.235,2:12:45.175


2:12:45.175,2:12:48.525


2:12:48.555,2:12:51.555


2:12:51.555,2:12:54.635


2:12:54.635,2:12:56.185


2:12:56.535,2:12:59.345


2:12:59.345,2:13:02.655


2:13:02.725,2:13:04.875


2:13:06.235,2:13:07.235


2:13:08.015,2:13:09.965


2:13:10.385,2:13:13.685


2:13:13.685,2:13:16.695


2:13:16.695,2:13:19.575


2:13:19.575,2:13:21.215


2:13:21.545,2:13:24.495


2:13:24.495,2:13:27.245


2:13:27.245,2:13:30.095


2:13:30.095,2:13:33.225


2:13:33.225,2:13:34.705


2:13:35.555,2:13:39.015


2:13:39.805,2:13:43.115


2:13:44.255,2:13:47.265


2:13:47.265,2:13:50.135


2:13:50.135,2:13:53.055


2:13:53.055,2:13:55.485


2:13:55.485,2:13:58.315


2:13:58.315,2:14:01.245


2:14:01.245,2:14:02.355


2:14:02.825,2:14:05.925


2:14:05.925,2:14:08.265


2:14:08.655,2:14:11.665


2:14:11.665,2:14:14.755


2:14:14.755,2:14:16.865


2:14:17.715,2:14:20.685


2:14:20.685,2:14:21.915


2:14:23.175,2:14:26.305


2:14:26.305,2:14:29.175


2:14:29.175,2:14:30.395


2:14:31.515,2:14:34.835


2:14:34.835,2:14:37.885


2:14:37.885,2:14:41.105


2:14:41.815,2:14:44.775


2:14:44.775,2:14:47.825


2:14:47.825,2:14:51.135


2:14:51.555,2:14:54.095


2:14:54.095,2:14:55.605


2:14:57.315,2:15:00.125


2:15:00.125,2:15:03.445


2:15:03.905,2:15:06.885


2:15:06.885,2:15:09.895


2:15:09.895,2:15:12.875


2:15:12.875,2:15:13.995


2:15:14.355,2:15:15.565


2:15:16.575,2:15:19.725


2:15:20.795,2:15:24.025


2:15:24.025,2:15:25.335


2:15:25.775,2:15:29.035


2:15:29.345,2:15:30.855


2:15:31.395,2:15:34.305


2:15:34.305,2:15:37.315


2:15:37.315,2:15:38.315


2:15:38.315,2:15:41.565


2:15:41.565,2:15:43.205


2:15:43.525,2:15:46.665


2:15:46.665,2:15:49.665


2:15:49.685,2:15:52.455


2:15:52.455,2:15:55.585


2:15:55.585,2:15:58.535


2:15:58.535,2:16:01.205


2:16:02.045,2:16:05.085


2:16:05.085,2:16:07.985


2:16:08.105,2:16:09.105


2:16:09.225,2:16:11.815


2:16:11.815,2:16:14.915


2:16:14.955,2:16:18.235


2:16:18.235,2:16:21.325


2:16:21.325,2:16:24.335


2:16:24.335,2:16:27.435


2:16:27.435,2:16:30.215


2:16:30.895,2:16:32.365

